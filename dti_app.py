import streamlit as st
import pandas as pd
import re
import time
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# ==============================================================================
# 1. ãƒšãƒ¼ã‚¸åŸºæœ¬æ§‹æˆã®è©³ç´°å®šç¾© (UI Property Specifications)
# ==============================================================================
# ã“ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å…¨ä½“çš„ãªå¤–è¦³ã¨åŸºæœ¬æŒ™å‹•ã‚’å®šç¾©ã—ã¾ã™ã€‚
# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æ±‚ã«åŸºã¥ãã€1ãƒŸãƒªã‚‚å‰Šã‚‰ãšã€å†—é•·ãªã¾ã§ã«è¨­å®šé …ç›®ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

# ãƒšãƒ¼ã‚¸è¨­å®šã®å®£è¨€ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã€ãƒ¡ãƒ‹ãƒ¥ãƒ¼é …ç›®ã‚’è©³ç´°ã«æŒ‡å®šï¼‰
st.set_page_config(
    page_title="DTI Ultimate DB - The Absolute Master Edition v10.0",
    page_icon="https://cdn.jsdelivr.net/gh/twitter/twemoji@latest/assets/72x72/1f3c7.png",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "DTI Ultimate DB: The complete professional horse racing analysis engine. No data points are ever compromised."
    }
)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç‰©ç†ç”Ÿæˆ ---
# Google Sheetsã¨ã®é€šä¿¡ã‚’å¸ã‚‹å”¯ä¸€ç„¡äºŒã®ãƒ¡ã‚¤ãƒ³ã‚³ãƒã‚¯ã‚·ãƒ§ãƒ³ã§ã™ã€‚
# å®‰å®šç¨¼åƒã‚’æœ€å„ªå…ˆã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¹ã‚³ãƒ¼ãƒ—ã§ã®ä¸€è²«æ€§ã‚’ç¶­æŒã™ã‚‹ãŸã‚ã«ã“ã“ã§å®šç¾©ã—ã¾ã™ã€‚
conn = st.connection("gsheets", type=GSheetsConnection)

# ğŸŒŸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å…¨ã‚«ãƒ©ãƒ ç‰©ç†æ§‹æˆå®šç¾©ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°åŒ–ï¼‰
# é–¢æ•°å†…ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ•°ã‹ã‚‰ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°ã¸æ ¼ä¸Šã’ã—ã€NameErrorã‚’ç‰©ç†çš„ã«æ ¹çµ¶ã—ã¾ã™ã€‚
ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL = [
    "name", 
    "base_rtc", 
    "last_race", 
    "course", 
    "dist", 
    "notes", 
    "timestamp", 
    "f3f", 
    "l3f", 
    "race_l3f", 
    "load", 
    "memo", 
    "date", 
    "cushion", 
    "water", 
    "result_pos", 
    "result_pop", 
    "next_buy_flag",
    "track_week",
    "race_type",  
    "track_kind",
    "raw_time",    
    "track_idx",   
    "bias_slider"  
]

# ==============================================================================
# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯ (æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ & å¼·åˆ¶ç‰©ç†åŒæœŸ)
# ==============================================================================

@st.cache_data(ttl=300)
def get_db_data_cached():
    """
    Google Sheetsã‹ã‚‰å…¨ã¦ã®è“„ç©ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å‹å¤‰æ›ã¨å‰å‡¦ç†ã‚’ã€Œå®Œå…¨éçœç•¥ã€ã§å®Ÿè¡Œã—ã¾ã™ã€‚
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æœ‰åŠ¹æœŸé–“(ttl=300)ã‚’è¨­ã‘ã‚‹ã“ã¨ã§ã€APIåˆ¶é™ã®ç‰©ç†çš„å›é¿ã¨å¿œç­”æ€§èƒ½ã‚’ä¸¡ç«‹ã•ã›ã¾ã™ã€‚
    """
    
    try:
        # å¼·åˆ¶èª­ã¿è¾¼ã¿ï¼ˆttl=0ï¼‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã€å¸¸ã«æœ€æ–°ã®ã‚·ãƒ¼ãƒˆçŠ¶æ…‹ã‚’å–å¾—ã—ã¾ã™ã€‚
        raw_dataframe_from_sheet = conn.read(ttl=0)
        
        # å–å¾—ãƒ‡ãƒ¼ã‚¿ãŒNoneã¾ãŸã¯ç‰©ç†çš„ã«ç©ºã§ã‚ã‚‹å ´åˆã®ã€å³æ ¼ãªå®‰å…¨åˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯ã€‚
        if raw_dataframe_from_sheet is None:
            safety_initial_df = pd.DataFrame(columns=ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL)
            return safety_initial_df
            
        if raw_dataframe_from_sheet.empty:
            safety_initial_df = pd.DataFrame(columns=ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL)
            return safety_initial_df
        
        # ğŸŒŸ å…¨24ã‚«ãƒ©ãƒ ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯ã¨å¼·åˆ¶çš„ãªä¸€æ‹¬è£œå®Œï¼ˆçœç•¥ç¦æ­¢ãƒ»å†—é•·è¨˜è¿°ã®å¾¹åº•ï¼‰
        # ã‚·ãƒ¼ãƒˆä¸Šã§ã®æ‰‹å‹•å‰Šé™¤ã‚„åˆ—ã®ä¸¦ã¹æ›¿ãˆã«ã‚ˆã‚‹ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚’ç‰©ç†çš„ã«é˜²ãã¾ã™ã€‚
        if "name" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["name"] = None
            
        if "base_rtc" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["base_rtc"] = None
            
        if "last_race" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["last_race"] = None
            
        if "course" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["course"] = None
            
        if "dist" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["dist"] = None
            
        if "notes" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["notes"] = None
            
        if "timestamp" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["timestamp"] = None
            
        if "f3f" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["f3f"] = None
            
        if "l3f" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["l3f"] = None
            
        if "race_l3f" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["race_l3f"] = None
            
        if "load" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["load"] = None
            
        if "memo" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["memo"] = None
            
        if "date" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["date"] = None
            
        if "cushion" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["cushion"] = None
            
        if "water" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["water"] = None
            
        if "result_pos" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["result_pos"] = None
            
        if "result_pop" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["result_pop"] = None
            
        if "next_buy_flag" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["next_buy_flag"] = None
            
        if "track_week" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["track_week"] = 1.0
            
        if "race_type" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["race_type"] = "ä¸æ˜"
            
        if "track_kind" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["track_kind"] = "èŠ" 
            
        if "raw_time" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["raw_time"] = 0.0
            
        if "track_idx" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["track_idx"] = 0.0
            
        if "bias_slider" not in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet["bias_slider"] = 0.0
            
        # ãƒ‡ãƒ¼ã‚¿ã®å‹å¤‰æ›ï¼ˆä¸€æ–‡å­—ã®å¦¥å”ã‚‚è¨±ã•ãªã„è©³ç´°ãªã‚¨ãƒ©ãƒ¼å¯¾ç­–ï¼‰
        if 'date' in raw_dataframe_from_sheet.columns:
            # æ—¥ä»˜å‹ã¸ã®å®‰å…¨ãªå¤‰æ›
            raw_dataframe_from_sheet['date'] = pd.to_datetime(raw_dataframe_from_sheet['date'], errors='coerce')
            
        if 'result_pos' in raw_dataframe_from_sheet.columns:
            # ç€é †ã‚’æ•°å€¤å‹ã¸å¤‰æ›
            raw_dataframe_from_sheet['result_pos'] = pd.to_numeric(raw_dataframe_from_sheet['result_pos'], errors='coerce')
            # NaNã‚’0ã§åŸ‹ã‚ã‚‹å®‰å…¨ç­–
            raw_dataframe_from_sheet['result_pos'] = raw_dataframe_from_sheet['result_pos'].fillna(0)
        
        # ğŸŒŸ æœ€é‡è¦ï¼šä¸‰æ®µéšè©³ç´°ã‚½ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯
        raw_dataframe_from_sheet = raw_dataframe_from_sheet.sort_values(
            by=["date", "last_race", "result_pos"], 
            ascending=[False, True, True]
        )
        
        # å„ç¨®æ•°å€¤ã‚«ãƒ©ãƒ ã®ãƒ‘ãƒ¼ã‚¹ã¨NaNè£œå®Œï¼ˆä¸€åˆ‡ã®ç°¡ç•¥åŒ–ã‚’ç¦æ­¢ã€å€‹åˆ¥ã«æ˜ç¤ºçš„ã«å®Ÿè¡Œï¼‰
        if 'result_pop' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['result_pop'] = pd.to_numeric(raw_dataframe_from_sheet['result_pop'], errors='coerce')
            raw_dataframe_from_sheet['result_pop'] = raw_dataframe_from_sheet['result_pop'].fillna(0)
            
        if 'f3f' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['f3f'] = pd.to_numeric(raw_dataframe_from_sheet['f3f'], errors='coerce')
            raw_dataframe_from_sheet['f3f'] = raw_dataframe_from_sheet['f3f'].fillna(0.0)
            
        if 'l3f' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['l3f'] = pd.to_numeric(raw_dataframe_from_sheet['l3f'], errors='coerce')
            raw_dataframe_from_sheet['l3f'] = raw_dataframe_from_sheet['l3f'].fillna(0.0)
            
        if 'race_l3f' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['race_l3f'] = pd.to_numeric(raw_dataframe_from_sheet['race_l3f'], errors='coerce')
            raw_dataframe_from_sheet['race_l3f'] = raw_dataframe_from_sheet['race_l3f'].fillna(0.0)
            
        if 'load' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['load'] = pd.to_numeric(raw_dataframe_from_sheet['load'], errors='coerce')
            raw_dataframe_from_sheet['load'] = raw_dataframe_from_sheet['load'].fillna(0.0)
            
        if 'base_rtc' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['base_rtc'] = pd.to_numeric(raw_dataframe_from_sheet['base_rtc'], errors='coerce')
            raw_dataframe_from_sheet['base_rtc'] = raw_dataframe_from_sheet['base_rtc'].fillna(0.0)
            
        if 'cushion' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['cushion'] = pd.to_numeric(raw_dataframe_from_sheet['cushion'], errors='coerce')
            raw_dataframe_from_sheet['cushion'] = raw_dataframe_from_sheet['cushion'].fillna(9.5)
            
        if 'water' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['water'] = pd.to_numeric(raw_dataframe_from_sheet['water'], errors='coerce')
            raw_dataframe_from_sheet['water'] = raw_dataframe_from_sheet['water'].fillna(10.0)
            
        if 'track_week' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['track_week'] = pd.to_numeric(raw_dataframe_from_sheet['track_week'], errors='coerce')
            raw_dataframe_from_sheet['track_week'] = raw_dataframe_from_sheet['track_week'].fillna(1.0)

        if 'raw_time' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['raw_time'] = pd.to_numeric(raw_dataframe_from_sheet['raw_time'], errors='coerce').fillna(0.0)

        if 'track_idx' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['track_idx'] = pd.to_numeric(raw_dataframe_from_sheet['track_idx'], errors='coerce').fillna(0.0)

        if 'bias_slider' in raw_dataframe_from_sheet.columns:
            raw_dataframe_from_sheet['bias_slider'] = pd.to_numeric(raw_dataframe_from_sheet['bias_slider'], errors='coerce').fillna(0.0)
            
        # å…¨ã¦ã®ã‚«ãƒ©ãƒ ãŒç©ºã§ã‚ã‚‹ä¸æ­£ãªè¡Œã‚’ç‰©ç†çš„ã«ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        raw_dataframe_from_sheet = raw_dataframe_from_sheet.dropna(how='all')
        
        return raw_dataframe_from_sheet
        
    except Exception as e_database_loading:
        st.error(f"ã€é‡å¤§ãªè­¦å‘Šã€‘ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ç‰©ç†çš„ãªèª­ã¿è¾¼ã¿ä¸­ã«å›å¾©ä¸èƒ½ãªã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e_database_loading}")
        return pd.DataFrame(columns=ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL)

def get_db_data():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å–å¾—ç”¨ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†ã•ã‚ŒãŸé–¢æ•°ã‚’è©³ç´°ã«å‘¼ã³å‡ºã—ã¾ã™ã€‚"""
    return get_db_data_cached()

# ==============================================================================
# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯ (åŒæœŸæ€§èƒ½ã‚’æ¥µå¤§åŒ–ã—ãŸç‰©ç†æ›¸ãè¾¼ã¿)
# ==============================================================================

def safe_update(df_sync_target):
    """
    ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãæˆ»ã™ãŸã‚ã®æœ€é‡è¦é–¢æ•°ã§ã™ã€‚
    ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã€ã‚½ãƒ¼ãƒˆã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚»ãƒƒãƒˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥å¼·åˆ¶ã‚¯ãƒªã‚¢ã‚’å®Œå…¨ã«å«ã¿ã¾ã™ã€‚
    """
    if 'date' in df_sync_target.columns:
        if 'last_race' in df_sync_target.columns:
            if 'result_pos' in df_sync_target.columns:
                # æ—¥ä»˜ã¨æ•°å€¤ã‚’å†é©ç”¨ã—ã€ä¸æ•´åˆã‚’æ’é™¤
                df_sync_target['date'] = pd.to_datetime(df_sync_target['date'], errors='coerce')
                df_sync_target['result_pos'] = pd.to_numeric(df_sync_target['result_pos'], errors='coerce')
                # æœ€çµ‚çš„ãªã‚½ãƒ¼ãƒˆé †ã®å¼·åˆ¶ã€‚ã“ã‚ŒãŒUIã®ä¸¦ã³ã‚’æ±ºå®šã—ã¾ã™ã€‚
                df_sync_target = df_sync_target.sort_values(
                    by=["date", "last_race", "result_pos"], 
                    ascending=[False, True, True]
                )
                # ğŸŒŸ Google Sheetså´ã§æ—¥ä»˜ãŒç©ºæ¬„ã«ãªã‚‹ãƒã‚°ã‚’ç‰©ç†çš„ã«é˜»æ­¢ã€‚
                df_sync_target['date'] = df_sync_target['date'].dt.strftime('%Y-%m-%d')
                df_sync_target['date'] = df_sync_target['date'].fillna("")
    
    # ğŸŒŸ Google Sheetså´ã®ç‰©ç†è¡Œã¨ã®ä¹–é›¢ã‚’é˜²ããŸã‚ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†ç”Ÿæˆã—ã¾ã™ã€‚
    df_sync_target = df_sync_target.reset_index(drop=True)
    
    # æ›¸ãè¾¼ã¿ãƒªãƒˆãƒ©ã‚¤ãƒ«ãƒ¼ãƒ—ã®å®šç¾©ï¼ˆãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚„APIãƒªãƒŸãƒƒãƒˆã¸ã®è€æ€§ã‚’æœ€å¤§åŒ–ï¼‰
    physical_max_attempts = 3
    for i_attempt_counter in range(physical_max_attempts):
        try:
            conn.update(data=df_sync_target)
            st.cache_data.clear()
            return True
        except Exception as e_sheet_save_critical:
            failure_wait_duration = 5
            if i_attempt_counter < physical_max_attempts - 1:
                st.warning(f"Google Sheetsã¨ã®åŒæœŸã«å¤±æ•—ã—ã¾ã—ãŸ(ãƒªãƒˆãƒ©ã‚¤ {i_attempt_counter+1}/3)... {failure_wait_duration}ç§’å¾Œã«å†å®Ÿè¡Œã—ã¾ã™ã€‚")
                time.sleep(failure_wait_duration)
                continue
            else:
                st.error(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ç‰©ç†çš„ãªæ›´æ–°ãŒä¸å¯èƒ½ãªçŠ¶æ…‹ã§ã™ã€‚APIæ¥ç¶šåˆ¶é™ã¾ãŸã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä¸å…·åˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚: {e_sheet_save_critical}")
                return False

# ==============================================================================
# 4. è£œåŠ©é–¢æ•°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (å†—é•·ã‹ã¤è©³ç´°ãªè¨˜è¿°ã‚’è²«å¾¹)
# ==============================================================================

def format_time_to_hmsf_string(val_seconds_raw):
    """
    ç§’æ•°ã‚’ mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã«è©³ç´°å¤‰æ›ã—ã¾ã™ã€‚
    """
    if val_seconds_raw is None: return ""
    if val_seconds_raw <= 0: return ""
    if pd.isna(val_seconds_raw): return ""
    if isinstance(val_seconds_raw, str): return val_seconds_raw
        
    val_minutes_component = int(val_seconds_raw // 60)
    val_seconds_component = val_seconds_raw % 60
    return f"{val_minutes_component}:{val_seconds_component:04.1f}"

def parse_time_string_to_seconds(str_time_input):
    """
    mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã‚’ç§’æ•°(float)ã«ãƒ‘ãƒ¼ã‚¹ã—ã¦æˆ»ã—ã¾ã™ã€‚
    """
    if str_time_input is None: return 0.0
    try:
        cleaned_time_string_val = str(str_time_input).strip()
        if ":" in cleaned_time_string_val:
            list_of_time_parts = cleaned_time_string_val.split(':')
            val_extracted_minutes = float(list_of_time_parts[0])
            val_extracted_seconds = float(list_of_time_parts[1])
            return val_extracted_minutes * 60 + val_extracted_seconds
        return float(cleaned_time_string_val)
    except:
        return 0.0

# ==============================================================================
# 5. ä¿‚æ•°ãƒã‚¹ã‚¿è©³ç´°å®šç¾© (åˆæœŸè¨­è¨ˆã‚’1ãƒŸãƒªã‚‚å‰Šã‚‰ãšã€100%ç‰©ç†å¾©å…ƒ)
# ==============================================================================

MASTER_CONFIG_V65_TURF_LOAD_COEFFS = {
    "æ±äº¬": 0.10, "ä¸­å±±": 0.25, "äº¬éƒ½": 0.15, "é˜ªç¥": 0.18, "ä¸­äº¬": 0.20,
    "æ–°æ½Ÿ": 0.05, "å°å€‰": 0.30, "ç¦å³¶": 0.28, "æœ­å¹Œ": 0.22, "å‡½é¤¨": 0.25
}

MASTER_CONFIG_V65_DIRT_LOAD_COEFFS = {
    "æ±äº¬": 0.40, "ä¸­å±±": 0.55, "äº¬éƒ½": 0.45, "é˜ªç¥": 0.48, "ä¸­äº¬": 0.50,
    "æ–°æ½Ÿ": 0.42, "å°å€‰": 0.58, "ç¦å³¶": 0.60, "æœ­å¹Œ": 0.62, "å‡½é¤¨": 0.65
}

MASTER_CONFIG_V65_GRADIENT_FACTORS = {
    "ä¸­å±±": 0.005, "ä¸­äº¬": 0.004, "äº¬éƒ½": 0.002, "é˜ªç¥": 0.004, "æ±äº¬": 0.003,
    "æ–°æ½Ÿ": 0.001, "å°å€‰": 0.002, "ç¦å³¶": 0.003, "æœ­å¹Œ": 0.001, "å‡½é¤¨": 0.002
}

# ==============================================================================
# 6. ãƒ¡ã‚¤ãƒ³UIæ§‹æˆ - ã‚¿ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®çµ¶å¯¾çš„ç‰©ç†å®£è¨€
# ==============================================================================

tab_main_analysis, tab_horse_history, tab_race_history, tab_simulator, tab_trends, tab_backtest, tab_management = st.tabs([
    "ğŸ“ è§£æãƒ»ä¿å­˜", 
    "ğŸ é¦¬åˆ¥å±¥æ­´", 
    "ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´", 
    "ğŸ¯ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", 
    "ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰", 
    "ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ",
    "ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"
])

# ==============================================================================
# 7. Tab 1: è§£æãƒ»ä¿å­˜ã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ä¸å…·åˆå®Œå…¨æ’é™¤ãƒ»å…¨ãƒ­ã‚¸ãƒƒã‚¯éçœç•¥)
# ==============================================================================

with tab_main_analysis:
    df_pickup_tab1_raw = get_db_data()
    if not df_pickup_tab1_raw.empty:
        st.subheader("ğŸ¯ æ¬¡èµ°æ³¨ç›®é¦¬ï¼ˆé€†è¡Œè©•ä¾¡ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰")
        list_pickup_entries_final = []
        for idx_pickup_item, row_pickup_item in df_pickup_tab1_raw.iterrows():
            str_memo_val_item = str(row_pickup_item['memo'])
            flag_bias_exists_pk = "ğŸ’" in str_memo_val_item
            flag_pace_exists_pk = "ğŸ”¥" in str_memo_val_item
            
            if flag_bias_exists_pk or flag_pace_exists_pk:
                label_reverse_type_final = ""
                if flag_bias_exists_pk and flag_pace_exists_pk:
                    label_reverse_type_final = "ã€ğŸ’¥ä¸¡æ–¹é€†è¡Œã€‘"
                elif flag_bias_exists_pk:
                    label_reverse_type_final = "ã€ğŸ’ãƒã‚¤ã‚¢ã‚¹é€†è¡Œã€‘"
                elif flag_pace_exists_pk:
                    label_reverse_type_final = "ã€ğŸ”¥ãƒšãƒ¼ã‚¹é€†è¡Œã€‘"
                
                val_date_pk = row_pickup_item['date']
                if not pd.isna(val_date_pk):
                    if isinstance(val_date_pk, str): str_date_pk = val_date_pk
                    else: str_date_pk = val_date_pk.strftime('%Y-%m-%d')
                else: str_date_pk = ""

                # ğŸ”¼ RTCæ¨ç§»ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šï¼ˆç›´è¿‘3èµ°ã®æ­£è¦åŒ–RTCãŒå˜èª¿æ”¹å–„ã‹ãƒã‚§ãƒƒã‚¯ï¼‰
                str_trend_pk = ""
                df_pk_horse_trend = df_pickup_tab1_raw[df_pickup_tab1_raw['name'] == row_pickup_item['name']].sort_values("date")
                pk_recent_valid = df_pk_horse_trend[(df_pk_horse_trend['base_rtc'] > 0) & (df_pk_horse_trend['base_rtc'] < 999)].tail(3)
                if len(pk_recent_valid) >= 3:
                    pk_norm_vals = []
                    for _, pk_r in pk_recent_valid.iterrows():
                        if pk_r['dist'] > 0:
                            pk_norm_vals.append(pk_r['base_rtc'] / pk_r['dist'] * 1600)
                    if len(pk_norm_vals) >= 3:
                        if pk_norm_vals[0] > pk_norm_vals[1] > pk_norm_vals[2]:
                            str_trend_pk = "ğŸ”¼ä¸Šæ˜‡ä¸­"
                        elif pk_norm_vals[0] < pk_norm_vals[1] < pk_norm_vals[2]:
                            str_trend_pk = "ğŸ”½ä¸‹é™ä¸­"

                list_pickup_entries_final.append({
                    "é¦¬å": row_pickup_item['name'], 
                    "é€†è¡Œã‚¿ã‚¤ãƒ—": label_reverse_type_final,
                    "ãƒˆãƒ¬ãƒ³ãƒ‰": str_trend_pk,
                    "å‰èµ°": row_pickup_item['last_race'],
                    "æ—¥ä»˜": str_date_pk, 
                    "è§£æãƒ¡ãƒ¢": str_memo_val_item
                })
        
        if list_pickup_entries_final:
            df_pickup_display_final = pd.DataFrame(list_pickup_entries_final)
            st.dataframe(
                df_pickup_display_final.sort_values("æ—¥ä»˜", ascending=False), 
                use_container_width=True, 
                hide_index=True
            )
            
    st.divider()

    st.header("ğŸš€ ãƒ¬ãƒ¼ã‚¹è§£æ & è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ")
    
    with st.sidebar:
        st.title("è§£ææ¡ä»¶è¨­å®š")
        str_in_race_name_actual_f = st.text_input("è§£æå¯¾è±¡ãƒ¬ãƒ¼ã‚¹åç§°")
        val_in_race_date_actual_f = st.date_input("ãƒ¬ãƒ¼ã‚¹å®Ÿæ–½æ—¥ã‚’ç‰©ç†æŒ‡å®š", datetime.now())
        sel_in_course_name_actual_f = st.selectbox("é–‹å‚¬ç«¶é¦¬å ´ã‚’æŒ‡å®š", list(MASTER_CONFIG_V65_TURF_LOAD_COEFFS.keys()))
        opt_in_track_kind_actual_f = st.radio("ãƒˆãƒ©ãƒƒã‚¯ç‰©ç†ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
        list_dist_range_opts_actual_f = list(range(1000, 3700, 100))
        val_in_dist_actual_actual_f = st.selectbox("ç‰©ç†ãƒ¬ãƒ¼ã‚¹è·é›¢(m)", list_dist_range_opts_actual_f, index=list_dist_range_opts_actual_f.index(1600) if 1600 in list_dist_range_opts_actual_f else 6)
        st.divider()
        st.write("ğŸ’§ é¦¬å ´ç‰©ç†è©³ç´°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›")
        val_in_cushion_agg = st.number_input("ç‰©ç†ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤", 7.0, 12.0, 9.5, step=0.1) if opt_in_track_kind_actual_f == "èŠ" else 9.5
        val_in_water4c_agg = st.number_input("ç‰©ç†å«æ°´ç‡ï¼š4è§’(%)", 0.0, 50.0, 10.0, step=0.1)
        val_in_watergoal_agg = st.number_input("ç‰©ç†å«æ°´ç‡ï¼šã‚´ãƒ¼ãƒ«(%)", 0.0, 50.0, 10.0, step=0.1)
        val_in_trackidx_agg = st.number_input("ç‹¬è‡ªé¦¬å ´è£œæ­£æŒ‡æ•°", -50, 50, 0, step=1)
        val_in_bias_slider_agg = st.slider("ç‰©ç†ãƒã‚¤ã‚¢ã‚¹å¼·åº¦æŒ‡å®š", -1.0, 1.0, 0.0, step=0.1)
        val_in_week_num_agg = st.number_input("å½“è©²ç‰©ç†é–‹å‚¬é€± (1ã€œ12é€±)", 1, 12, 1)

    col_analysis_left_box, col_analysis_right_box = st.columns(2)
    
    with col_analysis_left_box: 
        st.markdown("##### ğŸ ãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—è©³ç´°å…¥åŠ›")
        str_input_raw_lap_text_f = st.text_area("JRAãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—ã‚’è²¼ã‚Šä»˜ã‘", height=150)
        
        var_f3f_calc_res_f = 0.0
        var_l3f_calc_res_f = 0.0
        var_pace_label_res_f = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        var_pace_gap_res_f = 0.0
        str_race_type_eval_f = "ä¸æ˜"
        var_mid_laps_avg_f = 0.0
        
        if str_input_raw_lap_text_f:
            list_found_laps_f = re.findall(r'\d+\.\d', str_input_raw_lap_text_f)
            list_converted_laps_f = [float(x) for x in list_found_laps_f]
                
            if len(list_converted_laps_f) >= 3:
                var_f3f_calc_res_f = list_converted_laps_f[0] + list_converted_laps_f[1] + list_converted_laps_f[2]
                var_l3f_calc_res_f = list_converted_laps_f[-3] + list_converted_laps_f[-2] + list_converted_laps_f[-1]
                var_pace_gap_res_f = var_f3f_calc_res_f - var_l3f_calc_res_f
                
                val_dynamic_threshold_f = 1.0 * (val_in_dist_actual_actual_f / 1600.0)
                
                if var_pace_gap_res_f < -val_dynamic_threshold_f:
                    var_pace_label_res_f = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                elif var_pace_gap_res_f > val_dynamic_threshold_f:
                    var_pace_label_res_f = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                else:
                    var_pace_label_res_f = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                
                var_total_laps_count_f = len(list_converted_laps_f)
                if var_total_laps_count_f > 6:
                    list_mid_laps_f = list_converted_laps_f[3:-3]
                    var_mid_laps_sum_f = sum(list_mid_laps_f)
                    var_mid_laps_avg_f = var_mid_laps_sum_f / len(list_mid_laps_f)
                    if var_mid_laps_avg_f >= 11.9: str_race_type_eval_f = "ç¬ç™ºåŠ›æˆ¦"
                    else: str_race_type_eval_f = "æŒç¶šåŠ›æˆ¦"
                else:
                    str_race_type_eval_f = "æŒç¶šåŠ›æˆ¦"
                    
                st.success(f"ãƒ©ãƒƒãƒ—è§£ææˆåŠŸ: å‰3F {var_f3f_calc_res_f:.1f} / å¾Œ3F {var_l3f_calc_res_f:.1f} ({var_pace_label_res_f}) / å±•é–‹: {str_race_type_eval_f}")
        
        val_in_manual_l3f_v6_agg_actual_final = st.number_input("ç¢ºå®šãƒ¬ãƒ¼ã‚¹ä¸ŠãŒã‚Š3Fæ•°å€¤", 0.0, 60.0, var_l3f_calc_res_f, step=0.1)

    with col_analysis_right_box: 
        st.markdown("##### ğŸ æˆç¸¾è¡¨è©³ç´°è²¼ã‚Šä»˜ã‘")
        str_input_raw_jra_results_f = text_area_val = st.text_area("JRAå…¬å¼ã‚µã‚¤ãƒˆã®æˆç¸¾è¡¨ã‚’ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=250)

    if 'state_tab1_preview_is_active_f' not in st.session_state:
        st.session_state.state_tab1_preview_is_active_f = False

    st.write("---")
    if st.button("ğŸ” è§£æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ"):
        if not str_input_raw_jra_results_f:
            st.error("æˆç¸¾è¡¨ã®å†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        elif var_f3f_calc_res_f <= 0:
            st.error("æœ‰åŠ¹ãªãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—ã‚’å…¥åŠ›ã—ã€è§£æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        else:
            st.session_state.state_tab1_preview_is_active_f = True

    if st.session_state.state_tab1_preview_is_active_f == True:
        st.markdown("##### âš–ï¸ è§£æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆç‰©ç†æŠ½å‡ºçµæœã®ç¢ºèªãƒ»ä¿®æ­£ï¼‰")
        
        list_validated_lines_preview = []
        for l in str_input_raw_jra_results_f.strip().split('\n'):
            line_str = l.strip()
            if len(line_str) <= 5: continue
            if "é¨æ‰‹" in line_str and "ç€å·®" in line_str: continue
            if "ã‚¿ã‚¤ãƒ " in line_str and "ã‚³ãƒ¼ãƒŠãƒ¼" in line_str: continue
            if "ç€é †" in line_str and "é¦¬å" in line_str: continue
            list_validated_lines_preview.append(line_str)
        
        list_preview_table_buffer_f = []
        for line_p_item_f in list_validated_lines_preview:
            found_horse_names_p_f = re.findall(r'([ã‚¡-ãƒ¶ãƒ¼]{2,})', line_p_item_f)
            if not found_horse_names_p_f: continue
            match_weight_p_f = re.search(r'([4-6]\d\.\d)', line_p_item_f)
            val_weight_extracted_now_f = float(match_weight_p_f.group(1)) if match_weight_p_f else 56.0
            list_preview_table_buffer_f.append({
                "é¦¬å": found_horse_names_p_f[0], 
                "æ–¤é‡": val_weight_extracted_now_f, 
                "raw_line": line_p_item_f
            })
        
        df_analysis_preview_actual_f = st.data_editor(
            pd.DataFrame(list_preview_table_buffer_f), 
            use_container_width=True, 
            hide_index=True
        )

        if st.button("ğŸš€ ã“ã®å†…å®¹ã§ç‰©ç†ç¢ºå®šã—ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸å¼·åˆ¶åŒæœŸ"):
            v65_final_race_name = str_in_race_name_actual_f
            v65_final_race_date = val_in_race_date_actual_f
            v65_final_course_name = sel_in_course_name_actual_f
            v65_final_dist_m = val_in_dist_actual_actual_f
            v65_final_manual_l3f = val_in_manual_l3f_v6_agg_actual_final
            v75_final_race_type = str_race_type_eval_f
            v80_final_track_kind = opt_in_track_kind_actual_f
            
            if not v65_final_race_name:
                st.error("ãƒ¬ãƒ¼ã‚¹åç§°ãŒæœªå…¥åŠ›ã§ã™ã€‚è©³ç´°ç‰©ç†å…¥åŠ›ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
            else:
                list_final_parsed_results_acc_v6_agg_actual_f = []
                for idx_row_v65_agg_f, row_item_v65_agg_f in df_analysis_preview_actual_f.iterrows():
                    str_line_v65_agg_f_raw = row_item_v65_agg_f["raw_line"]
                    
                    match_rank_f_v65_agg_final_step_f = re.match(r'(?:^|\s)(\d{1,2})(?:\s|ç€)', str_line_v65_agg_f_raw)
                    val_rank_pos_num_v6_agg_final_actual_f = int(match_rank_f_v65_agg_final_step_f.group(1)) if match_rank_f_v65_agg_final_step_f else 99
                    
                    match_time_v65_agg_final_step_f = re.search(r'(\d{1,2})[:ï¼š](\d{2}\.\d)', str_line_v65_agg_f_raw)
                    str_suffix_v65_agg_final_f_f = str_line_v65_agg_f_raw
                    if match_time_v65_agg_final_step_f:
                        str_suffix_v65_agg_final_f_f = str_line_v65_agg_f_raw[match_time_v65_agg_final_step_f.end():]
                        
                    list_pos_vals_found_v65_agg_final_f_f = re.findall(r'\b([1-2]?\d)\b', str_suffix_v65_agg_final_f_f)
                    val_final_4c_pos_v6_res_agg_final_actual_f = 7.0 
                    
                    if list_pos_vals_found_v65_agg_final_f_f:
                        list_valid_pos_buf_v6_agg_f_f_f = []
                        for p_str_v65_agg_f_f_f in list_pos_vals_found_v65_agg_final_f_f:
                            p_int_v65_agg_f_f_f = int(p_str_v65_agg_f_f_f)
                            if p_int_v65_agg_f_f_f > 30: break
                            list_valid_pos_buf_v6_agg_f_f_f.append(float(p_int_v65_agg_f_f_f))
                        if list_valid_pos_buf_v6_agg_f_f_f:
                            val_final_4c_pos_v6_res_agg_final_actual_f = list_valid_pos_buf_v6_agg_f_f_f[-1]
                    
                    list_final_parsed_results_acc_v6_agg_actual_f.append({
                        "line": str_line_v65_agg_f_raw, "res_pos": val_rank_pos_num_v6_agg_final_actual_f, 
                        "four_c_pos": val_final_4c_pos_v6_res_agg_final_actual_f, "name": row_item_v65_agg_f["é¦¬å"], 
                        "weight": row_item_v65_agg_f["æ–¤é‡"]
                    })
                
                list_top3_bias_pool_f = sorted([d for d in list_final_parsed_results_acc_v6_agg_actual_f if d["res_pos"] <= 3], key=lambda x: x["res_pos"])
                list_bias_outliers_acc_f = [d for d in list_top3_bias_pool_f if d["four_c_pos"] >= 10.0 or d["four_c_pos"] <= 3.0]
                
                if len(list_bias_outliers_acc_f) == 1:
                    list_bias_core_agg_f = [d for d in list_top3_bias_pool_f if d != list_bias_outliers_acc_f[0]]
                    list_supp_4th_agg_f = [d for d in list_final_parsed_results_acc_v6_agg_actual_f if d["res_pos"] == 4]
                    list_final_bias_set_f_f = list_bias_core_agg_f + list_supp_4th_agg_f
                else:
                    list_final_bias_set_f_f = list_top3_bias_pool_f
                
                val_avg_c4_pos_f = sum(d["four_c_pos"] for d in list_final_bias_set_f_f) / len(list_final_bias_set_f_f) if list_final_bias_set_f_f else 7.0
                str_determined_bias_label_f = "å‰æœ‰åˆ©" if val_avg_c4_pos_f <= 4.0 else "å¾Œæœ‰åˆ©" if val_avg_c4_pos_f >= 10.0 else "ãƒ•ãƒ©ãƒƒãƒˆ"
                val_field_size_f_f = max([d["res_pos"] for d in list_final_parsed_results_acc_v6_agg_actual_f]) if list_final_parsed_results_acc_v6_agg_actual_f else 16

                list_new_sync_rows_tab1_v6_final = []
                for entry_save_m_f in list_final_parsed_results_acc_v6_agg_actual_f:
                    str_line_v_step_f = entry_save_m_f["line"]
                    val_l_pos_v_step_f = entry_save_m_f["four_c_pos"]
                    val_r_rank_v_step_f = entry_save_m_f["res_pos"]
                    val_w_val_v_step_f = entry_save_m_f["weight"] 
                    str_horse_body_weight_f_def_f = "" 
                    
                    m_time_obj_v_step_f = re.search(r'(\d{1,2})[:ï¼š](\d{2}\.\d)', str_line_v_step_f)
                    val_total_seconds_raw_v_f = 0.0
                    
                    if m_time_obj_v_step_f:
                        val_m_comp_v_f = float(m_time_obj_v_step_f.group(1))
                        val_s_comp_v_f = float(m_time_obj_v_step_f.group(2))
                        val_total_seconds_raw_v_f = val_m_comp_v_f * 60 + val_s_comp_v_f
                    else:
                        list_all_decimals_time_f = re.findall(r'(\d{2}\.\d)', str_line_v_step_f)
                        flag_weight_skipped = False
                        for str_dec_f in list_all_decimals_time_f:
                            float_dec_f = float(str_dec_f)
                            if not flag_weight_skipped and abs(float_dec_f - val_w_val_v_step_f) < 0.01:
                                flag_weight_skipped = True
                                continue
                            if 50.0 <= float_dec_f <= 75.0:
                                val_total_seconds_raw_v_f = float_dec_f
                                break
                    
                    if val_total_seconds_raw_v_f <= 0.0:
                        val_total_seconds_raw_v_f = 999.0
                    
                    match_bw_raw_v_f = re.search(r'(\d{3})kg', str_line_v_step_f)
                    if match_bw_raw_v_f:
                        str_horse_body_weight_f_def_f = f"({match_bw_raw_v_f.group(1)}kg)"

                    val_l3f_indiv_v_f = 0.0
                    m_l3f_p_v_f = re.search(r'(\d{2}\.\d)\s*\d{3}\(', str_line_v_step_f)
                    if m_l3f_p_v_f:
                        val_l3f_indiv_v_f = float(m_l3f_p_v_f.group(1))
                    else:
                        list_decimals_v_f = re.findall(r'(\d{2}\.\d)', str_line_v_step_f)
                        for dv_v_f in list_decimals_v_f:
                            dv_float_v_f = float(dv_v_f)
                            if 30.0 <= dv_float_v_f <= 46.0 and abs(dv_float_v_f - val_w_val_v_step_f) > 0.5:
                                val_l3f_indiv_v_f = dv_float_v_f; break
                    
                    if val_l3f_indiv_v_f == 0.0:
                        val_l3f_indiv_v_f = v65_final_manual_l3f

                    val_rel_ratio_f = val_l_pos_v_step_f / val_field_size_f_f
                    val_scale_f = val_field_size_f_f / 16.0
                    val_computed_load_score_f = 0.0
                    if var_pace_label_res_f == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and str_determined_bias_label_f != "å‰æœ‰åˆ©":
                        v_raw_load_calc = (0.6 - val_rel_ratio_f) * abs(var_pace_gap_res_f) * 3.0
                        val_computed_load_score_f = max(0.0, v_raw_load_calc) * val_scale_f
                    elif var_pace_label_res_f == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and str_determined_bias_label_f != "å¾Œæœ‰åˆ©":
                        v_raw_load_calc = (val_rel_ratio_f - 0.4) * abs(var_pace_gap_res_f) * 2.0
                        val_computed_load_score_f = max(0.0, v_raw_load_calc) * val_scale_f
                    
                    list_tags_f = []
                    flag_is_counter_f = False
                    
                    if val_r_rank_v_step_f <= 5:
                        if (str_determined_bias_label_f == "å‰æœ‰åˆ©" and val_l_pos_v_step_f >= 10.0) or (str_determined_bias_label_f == "å¾Œæœ‰åˆ©" and val_l_pos_v_step_f <= 3.0):
                            list_tags_f.append("ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if val_field_size_f_f >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ"); flag_is_counter_f = True
                    
                    if not ((var_pace_label_res_f == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and str_determined_bias_label_f == "å‰æœ‰åˆ©") or (var_pace_label_res_f == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and str_determined_bias_label_f == "å¾Œæœ‰åˆ©")):
                        if var_pace_label_res_f == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and val_l_pos_v_step_f <= 3.0 and val_r_rank_v_step_f <= 5: 
                            list_tags_f.append("ğŸ“‰ æ¿€æµè¢«å®³" if val_field_size_f_f >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ"); flag_is_counter_f = True
                        elif var_pace_label_res_f == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and val_l_pos_v_step_f >= 10.0 and (var_f3f_calc_res_f - val_l3f_indiv_v_f) > 1.5 and val_r_rank_v_step_f <= 5: 
                            list_tags_f.append("ğŸ”¥ å±•é–‹é€†è¡Œ"); flag_is_counter_f = True

                    val_l3f_gap_f = v65_final_manual_l3f - val_l3f_indiv_v_f
                    if val_l3f_gap_f >= 0.5: list_tags_f.append("ğŸš€ ã‚¢ã‚¬ãƒªå„ªç§€")
                    elif val_l3f_gap_f <= -1.0: list_tags_f.append("ğŸ“‰ å¤±é€Ÿå¤§")
                    
                    r_p1 = val_total_seconds_raw_v_f
                    r_p2 = (val_w_val_v_step_f - 56.0) * 0.1
                    r_p3 = val_in_trackidx_agg / 10.0
                    r_p4 = val_computed_load_score_f / 10.0
                    r_p5 = (val_in_week_num_agg - 1) * 0.05
                    r_p7 = (val_in_water4c_agg + val_in_watergoal_agg) / 2.0
                    r_p8 = (r_p7 - 10.0) * 0.05
                    r_p9 = (9.5 - val_in_cushion_agg) * 0.1
                    r_p10 = (v65_final_dist_m - 1600) * 0.0005
                    
                    val_final_rtc_v = r_p1 - r_p2 - r_p3 - r_p4 - r_p5 + val_in_bias_slider_agg - r_p8 - r_p9 + r_p10

                    str_field_tag_f = "å¤š" if val_field_size_f_f >= 16 else "å°‘" if val_field_size_f_f <= 10 else "ä¸­"
                    str_final_memo_f = f"ã€{var_pace_label_res_f}({v75_final_race_type})/{str_determined_bias_label_f}/è² è·:{val_computed_load_score_f:.1f}({str_field_tag_f})/å¹³ã€‘{'/'.join(list_tags_f) if list_tags_f else 'é †å¢ƒ'}"

                    list_new_sync_rows_tab1_v6_final.append({
                        "name": entry_save_m_f["name"], "base_rtc": val_final_rtc_v, 
                        "last_race": v65_final_race_name, "course": v65_final_course_name, "dist": v65_final_dist_m, 
                        "notes": f"{val_w_val_v_step_f}kg{str_horse_body_weight_f_def_f}", 
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"), "f3f": var_f3f_calc_res_f, 
                        "l3f": val_l3f_indiv_v_f, "race_l3f": v65_final_manual_l3f, 
                        "load": val_l_pos_v_step_f, "memo": str_final_memo_f,
                        "date": v65_final_race_date.strftime("%Y-%m-%d"), "cushion": val_in_cushion_agg, 
                        "water": r_p7, "next_buy_flag": "â˜…é€†è¡Œç‹™ã„" if flag_is_counter_f else "", 
                        "result_pos": val_r_rank_v_step_f, "track_week": val_in_week_num_agg,
                        "race_type": v75_final_race_type,
                        "track_kind": v80_final_track_kind,
                        "raw_time": val_total_seconds_raw_v_f,
                        "track_idx": val_in_trackidx_agg,
                        "bias_slider": val_in_bias_slider_agg
                    })
                
                if list_new_sync_rows_tab1_v6_final:
                    st.cache_data.clear()
                    df_sheet_latest_v = conn.read(ttl=0)
                    for col_norm_f in ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL:
                        if col_norm_f not in df_sheet_latest_v.columns: df_sheet_latest_v[col_norm_f] = None
                    df_final_sync_v = pd.concat([df_sheet_latest_v, pd.DataFrame(list_new_sync_rows_tab1_v6_final)], ignore_index=True)
                    if safe_update(df_final_sync_v):
                        st.session_state.state_tab1_preview_is_active_f = False
                        st.success(f"âœ… è§£æãƒ»åŒæœŸä¿å­˜ãŒç‰©ç†çš„ã«å®Œäº†ã—ã¾ã—ãŸã€‚"); st.rerun()

# ==============================================================================
# 8. Tab 2: é¦¬åˆ¥å±¥æ­´è©³ç´° & å€‹åˆ¥ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
# ==============================================================================

with tab_horse_history:
    st.header("ğŸ“Š é¦¬åˆ¥å±¥æ­´ & è²·ã„æ¡ä»¶è©³ç´°ç‰©ç†ç®¡ç†ã‚¨ãƒ³ã‚¸ãƒ³")
    df_t2_source_v6 = get_db_data()
    if not df_t2_source_v6.empty:
        col_t2_f1, col_t2_f2 = st.columns([1, 1])
        with col_t2_f1:
            input_horse_search_q_v6 = st.text_input("é¦¬åç‰©ç†çµã‚Šè¾¼ã¿æ¤œç´¢", key="q_h_t2_v6")
        
        list_h_names_t2_pool = sorted([str(xn) for xn in df_t2_source_v6['name'].dropna().unique()])
        with col_t2_f2:
            val_sel_target_h_t2_v6 = st.selectbox("å€‹åˆ¥é¦¬å®Ÿç¸¾ã®ç‰©ç†ä¿®æ­£å¯¾è±¡é¦¬ã‚’é¸æŠ", ["æœªé¸æŠ"] + list_h_names_t2_pool)
        
        if val_sel_target_h_t2_v6 != "æœªé¸æŠ":
            idx_list_t2_found = df_t2_source_v6[df_t2_source_v6['name'] == val_sel_target_h_t2_v6].index
            target_idx_t2_f_actual = idx_list_t2_found[-1]
            
            with st.form("form_edit_h_t2_v6_agg"):
                val_memo_t2_v6_cur = df_t2_source_v6.at[target_idx_t2_f_actual, 'memo'] if not pd.isna(df_t2_source_v6.at[target_idx_t2_f_actual, 'memo']) else ""
                new_memo_t2_v6_val = st.text_area("è§£æè©•ä¾¡ãƒ¡ãƒ¢ã®è©³ç´°ç‰©ç†ä¿®æ­£", value=val_memo_t2_v6_cur)
                val_flag_t2_v6_cur = df_t2_source_v6.at[target_idx_t2_f_actual, 'next_buy_flag'] if not pd.isna(df_t2_source_v6.at[target_idx_t2_f_actual, 'next_buy_flag']) else ""
                new_flag_t2_v6_val = st.text_input("æ¬¡èµ°å€‹åˆ¥è²·ã„ãƒ•ãƒ©ã‚°ç‰©ç†è¨­å®š", value=val_flag_t2_v6_cur)
                
                val_kind_t2_v6_cur = str(df_t2_source_v6.at[target_idx_t2_f_actual, 'track_kind']) if not pd.isna(df_t2_source_v6.at[target_idx_t2_f_actual, 'track_kind']) else "èŠ"
                if val_kind_t2_v6_cur not in ["èŠ", "ãƒ€ãƒ¼ãƒˆ"]: val_kind_t2_v6_cur = "èŠ"
                new_kind_t2_v6_val = st.selectbox("ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥ç‰©ç†è¨­å®š (èŠ/ãƒ€ãƒ¼ãƒˆ)", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], index=0 if val_kind_t2_v6_cur == "èŠ" else 1)
                
                if st.form_submit_button("åŒæœŸä¿å­˜å®Ÿè¡Œ"):
                    df_t2_source_v6.at[target_idx_t2_f_actual, 'memo'] = new_memo_t2_v6_val
                    df_t2_source_v6.at[target_idx_t2_f_actual, 'next_buy_flag'] = new_flag_t2_v6_val
                    df_t2_source_v6.at[target_idx_t2_f_actual, 'track_kind'] = new_kind_t2_v6_val
                    if safe_update(df_t2_source_v6):
                        st.success(f"ã€{val_sel_target_h_t2_v6}ã€‘åŒæœŸæˆåŠŸ"); st.rerun()

        # ==============================================================================
        # ã€æ©Ÿèƒ½3ã€‘RTCæ¨ç§»åˆ†æ / ãƒ”ãƒ¼ã‚¯æ™‚æœŸäºˆæ¸¬ / è·é›¢é©æ€§ãƒ†ãƒ¼ãƒ–ãƒ«
        # ==============================================================================
        st.divider()
        st.subheader(f"ğŸ“ˆ {val_sel_target_h_t2_v6} èƒ½åŠ›æ¨ç§»è©³ç´°åˆ†æ")

        df_trend_target = df_t2_source_v6[df_t2_source_v6['name'] == val_sel_target_h_t2_v6].sort_values("date")
        df_trend_valid = df_trend_target[(df_trend_target['base_rtc'] > 0) & (df_trend_target['base_rtc'] < 999)].copy()

        if not df_trend_valid.empty:
            # è·é›¢æ­£è¦åŒ–RTCï¼ˆç•°ãªã‚‹è·é›¢ã®ãƒ¬ãƒ¼ã‚¹ã‚’1600måŸºæº–ã§æ¯”è¼ƒå¯èƒ½ã«ã™ã‚‹ï¼‰
            df_trend_valid['norm_rtc'] = df_trend_valid.apply(
                lambda r: r['base_rtc'] / r['dist'] * 1600 if r['dist'] > 0 else r['base_rtc'], axis=1
            )
            df_trend_valid['date_str'] = df_trend_valid['date'].apply(
                lambda x: x.strftime('%Y-%m-%d') if not pd.isna(x) else ""
            )
            chart_df_trend = df_trend_valid[df_trend_valid['date_str'] != ""][['date_str', 'norm_rtc']].set_index('date_str')
            st.caption("æ­£è¦åŒ–RTCæ¨ç§»ï¼ˆ1600mæ›ç®—ãƒ»ä½ã„ã»ã©é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ï¼‰")
            st.line_chart(chart_df_trend, use_container_width=True)

            # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ãƒ™ãƒ«åˆ¤å®šï¼ˆç›´è¿‘3èµ°ï¼‰
            recent3_norm = df_trend_valid['norm_rtc'].tail(3).tolist()
            if len(recent3_norm) >= 3:
                if recent3_norm[0] > recent3_norm[1] > recent3_norm[2]:
                    trend_result_label = "ğŸ”¼ä¸Šæ˜‡ä¸­ï¼ˆç›´è¿‘3èµ°ã§ç¶™ç¶šçš„ã«ã‚¿ã‚¤ãƒ çŸ­ç¸®ï¼‰"
                elif recent3_norm[0] < recent3_norm[1] < recent3_norm[2]:
                    trend_result_label = "ğŸ”½ä¸‹é™ä¸­ï¼ˆç›´è¿‘3èµ°ã§ç¶™ç¶šçš„ã«ã‚¿ã‚¤ãƒ æ‚ªåŒ–ï¼‰"
                else:
                    trend_result_label = "â¡ï¸æ¨ªã°ã„ï¼ˆç›´è¿‘3èµ°ã§ä¸Šä¸‹å‹•ã‚ã‚Šï¼‰"
            elif len(recent3_norm) == 2:
                if recent3_norm[0] > recent3_norm[1]:
                    trend_result_label = "ğŸ”¼ä¸Šæ˜‡ï¼ˆ2èµ°ã§æ¯”è¼ƒï¼‰"
                elif recent3_norm[0] < recent3_norm[1]:
                    trend_result_label = "ğŸ”½ä¸‹é™ï¼ˆ2èµ°ã§æ¯”è¼ƒï¼‰"
                else:
                    trend_result_label = "â¡ï¸å¤‰åŒ–ãªã—"
            else:
                trend_result_label = "ãƒ‡ãƒ¼ã‚¿ä¸è¶³"

            st.metric("ğŸ“Š RTCãƒˆãƒ¬ãƒ³ãƒ‰", trend_result_label)

            # è·é›¢åˆ¥é©æ€§ãƒ†ãƒ¼ãƒ–ãƒ«
            st.markdown("##### ğŸ‡ è·é›¢å¸¯åˆ¥é©æ€§")
            dist_range_defs = [
                ("çŸ­è·é›¢ (~1400m)", 0, 1400),
                ("ãƒã‚¤ãƒ« (1401~1800m)", 1401, 1800),
                ("ä¸­è·é›¢ (1801~2200m)", 1801, 2200),
                ("é•·è·é›¢ (2201m~)", 2201, 99999),
            ]
            dist_apt_rows = []
            for d_label, d_min, d_max in dist_range_defs:
                df_d_sub = df_trend_target[(df_trend_target['dist'] >= d_min) & (df_trend_target['dist'] <= d_max)].copy()
                if df_d_sub.empty:
                    continue
                n_d = len(df_d_sub)
                n_top3_d = len(df_d_sub[df_d_sub['result_pos'] <= 3]) if df_d_sub['result_pos'].sum() > 0 else 0
                valid_rtc_d = df_d_sub[(df_d_sub['base_rtc'] > 0) & (df_d_sub['base_rtc'] < 999)]
                if valid_rtc_d.empty:
                    continue
                avg_norm_d = (valid_rtc_d['base_rtc'] / valid_rtc_d['dist'] * 1600).mean()
                dist_apt_rows.append({
                    "è·é›¢å¸¯": d_label,
                    "èµ°æ•°": n_d,
                    "è¤‡å‹ç‡": f"{n_top3_d / n_d * 100:.0f}%" if n_d > 0 else "-",
                    "å¹³å‡æ­£è¦åŒ–RTC": f"{avg_norm_d:.2f}ç§’",
                    "åˆ¤å®š": "ğŸ”¥å¾—æ„" if (n_top3_d / n_d >= 0.4 and n_d >= 2) else "âŒè‹¦æ‰‹" if (n_top3_d / n_d < 0.2 and n_d >= 3) else "æ™®é€š",
                })
            if dist_apt_rows:
                st.dataframe(pd.DataFrame(dist_apt_rows), use_container_width=True, hide_index=True)
            else:
                st.caption("è·é›¢åˆ¥ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰")
        else:
            st.info("æœ‰åŠ¹ãªRTCãƒ‡ãƒ¼ã‚¿ãŒãªã„ãŸã‚æ¨ç§»åˆ†æã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")

        df_t2_filtered_v6 = df_t2_source_v6[df_t2_source_v6['name'].str.contains(input_horse_search_q_v6, na=False)] if input_horse_search_q_v6 else df_t2_source_v6
        df_t2_final_view_f_v6 = df_t2_filtered_v6.copy()
        
        df_t2_final_view_f_v6['date'] = df_t2_final_view_f_v6['date'].apply(lambda x: x.strftime('%Y-%m-%d') if not pd.isna(x) else "")
        df_t2_final_view_f_v6['base_rtc'] = df_t2_final_view_f_v6['base_rtc'].apply(format_time_to_hmsf_string)
        st.dataframe(
            df_t2_final_view_f_v6.sort_values("date", ascending=False)[["date", "name", "last_race", "track_kind", "track_week", "race_type", "base_rtc", "f3f", "l3f", "race_l3f", "load", "memo", "next_buy_flag"]], 
            use_container_width=True
        )

# ==============================================================================
# 9. Tab 3: ãƒ¬ãƒ¼ã‚¹å®Ÿç¸¾ç‰©ç†ç®¡ç†
# ==============================================================================

with tab_race_history:
    st.header("ğŸ ç­”ãˆåˆã‚ã›è©³ç´°ç®¡ç†")
    df_t3_f = get_db_data()
    if not df_t3_f.empty:
        list_r_all_v = sorted([str(x) for x in df_t3_f['last_race'].dropna().unique()])
        sel_r_v = st.selectbox("å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", list_r_all_v)
        if sel_r_v:
            df_sub_v = df_t3_f[df_t3_f['last_race'] == sel_r_v].copy()
            with st.form("form_race_res_t3_f"):
                for i_v, row_v in df_sub_v.iterrows():
                    c_grid_1, c_grid_2, c_grid_3 = st.columns(3)
                    with c_grid_1:
                        val_pos_safe = 0
                        if not pd.isna(row_v['result_pos']):
                            try: val_pos_safe = int(row_v['result_pos'])
                            except: val_pos_safe = 0
                        df_sub_v.at[i_v, 'result_pos'] = st.number_input(f"{row_v['name']} ç€é †", 0, 100, val_pos_safe, key=f"p_t3_{i_v}")
                    with c_grid_2:
                        val_pop_safe = 0
                        if not pd.isna(row_v['result_pop']):
                            try: val_pop_safe = int(row_v['result_pop'])
                            except: val_pop_safe = 0
                        df_sub_v.at[i_v, 'result_pop'] = st.number_input(f"{row_v['name']} äººæ°—", 0, 100, val_pop_safe, key=f"pop_t3_{i_v}")
                    with c_grid_3:
                        val_kind_safe = str(row_v.get('track_kind', 'èŠ'))
                        if val_kind_safe not in ["èŠ", "ãƒ€ãƒ¼ãƒˆ"]: val_kind_safe = "èŠ"
                        df_sub_v.at[i_v, 'track_kind'] = st.selectbox(f"{row_v['name']} èŠ/ãƒ€ãƒ¼ãƒˆ", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], index=0 if val_kind_safe == "èŠ" else 1, key=f"k_t3_{i_v}")
                        
                if st.form_submit_button("åŒæœŸä¿å­˜"):
                    for i_v, row_v in df_sub_v.iterrows(): 
                        df_t3_f.at[i_v, 'result_pos'] = row_v['result_pos']
                        df_t3_f.at[i_v, 'result_pop'] = row_v['result_pop']
                        df_t3_f.at[i_v, 'track_kind'] = row_v['track_kind']
                    if safe_update(df_t3_f): st.success("åŒæœŸå®Œäº†"); st.rerun()
            df_t3_fmt = df_sub_v.copy()
            df_t3_fmt['base_rtc'] = df_t3_fmt['base_rtc'].apply(format_time_to_hmsf_string)
            st.dataframe(df_t3_fmt[["name", "notes", "track_kind", "track_week", "race_type", "base_rtc", "f3f", "l3f", "race_l3f", "result_pos", "result_pop"]], use_container_width=True)

# ==============================================================================
# 10. Tab 4: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼è©³ç´°å·¥ç¨‹ (v10.0 ç©¶æ¥µæ–°æ©Ÿèƒ½æ­è¼‰ç‰ˆ)
# ==============================================================================

with tab_simulator:
    st.header("ğŸ¯ æ¬¡èµ°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼è©³ç´°ç‰©ç†è¨ˆç®—ã‚¨ãƒ³ã‚¸ãƒ³")
    df_t4_f = get_db_data()
    if not df_t4_f.empty:
        list_h_names_v = sorted([str(x) for x in df_t4_f['name'].dropna().unique()])
        sel_multi_h = st.multiselect("å¯¾è±¡é¦¬ã‚’ç‰©ç†é¸æŠ", list_h_names_v)
        sim_w_map = {}
        sim_g_map = {}
        sim_p_map = {}
        
        if sel_multi_h:
            st.markdown("##### ğŸ“ å€‹åˆ¥ç‰©ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å…¥åŠ›")
            grid_sim = st.columns(min(len(sel_multi_h), 4))
            for i_h, h_i in enumerate(sel_multi_h):
                with grid_sim[i_h % 4]:
                    h_lat_data = df_t4_f[df_t4_f['name'] == h_i].iloc[-1]
                    sim_g_map[h_i] = st.number_input(f"{h_i} æ ", 1, 18, value=1, key=f"g_sim_{h_i}")
                    
                    val_raw_pop_sim_f = 10
                    if not pd.isna(h_lat_data['result_pop']):
                        try: val_raw_pop_sim_f = int(h_lat_data['result_pop'])
                        except: val_raw_pop_sim_f = 10
                    val_safe_pop_sim_f = val_raw_pop_sim_f
                    if val_safe_pop_sim_f < 1: val_safe_pop_sim_f = 1
                    if val_safe_pop_sim_f > 18: val_safe_pop_sim_f = 18
                        
                    sim_p_map[h_i] = st.number_input(f"{h_i} äººæ°—", 1, 18, value=val_safe_pop_sim_f, key=f"p_sim_{h_i}")
                    sim_w_map[h_i] = st.number_input(f"{h_i} æ–¤é‡", 48.0, 62.0, 56.0, step=0.5, key=f"w_sim_{h_i}")
            
            c_sc_1, c_sc_2 = st.columns(2)
            with c_sc_1:
                val_sim_course = st.selectbox("æ¬¡èµ°ç«¶é¦¬å ´", list(MASTER_CONFIG_V65_TURF_LOAD_COEFFS.keys()))
                val_sim_dist = st.selectbox("æ¬¡èµ°è·é›¢", list_dist_range_opts_actual_f if 'list_dist_range_opts_actual_f' in locals() else [1600], index=0)
                opt_sim_track = st.radio("æ¬¡èµ°ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
                val_sim_race_name = st.text_input("æ¬¡èµ°ãƒ¬ãƒ¼ã‚¹åï¼ˆä»»æ„ãƒ»åŒä¸€ãƒ¬ãƒ¼ã‚¹æ­´ã‚’æ¤œç´¢ï¼‰", value="", placeholder="ä¾‹: å¤©çš‡è³ç§‹ã€æœ‰é¦¬è¨˜å¿µ")
            with c_sc_2:
                val_sim_cush = st.slider("æƒ³å®šã‚¯ãƒƒã‚·ãƒ§ãƒ³", 7.0, 12.0, 9.5)
                val_sim_water = st.slider("æƒ³å®šå«æ°´ç‡", 0.0, 30.0, 10.0)

            if st.button("ğŸ ç‰©ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
                list_res_v = []
                num_sim_total = len(sel_multi_h)
                
                dict_styles = {"é€ƒã’": 0, "å…ˆè¡Œ": 0, "å·®ã—": 0, "è¿½è¾¼": 0}
                dict_race_types_v75 = {"ç¬ç™ºåŠ›": 0, "æŒç¶šåŠ›": 0, "è‡ªåœ¨": 0}
                dict_horse_pref_type_v75 = {}

                for h_n_v in sel_multi_h:
                    df_h_temp = df_t4_f[df_t4_f['name'] == h_n_v].sort_values("date")
                    df_l3_temp = df_h_temp.tail(3)
                    
                    val_avg_load_3r = df_l3_temp['load'].mean()
                    if val_avg_load_3r <= 3.5: style_l = "é€ƒã’"
                    elif val_avg_load_3r <= 7.0: style_l = "å…ˆè¡Œ"
                    elif val_avg_load_3r <= 11.0: style_l = "å·®ã—"
                    else: style_l = "è¿½è¾¼"
                    dict_styles[style_l] += 1
                    
                    val_count_shunpatsu_v75 = 0
                    val_count_jizoku_v75 = 0
                    for idx_p, row_p in df_h_temp.iterrows():
                        if row_p['result_pos'] <= 5:
                            if row_p['race_type'] == "ç¬ç™ºåŠ›æˆ¦": val_count_shunpatsu_v75 += 1
                            elif row_p['race_type'] == "æŒç¶šåŠ›æˆ¦": val_count_jizoku_v75 += 1
                    
                    str_pref_race_type_v75 = "è‡ªåœ¨"
                    if val_count_shunpatsu_v75 > val_count_jizoku_v75: str_pref_race_type_v75 = "ç¬ç™ºåŠ›"
                    elif val_count_jizoku_v75 > val_count_shunpatsu_v75: str_pref_race_type_v75 = "æŒç¶šåŠ›"
                    
                    dict_horse_pref_type_v75[h_n_v] = str_pref_race_type_v75
                    dict_race_types_v75[str_pref_race_type_v75] += 1

                str_sim_pace = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                if dict_styles["é€ƒã’"] >= 2 or (dict_styles["é€ƒã’"] + dict_styles["å…ˆè¡Œ"]) >= num_sim_total * 0.6:
                    str_sim_pace = "ãƒã‚¤ãƒšãƒ¼ã‚¹å‚¾å‘"
                elif dict_styles["é€ƒã’"] == 0 and dict_styles["å…ˆè¡Œ"] <= 1:
                    str_sim_pace = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹å‚¾å‘"
                    
                str_sim_race_type_forecast_v75 = "ç¬ç™ºåŠ›æˆ¦"
                if dict_race_types_v75["æŒç¶šåŠ›"] > dict_race_types_v75["ç¬ç™ºåŠ›"]:
                    str_sim_race_type_forecast_v75 = "æŒç¶šåŠ›æˆ¦"

                for h_n_v in sel_multi_h:
                    df_h_v = df_t4_f[df_t4_f['name'] == h_n_v].sort_values("date")
                    df_l3_v = df_h_v.tail(3); list_conv_rtc_v = []
                    
                    val_avg_load_3r = df_l3_v['load'].mean()
                    if val_avg_load_3r <= 3.5: style_l = "é€ƒã’"
                    elif val_avg_load_3r <= 7.0: style_l = "å…ˆè¡Œ"
                    elif val_avg_load_3r <= 11.0: style_l = "å·®ã—"
                    else: style_l = "è¿½è¾¼"
                    
                    jam_label = "âš ï¸è©°ã¾ã‚Šæ³¨æ„" if num_sim_total >= 15 and style_l in ["å·®ã—", "è¿½è¾¼"] and sim_g_map[h_n_v] <= 4 else "-"
                    
                    flag_is_cross_surface = False
                    str_cross_label = ""

                    for idx_r, row_r in df_l3_v.iterrows():
                        p_w_v = 56.0
                        wm_v = re.search(r'([4-6]\d\.\d)', str(row_r['notes']))
                        if wm_v: p_w_v = float(wm_v.group(1))
                        
                        v_h_bw = 480.0
                        match_bw = re.search(r'\((\d{3})kg\)', str(row_r['notes']))
                        if match_bw: v_h_bw = float(match_bw.group(1))
                        
                        sens_v = 0.15 if v_h_bw <= 440 else 0.08 if v_h_bw >= 500 else 0.1
                        w_diff_v = (sim_w_map[h_n_v] - p_w_v) * sens_v
                        
                        v_p_v_l_adj = (row_r['load'] - 7.0) * 0.02
                        v_step1 = (row_r['base_rtc'] + v_p_v_l_adj + w_diff_v)
                        v_step2 = v_step1 / row_r['dist'] if row_r['dist'] > 0 else v_step1 / 1600.0
                        v_step_rtc = v_step2 * val_sim_dist
                        p_v_s_adj = (MASTER_CONFIG_V65_GRADIENT_FACTORS.get(val_sim_course, 0.002) - MASTER_CONFIG_V65_GRADIENT_FACTORS.get(row_r['course'], 0.002)) * val_sim_dist
                        
                        past_track_kind = str(row_r.get('track_kind', 'èŠ'))
                        if pd.isna(past_track_kind) or past_track_kind == 'nan':
                            past_track_kind = 'èŠ'
                            
                        cross_penalty_v = 0.0
                        if past_track_kind == "èŠ" and opt_sim_track == "ãƒ€ãƒ¼ãƒˆ":
                            cross_penalty_v = 3.5 * (val_sim_dist / 1600.0)
                            flag_is_cross_surface = True
                            str_cross_label = "ğŸ”„åˆãƒ€"
                        elif past_track_kind == "ãƒ€ãƒ¼ãƒˆ" and opt_sim_track == "èŠ":
                            cross_penalty_v = -3.5 * (val_sim_dist / 1600.0)
                            flag_is_cross_surface = True
                            str_cross_label = "ğŸ”„åˆèŠ"
                        
                        list_conv_rtc_v.append(v_step_rtc + p_v_s_adj + cross_penalty_v)
                        
                    # ã€æ©Ÿèƒ½3ã€‘ãƒˆãƒªãƒ å¹³å‡: 5èµ°ä»¥ä¸Šã¯æœ€é«˜ãƒ»æœ€ä½ã‚’1ã¤ãšã¤é™¤å¤–ã€3ã€œ4èµ°ã¯ä¸­å¤®å€¤ã€1ã€œ2èµ°ã¯å˜ç´”å¹³å‡
                    if len(list_conv_rtc_v) >= 5:
                        sorted_rtc = sorted(list_conv_rtc_v)
                        trimmed_rtc = sorted_rtc[1:-1]
                        val_avg_rtc_res = sum(trimmed_rtc) / len(trimmed_rtc)
                    elif len(list_conv_rtc_v) >= 3:
                        sorted_rtc = sorted(list_conv_rtc_v)
                        mid = len(sorted_rtc) // 2
                        val_avg_rtc_res = sorted_rtc[mid]
                    elif list_conv_rtc_v:
                        val_avg_rtc_res = sum(list_conv_rtc_v) / len(list_conv_rtc_v)
                    else:
                        val_avg_rtc_res = 0

                    c_dict_v = MASTER_CONFIG_V65_DIRT_LOAD_COEFFS if opt_sim_track == "ãƒ€ãƒ¼ãƒˆ" else MASTER_CONFIG_V65_TURF_LOAD_COEFFS
                    final_rtc_v = val_avg_rtc_res + (c_dict_v.get(val_sim_course, 0.20) * (val_sim_dist/1600.0)) - (9.5 - val_sim_cush) * 0.1
                    
                    course_aptitude_bonus_v9 = 0.0
                    aptitude_label_v9 = "åˆã‚³ãƒ¼ã‚¹"
                    
                    df_same_course_v9 = df_h_v[df_h_v['course'] == val_sim_course]
                    
                    if not df_same_course_v9.empty and len(df_h_v) > 0:
                        list_all_rtc_v9 = []
                        for idx_all, r_all in df_h_v.iterrows():
                            if 0.0 < r_all['base_rtc'] < 300.0: 
                                v_rtc_all = r_all['base_rtc'] / r_all['dist'] if r_all['dist'] > 0 else r_all['base_rtc'] / 1600.0
                                list_all_rtc_v9.append(v_rtc_all * val_sim_dist)
                        avg_all_rtc_v9 = sum(list_all_rtc_v9) / len(list_all_rtc_v9) if list_all_rtc_v9 else 0.0
                        
                        list_same_course_rtc_v9 = []
                        for idx_same, r_same in df_same_course_v9.iterrows():
                            if 0.0 < r_same['base_rtc'] < 300.0:
                                v_rtc_same = r_same['base_rtc'] / r_same['dist'] if r_same['dist'] > 0 else r_same['base_rtc'] / 1600.0
                                list_same_course_rtc_v9.append(v_rtc_same * val_sim_dist)
                        avg_same_course_rtc_v9 = sum(list_same_course_rtc_v9) / len(list_same_course_rtc_v9) if list_same_course_rtc_v9 else 0.0
                        
                        if avg_all_rtc_v9 > 0.0 and avg_same_course_rtc_v9 > 0.0:
                            aptitude_diff_v9 = avg_same_course_rtc_v9 - avg_all_rtc_v9
                            course_aptitude_bonus_v9 = aptitude_diff_v9 * 0.5
                            
                            if aptitude_diff_v9 <= -0.5:
                                aptitude_label_v9 = "ğŸ”¥ã‚³ãƒ¼ã‚¹é¬¼"
                            elif aptitude_diff_v9 <= -0.1:
                                aptitude_label_v9 = "â­•é©æ€§ã‚ã‚Š"
                            elif aptitude_diff_v9 >= 0.5:
                                aptitude_label_v9 = "âŒã‚³ãƒ¼ã‚¹è‹¦æ‰‹"
                            else:
                                aptitude_label_v9 = "æ™®é€š"
                                
                    # ğŸŒŸ ã€æ–°æ©Ÿèƒ½1 & 2ã€‘å®‰å®šåº¦æŒ‡æ•°ï¼ˆRTCåå·®ï¼‰ã¨ L3Fä¹–é›¢è§£æï¼ˆé¬¼è„šåˆ¤å®šï¼‰
                    list_all_rtc_std_v10 = []
                    list_burst_scores_v10 = []
                    
                    for idx_all, r_all in df_h_v.iterrows():
                        if 0.0 < r_all['base_rtc'] < 300.0:
                            v_rtc_all_std = r_all['base_rtc'] / r_all['dist'] if r_all['dist'] > 0 else r_all['base_rtc'] / 1600.0
                            list_all_rtc_std_v10.append(v_rtc_all_std * val_sim_dist)
                        
                        if r_all['race_l3f'] > 0.0 and r_all['l3f'] > 0.0:
                            val_l3f_diff_v10 = r_all['race_l3f'] - r_all['l3f']
                            val_burst_score_v10 = val_l3f_diff_v10 * (r_all['load'] / 10.0)
                            list_burst_scores_v10.append(val_burst_score_v10)

                    val_std_rtc_v10 = pd.Series(list_all_rtc_std_v10).std() if len(list_all_rtc_std_v10) > 1 else 0.0
                    label_consistency_v10 = "æ™®é€š"
                    if pd.isna(val_std_rtc_v10) or val_std_rtc_v10 == 0.0:
                        label_consistency_v10 = "åˆ¤å®šä¸èƒ½"
                    elif val_std_rtc_v10 <= 0.5:
                        label_consistency_v10 = "ğŸ›¡ï¸å®‰å®š(è»¸å‘)"
                    elif val_std_rtc_v10 >= 1.5:
                        label_consistency_v10 = "ğŸ²ãƒ ãƒ©(ç©´å‘)"

                    val_avg_burst_v10 = sum(list_burst_scores_v10) / len(list_burst_scores_v10) if list_burst_scores_v10 else 0.0
                    label_burst_v10 = "-"
                    if val_avg_burst_v10 >= 0.5:
                        label_burst_v10 = "ğŸš€æ¥µé™é¬¼è„š"
                    elif val_avg_burst_v10 >= 0.2:
                        label_burst_v10 = "ğŸ’¨é‹­ã„è„š"

                    # ==============================================================================
                    # ã€æ©Ÿèƒ½7ã€‘ãƒšãƒ¼ã‚¹é©æ€§ã‚¹ã‚³ã‚¢ï¼šéå»ãƒ¬ãƒ¼ã‚¹ã®ãƒšãƒ¼ã‚¹åˆ¥ãƒ»å±•é–‹åˆ¥æˆç¸¾ã‹ã‚‰ç®—å‡º
                    # ==============================================================================
                    dict_pace_hit_v10 = {"ãƒã‚¤ãƒšãƒ¼ã‚¹": [], "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹": [], "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹": []}
                    dict_racetype_hit_v10 = {"ç¬ç™ºåŠ›æˆ¦": [], "æŒç¶šåŠ›æˆ¦": []}

                    for idx_pa, row_pa in df_h_v.iterrows():
                        memo_pa = str(row_pa.get('memo', ''))
                        pos_pa = row_pa.get('result_pos', 0)
                        if pd.isna(pos_pa) or pos_pa <= 0:
                            continue
                        hit_pa = 1 if float(pos_pa) <= 3 else 0
                        if 'ãƒã‚¤' in memo_pa:
                            dict_pace_hit_v10["ãƒã‚¤ãƒšãƒ¼ã‚¹"].append(hit_pa)
                        elif 'ã‚¹ãƒ­ãƒ¼' in memo_pa:
                            dict_pace_hit_v10["ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"].append(hit_pa)
                        else:
                            dict_pace_hit_v10["ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"].append(hit_pa)
                        race_type_pa = str(row_pa.get('race_type', ''))
                        if race_type_pa == "ç¬ç™ºåŠ›æˆ¦":
                            dict_racetype_hit_v10["ç¬ç™ºåŠ›æˆ¦"].append(hit_pa)
                        elif race_type_pa == "æŒç¶šåŠ›æˆ¦":
                            dict_racetype_hit_v10["æŒç¶šåŠ›æˆ¦"].append(hit_pa)

                    if "ãƒã‚¤" in str_sim_pace:
                        sim_target_pace_key = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                    elif "ã‚¹ãƒ­ãƒ¼" in str_sim_pace:
                        sim_target_pace_key = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                    else:
                        sim_target_pace_key = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"

                    pace_samples = dict_pace_hit_v10[sim_target_pace_key]
                    if pace_samples:
                        pace_hit_rate_v10 = sum(pace_samples) / len(pace_samples)
                        n_pace = len(pace_samples)
                        if pace_hit_rate_v10 >= 0.5 and n_pace >= 2:
                            label_pace_apt_v10 = f"ğŸ”¥{sim_target_pace_key}å¾—æ„({int(pace_hit_rate_v10*100)}%/{n_pace}èµ°)"
                        elif pace_hit_rate_v10 >= 0.3:
                            label_pace_apt_v10 = f"â­•é©æ€§ã‚ã‚Š({int(pace_hit_rate_v10*100)}%/{n_pace}èµ°)"
                        elif n_pace >= 3:
                            label_pace_apt_v10 = f"âŒè‹¦æ‰‹({int(pace_hit_rate_v10*100)}%/{n_pace}èµ°)"
                        else:
                            label_pace_apt_v10 = f"å‚è€ƒ({n_pace}èµ°ã®ã¿)"
                    else:
                        label_pace_apt_v10 = "å®Ÿç¸¾ãªã—"

                    # å±•é–‹ã‚¿ã‚¤ãƒ—é©æ€§ã‚‚ç¢ºèªã—ã¦ã‚·ãƒŠã‚¸ãƒ¼è£œæ­£ã«åŠ ãˆã‚‹
                    if str_sim_race_type_forecast_v75 == "ç¬ç™ºåŠ›æˆ¦":
                        rt_samples = dict_racetype_hit_v10["ç¬ç™ºåŠ›æˆ¦"]
                    else:
                        rt_samples = dict_racetype_hit_v10["æŒç¶šåŠ›æˆ¦"]
                    if rt_samples:
                        rt_hit_rate_v10 = sum(rt_samples) / len(rt_samples)
                        rt_label_part = f"/{str_sim_race_type_forecast_v75}:{int(rt_hit_rate_v10*100)}%"
                        label_pace_apt_v10 += rt_label_part

                    # ==============================================================================
                    # ã€åŒä¸€ãƒ¬ãƒ¼ã‚¹éå»æ­´ã€‘å…¥åŠ›ã—ãŸãƒ¬ãƒ¼ã‚¹åã§é¦¬ã®éå»æˆç¸¾ã‚’æ¤œç´¢
                    # ==============================================================================
                    label_same_race_hist = "-"
                    if val_sim_race_name.strip():
                        # éƒ¨åˆ†ä¸€è‡´ã§åŒåãƒ¬ãƒ¼ã‚¹ã®éå»å‡ºèµ°ã‚’æ¤œç´¢
                        df_same_race_h = df_h_v[df_h_v['last_race'].str.contains(
                            val_sim_race_name.strip(), na=False, case=False
                        )].sort_values("date")

                        if not df_same_race_h.empty:
                            n_same = len(df_same_race_h)
                            # çµæœãŒå…¥åŠ›ã•ã‚Œã¦ã„ã‚‹è¡Œã®ã¿ã§é›†è¨ˆ
                            df_same_with_res = df_same_race_h[df_same_race_h['result_pos'] > 0]
                            if not df_same_with_res.empty:
                                best_pos = int(df_same_with_res['result_pos'].min())
                                avg_pos = df_same_with_res['result_pos'].mean()
                                n_top3 = len(df_same_with_res[df_same_with_res['result_pos'] <= 3])
                                # æœ€æ–°å‡ºèµ°æ™‚ã®RTCï¼ˆ1600mæ­£è¦åŒ–ï¼‰
                                last_same = df_same_race_h.iloc[-1]
                                last_same_date = last_same['date']
                                last_date_str = last_same_date.strftime('%Y/%m/%d') if not pd.isna(last_same_date) else "æ—¥ä»˜ä¸æ˜"
                                if best_pos == 1:
                                    result_icon = "ğŸ¥‡"
                                elif best_pos <= 3:
                                    result_icon = "ğŸ¥ˆ"
                                elif best_pos <= 5:
                                    result_icon = "âœ…"
                                else:
                                    result_icon = "ğŸ“‹"
                                label_same_race_hist = f"{result_icon}{n_same}èµ°/æœ€é«˜{best_pos}ç€/è¤‡å‹{n_top3}/{len(df_same_with_res)}å›({last_date_str})"
                            else:
                                # å‡ºèµ°æ­´ã¯ã‚ã‚‹ãŒç€é †æœªå…¥åŠ›
                                label_same_race_hist = f"ğŸ“‹å‡ºèµ°æ­´{n_same}å›ï¼ˆç€é †æœªå…¥åŠ›ï¼‰"
                        else:
                            label_same_race_hist = "åˆå‡ºèµ°"

                    # ==============================================================================
                    # RTCä¸Šæ˜‡ãƒ»ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®šï¼ˆç›´è¿‘3èµ°ã®æ­£è¦åŒ–RTCãŒå˜èª¿æ”¹å–„ã‹æ‚ªåŒ–ã‹ã‚’åˆ¤å®šï¼‰
                    # compute_synergyã§ã®å¾®å°è£œæ­£ã«ä½¿ç”¨ã™ã‚‹
                    # ==============================================================================
                    rtc_trend_val = "æ¨ªã°ã„"
                    valid_rtc_trend = df_h_v[(df_h_v['base_rtc'] > 0) & (df_h_v['base_rtc'] < 999)].tail(3)
                    if len(valid_rtc_trend) >= 3:
                        trend_norm_vals = []
                        for _, r_tr in valid_rtc_trend.iterrows():
                            if r_tr['dist'] > 0:
                                trend_norm_vals.append(r_tr['base_rtc'] / r_tr['dist'] * 1600)
                        if len(trend_norm_vals) >= 3:
                            if trend_norm_vals[0] > trend_norm_vals[1] > trend_norm_vals[2]:
                                rtc_trend_val = "ä¸Šæ˜‡ä¸­"
                            elif trend_norm_vals[0] < trend_norm_vals[1] < trend_norm_vals[2]:
                                rtc_trend_val = "ä¸‹é™ä¸­"

                    # ==============================================================================
                    # ã€æ©Ÿèƒ½7ã€‘è·é›¢é©æ€§ãƒœãƒ¼ãƒŠã‚¹: æ¬¡èµ°è·é›¢å¸¯ã§ã®éå»è¤‡å‹ç‡ã«åŸºã¥ãè£œæ­£å€¤ã‚’ç®—å‡º
                    # ==============================================================================
                    if val_sim_dist <= 1400:
                        dist_apt_range = (0, 1400)
                    elif val_sim_dist <= 1800:
                        dist_apt_range = (1401, 1800)
                    elif val_sim_dist <= 2200:
                        dist_apt_range = (1801, 2200)
                    else:
                        dist_apt_range = (2201, 99999)

                    df_dist_apt = df_h_v[
                        (df_h_v['dist'] >= dist_apt_range[0]) & (df_h_v['dist'] <= dist_apt_range[1]) &
                        (df_h_v['result_pos'] > 0)
                    ]
                    df_all_results = df_h_v[df_h_v['result_pos'] > 0]
                    dist_apt_bonus = 0.0
                    dist_apt_label = "-"
                    if len(df_dist_apt) >= 2 and len(df_all_results) >= 2:
                        dist_fuku_rate = len(df_dist_apt[df_dist_apt['result_pos'] <= 3]) / len(df_dist_apt)
                        all_fuku_rate = len(df_all_results[df_all_results['result_pos'] <= 3]) / len(df_all_results)
                        dist_diff = dist_fuku_rate - all_fuku_rate
                        dist_apt_bonus = -dist_diff * 0.5
                        if dist_diff >= 0.2:
                            dist_apt_label = f"ğŸ”¥è·é›¢å¾—æ„({int(dist_fuku_rate*100)}%)"
                        elif dist_diff <= -0.2:
                            dist_apt_label = f"âŒè·é›¢è‹¦æ‰‹({int(dist_fuku_rate*100)}%)"
                        else:
                            dist_apt_label = f"æ™®é€š({int(dist_fuku_rate*100)}%)"

                    list_res_v.append({
                        "é¦¬å": h_n_v, "è„šè³ª": style_l, "å¾—æ„å±•é–‹": dict_horse_pref_type_v75[h_n_v],
                        "è·¯ç·šå¤‰æ›´": str_cross_label if flag_is_cross_surface else "-",
                        "ã‚³ãƒ¼ã‚¹é©æ€§": aptitude_label_v9, 
                        "å®‰å®šåº¦": label_consistency_v10,
                        "é¬¼è„š": label_burst_v10,
                        "ãƒšãƒ¼ã‚¹é©æ€§": label_pace_apt_v10,
                        "åŒä¸€ãƒ¬ãƒ¼ã‚¹æ­´": label_same_race_hist,
                        "RTCãƒˆãƒ¬ãƒ³ãƒ‰": "ğŸ”¼ä¸Šæ˜‡ä¸­" if rtc_trend_val == "ä¸Šæ˜‡ä¸­" else "ğŸ”½ä¸‹é™ä¸­" if rtc_trend_val == "ä¸‹é™ä¸­" else "â¡ï¸æ¨ªã°ã„",
                        "è·é›¢é©æ€§": dist_apt_label,
                        "æƒ³å®šã‚¿ã‚¤ãƒ ": final_rtc_v, "æ¸‹æ»": jam_label, 
                        "load": f"{val_avg_load_3r:.1f}", "raw_rtc": final_rtc_v, "è§£æãƒ¡ãƒ¢": df_h_v.iloc[-1]['memo'],
                        "is_cross": flag_is_cross_surface,
                        "course_bonus": course_aptitude_bonus_v9,
                        "rtc_trend": rtc_trend_val,
                        "std_rtc": val_std_rtc_v10 if not pd.isna(val_std_rtc_v10) else 0.0,
                        "dist_apt_bonus": dist_apt_bonus,
                    })
                
                df_final_v = pd.DataFrame(list_res_v)
                
                val_sim_p_mult = 1.5 if num_sim_total >= 15 else 1.0
                def compute_synergy(row):
                    adj = 0.0
                    if "ãƒã‚¤" in str_sim_pace:
                        if row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]: adj -= 0.2 * val_sim_p_mult
                        elif row['è„šè³ª'] == "é€ƒã’": adj += 0.2 * val_sim_p_mult
                    elif "ã‚¹ãƒ­ãƒ¼" in str_sim_pace:
                        if row['è„šè³ª'] in ["é€ƒã’", "å…ˆè¡Œ"]: adj -= 0.2 * val_sim_p_mult
                        elif row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]: adj += 0.2 * val_sim_p_mult
                    
                    if str_sim_race_type_forecast_v75 == "ç¬ç™ºåŠ›æˆ¦":
                        if row['å¾—æ„å±•é–‹'] == "ç¬ç™ºåŠ›": adj -= 0.15
                        elif row['å¾—æ„å±•é–‹'] == "æŒç¶šåŠ›": adj += 0.15
                    elif str_sim_race_type_forecast_v75 == "æŒç¶šåŠ›æˆ¦":
                        if row['å¾—æ„å±•é–‹'] == "æŒç¶šåŠ›": adj -= 0.15
                        elif row['å¾—æ„å±•é–‹'] == "ç¬ç™ºåŠ›": adj += 0.15
                        
                    if row.get('is_cross', False):
                        adj += 0.0
                        
                    adj += row.get('course_bonus', 0.0)

                    # RTCãƒˆãƒ¬ãƒ³ãƒ‰è£œæ­£
                    trend = row.get('rtc_trend', 'æ¨ªã°ã„')
                    if trend == "ä¸Šæ˜‡ä¸­":
                        adj -= 0.15
                    elif trend == "ä¸‹é™ä¸­":
                        adj += 0.15

                    # ã€æ©Ÿèƒ½2ã€‘å®‰å®šåº¦è£œæ­£: æ¨™æº–åå·®ãŒå°ã•ã„ï¼ˆå®‰å®šï¼‰é¦¬ã¯ãƒœãƒ¼ãƒŠã‚¹ã€å¤§ãã„ï¼ˆãƒ ãƒ©ï¼‰é¦¬ã¯ãƒšãƒŠãƒ«ãƒ†ã‚£
                    std_v = row.get('std_rtc', 0.0)
                    if std_v > 0:
                        if std_v <= 0.5:
                            adj -= 0.1
                        elif std_v >= 1.5:
                            adj += 0.1

                    # ã€æ©Ÿèƒ½7ã€‘è·é›¢é©æ€§è£œæ­£
                    adj += row.get('dist_apt_bonus', 0.0)

                    return row['raw_rtc'] + adj

                df_final_v['synergy_rtc'] = df_final_v.apply(compute_synergy, axis=1)

                # ã€æ©Ÿèƒ½6ã€‘ç›¸å¯¾è©•ä¾¡ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å†…åå·®å€¤ï¼‰: å‡ºèµ°é¦¬é–“ã®synergy_rtcã‚’åå·®å€¤åŒ–ã—ã¦ã‚½ãƒ¼ãƒˆ
                if len(df_final_v) >= 3:
                    rtc_mean = df_final_v['synergy_rtc'].mean()
                    rtc_std = df_final_v['synergy_rtc'].std()
                    if rtc_std > 0:
                        # RTCã¯ä½ã„æ–¹ãŒè‰¯ã„ â†’ åå·®å€¤ã¯é«˜ã„æ–¹ãŒè‰¯ã„ï¼ˆç¬¦å·åè»¢ï¼‰
                        df_final_v['ç›¸å¯¾åå·®å€¤'] = (50 - (df_final_v['synergy_rtc'] - rtc_mean) / rtc_std * 10).round(1)
                    else:
                        df_final_v['ç›¸å¯¾åå·®å€¤'] = 50.0
                else:
                    df_final_v['ç›¸å¯¾åå·®å€¤'] = 50.0

                df_final_v = df_final_v.sort_values("synergy_rtc")
                df_final_v['é †ä½'] = range(1, len(df_final_v) + 1)
                
                df_final_v['å½¹å‰²'] = "-"
                df_final_v.loc[df_final_v['é †ä½'] == 1, 'å½¹å‰²'] = "â—"
                df_final_v.loc[df_final_v['é †ä½'] == 2, 'å½¹å‰²'] = "ã€‡"
                df_final_v.loc[df_final_v['é †ä½'] == 3, 'å½¹å‰²'] = "â–²"
                
                df_final_v['äºˆæƒ³äººæ°—'] = df_final_v['é¦¬å'].map(sim_p_map)
                df_final_v['å¦™å‘³ã‚¹ã‚³ã‚¢'] = df_final_v['äºˆæƒ³äººæ°—'] - df_final_v['é †ä½']
                
                # ğŸŒŸ ã€æ–°æ©Ÿèƒ½4ã€‘æ¨å®šã‚ªãƒƒã‚ºä¹–é›¢ãƒ»æœŸå¾…å€¤åˆ¤å®š
                def evaluate_expected_value_v10(row):
                    gap = row['å¦™å‘³ã‚¹ã‚³ã‚¢']
                    if row['é †ä½'] <= 3 and row['äºˆæƒ³äººæ°—'] >= 6:
                        return "ğŸ”¥çˆ†ãƒ»æœŸå¾…å€¤æœ€é«˜"
                    elif gap >= 3:
                        return "ğŸ“ˆå¦™å‘³ã‚ã‚Š"
                    elif gap <= -3:
                        return "âš ï¸éå‰°äººæ°—"
                    else:
                        return "å¦¥å½“"

                df_final_v['æœŸå¾…å€¤'] = df_final_v.apply(evaluate_expected_value_v10, axis=1)
                
                df_bomb = df_final_v[df_final_v['é †ä½'] > 1].sort_values("å¦™å‘³ã‚¹ã‚³ã‚¢", ascending=False)
                if not df_bomb.empty:
                     df_final_v.loc[df_final_v['é¦¬å'] == df_bomb.iloc[0]['é¦¬å'], 'å½¹å‰²'] = "â˜…"

                st.markdown("---")
                st.subheader(f"ğŸ å±•é–‹äºˆæƒ³ï¼š{str_sim_pace} Ã— {str_sim_race_type_forecast_v75} ({num_sim_total}é ­ç«‹ã¦)")

                # ã€æ©Ÿèƒ½7ã€‘é€ƒã’é¦¬è¤‡æ•°è­¦å‘Š & ãƒšãƒ¼ã‚¹äºˆæ¸¬æ ¹æ‹ ã‚’æ˜ç¤ºè¡¨ç¤º
                if dict_styles["é€ƒã’"] >= 2:
                    st.error(f"ğŸš¨ **é€ƒã’é¦¬è¤‡æ•°è­¦å‘Š**: é€ƒã’è„šè³ªãŒ{dict_styles['é€ƒã’']}é ­ç¢ºèªã€‚ãƒã‚¤ãƒšãƒ¼ã‚¹ç¢ºå®šã«è¿‘ãã€å…ˆè¡Œé¦¬ã‚‚è‹¦æˆ¦å¿…è‡³ã€‚å·®ã—ãƒ»è¿½è¾¼é¦¬ã‚’å„ªå…ˆçš„ã«è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚")
                elif dict_styles["é€ƒã’"] == 1 and (dict_styles["é€ƒã’"] + dict_styles["å…ˆè¡Œ"]) >= num_sim_total * 0.5:
                    st.warning(f"âš ï¸ **å‰å‚¾ãƒ¡ãƒ³ãƒãƒ¼æ§‹æˆ**: å…ˆè¡Œå‹¢ãŒéåŠæ•° ({dict_styles['é€ƒã’']}é€ƒã’/{dict_styles['å…ˆè¡Œ']}å…ˆè¡Œ)ã€‚ãƒšãƒ¼ã‚¹ãŒä¸ŠãŒã‚Šã‚„ã™ãå·®ã—é¦¬ã®å°é ­ã«æ³¨æ„ã€‚")
                elif dict_styles["é€ƒã’"] == 0:
                    st.info(f"â„¹ï¸ **é€ƒã’é¦¬ä¸åœ¨**: é€ƒã’è„šè³ª0é ­ã€‚å…ˆè¡Œäº‰ã„ãŒæ¿€åŒ–ã—ã«ããã€ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹å¾Œã®ç¬ç™ºåŠ›å‹è² ã«ãªã‚Šã‚„ã™ã„æ§‹æˆã§ã™ã€‚")

                col_pace_detail1, col_pace_detail2, col_pace_detail3, col_pace_detail4 = st.columns(4)
                with col_pace_detail1:
                    st.metric("é€ƒã’", f"{dict_styles['é€ƒã’']}é ­")
                with col_pace_detail2:
                    st.metric("å…ˆè¡Œ", f"{dict_styles['å…ˆè¡Œ']}é ­")
                with col_pace_detail3:
                    st.metric("å·®ã—", f"{dict_styles['å·®ã—']}é ­")
                with col_pace_detail4:
                    st.metric("è¿½è¾¼", f"{dict_styles['è¿½è¾¼']}é ­")
                
                # æœ¬å‘½(1ï½5äººæ°—)1é ­ãƒ»ç›¸æ‰‹(6ï½9äººæ°—)1é ­ãƒ»ç›¸æ‰‹(10äººæ°—ä»¥ä¸‹)1é ­ã®2ç‚¹æµã—ï¼ˆ10äººæ°—ä»¥ä¸‹ã§åŠ›ä¸è¶³ã®é¦¬ã¯é™¤å¤–ã—1ç‚¹å‹è² ã«ï¼‰
                df_1_5 = df_final_v[(df_final_v['äºˆæƒ³äººæ°—'] >= 1) & (df_final_v['äºˆæƒ³äººæ°—'] <= 5)].sort_values("synergy_rtc")
                df_6_9 = df_final_v[(df_final_v['äºˆæƒ³äººæ°—'] >= 6) & (df_final_v['äºˆæƒ³äººæ°—'] <= 9)].sort_values("synergy_rtc")
                df_10_plus = df_final_v[df_final_v['äºˆæƒ³äººæ°—'] >= 10].sort_values("synergy_rtc")

                honmei_name = ""
                aite_6_9_name = ""
                aite_10_name = ""

                if not df_1_5.empty:
                    honmei_name = df_1_5.iloc[0]['é¦¬å']
                if not df_6_9.empty:
                    aite_6_9_name = df_6_9.iloc[0]['é¦¬å']

                # 10äººæ°—ä»¥ä¸‹ã‹ã‚‰ã¯ã€ŒåŠ›ãŒè¶³ã‚Šã‚‹ã€é¦¬ã®ã¿æ¡ç”¨ï¼ˆç›¸å¯¾åå·®å€¤42ä»¥ä¸Šï¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸­ä½ä»¥ä¸Šã®å®ŸåŠ›ï¼‰
                if not df_10_plus.empty:
                    df_10_strong = df_10_plus[df_10_plus['ç›¸å¯¾åå·®å€¤'] >= 42]
                    if not df_10_strong.empty:
                        aite_10_name = df_10_strong.iloc[0]['é¦¬å']

                col_rec1, col_rec2 = st.columns(2)
                with col_rec1:
                    st.subheader("ğŸ¯ è²·ã„ç›®ï¼ˆé¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰ï¼‰")
                    if honmei_name:
                        lines = [f"**æœ¬å‘½ï¼ˆ1ï½5äººæ°—ï¼‰**: {honmei_name}"]
                        if aite_6_9_name:
                            lines.append(f"**ç›¸æ‰‹ï¼ˆ6ï½9äººæ°—ï¼‰**: {aite_6_9_name}")
                        if aite_10_name:
                            lines.append(f"**ç›¸æ‰‹ï¼ˆ10äººæ°—ä»¥ä¸‹ï¼‰**: {aite_10_name}")

                        if aite_6_9_name and aite_10_name:
                            lines.append("")
                            lines.append("**2ç‚¹æµã—**")
                            lines.append(f"â‘  {honmei_name} Ã— {aite_6_9_name}")
                            lines.append(f"â‘¡ {honmei_name} Ã— {aite_10_name}")
                        elif aite_6_9_name:
                            lines.append("")
                            lines.append("**1ç‚¹å‹è² **ï¼ˆ10äººæ°—ä»¥ä¸‹ã«åŠ›ã‚ã‚Šé¦¬ãªã—ï¼‰")
                            lines.append(f"{honmei_name} Ã— {aite_6_9_name}")
                        else:
                            lines.append("")
                            lines.append("ï¼ˆ6ï½9äººæ°—ã®é¦¬ãŒã„ãªã„ãŸã‚è²·ã„ç›®ã‚’å‡ºã›ã¾ã›ã‚“ï¼‰")
                        st.info("\n\n".join(lines))
                    else:
                        st.warning("1ï½5äººæ°—ã®é¦¬ãŒã„ãªã„ãŸã‚è²·ã„ç›®ã‚’å‡ºã›ã¾ã›ã‚“ã€‚")

                with col_rec2:
                    bomb_name = df_final_v[df_final_v['å½¹å‰²'] == "â˜…"].iloc[0]['é¦¬å'] if not df_final_v[df_final_v['å½¹å‰²'] == "â˜…"].empty else ""
                    if honmei_name and bomb_name:
                        st.warning(f"**ğŸ’£ å¦™å‘³ç‹™ã„ãƒ¯ã‚¤ãƒ‰ 1ç‚¹**\n\nâ— {honmei_name} ï¼ â˜… {bomb_name}")

                df_final_v['æƒ³å®šã‚¿ã‚¤ãƒ '] = df_final_v['raw_rtc'].apply(format_time_to_hmsf_string)
                
                def highlight_role(row):
                    if row['å½¹å‰²'] == 'â—': return ['background-color: #ffffcc; font-weight: bold; color: black'] * len(row)
                    if row['å½¹å‰²'] == 'â˜…': return ['background-color: #ffe6e6; font-weight: bold'] * len(row)
                    return [''] * len(row)

                # åŒä¸€ãƒ¬ãƒ¼ã‚¹æ­´ã‚«ãƒ©ãƒ ã¯ãƒ¬ãƒ¼ã‚¹åå…¥åŠ›æ™‚ã®ã¿è¡¨ç¤º
                if val_sim_race_name.strip():
                    sim_display_cols = ["å½¹å‰²", "é †ä½", "ç›¸å¯¾åå·®å€¤", "é¦¬å", "äºˆæƒ³äººæ°—", "æœŸå¾…å€¤", "RTCãƒˆãƒ¬ãƒ³ãƒ‰", "è·é›¢é©æ€§", "åŒä¸€ãƒ¬ãƒ¼ã‚¹æ­´", "è„šè³ª", "å¾—æ„å±•é–‹", "ãƒšãƒ¼ã‚¹é©æ€§", "è·¯ç·šå¤‰æ›´", "ã‚³ãƒ¼ã‚¹é©æ€§", "å®‰å®šåº¦", "é¬¼è„š", "æ¸‹æ»", "load", "æƒ³å®šã‚¿ã‚¤ãƒ ", "è§£æãƒ¡ãƒ¢"]
                else:
                    sim_display_cols = ["å½¹å‰²", "é †ä½", "ç›¸å¯¾åå·®å€¤", "é¦¬å", "äºˆæƒ³äººæ°—", "æœŸå¾…å€¤", "RTCãƒˆãƒ¬ãƒ³ãƒ‰", "è·é›¢é©æ€§", "è„šè³ª", "å¾—æ„å±•é–‹", "ãƒšãƒ¼ã‚¹é©æ€§", "è·¯ç·šå¤‰æ›´", "ã‚³ãƒ¼ã‚¹é©æ€§", "å®‰å®šåº¦", "é¬¼è„š", "æ¸‹æ»", "load", "æƒ³å®šã‚¿ã‚¤ãƒ ", "è§£æãƒ¡ãƒ¢"]
                st.table(df_final_v[sim_display_cols].style.apply(highlight_role, axis=1))

# ==============================================================================
# 11. Tab 5: ãƒˆãƒ¬ãƒ³ãƒ‰çµ±è¨ˆè©³ç´° & Tab 6: ç‰©ç†ç®¡ç†è©³ç´°
# ==============================================================================

with tab_trends:
    st.header("ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰è©³ç´°ç‰©ç†çµ±è¨ˆ")
    df_t5_f = get_db_data()
    if not df_t5_f.empty:
        sel_c_v = st.selectbox("ãƒˆãƒ¬ãƒ³ãƒ‰ç«¶é¦¬å ´æŒ‡å®š", list(MASTER_CONFIG_V65_TURF_LOAD_COEFFS.keys()), key="tc_v5_final")
        tdf_v = df_t5_f[df_t5_f['course'] == sel_c_v].sort_values("date")
        if not tdf_v.empty:
            st.subheader("ğŸ’§ ç‰©ç†æ¨ç§»ã‚°ãƒ©ãƒ•")
            st.line_chart(tdf_v.set_index("date")[["cushion", "water"]])

# ==============================================================================
# 11.5. Tab ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: å›åç‡åˆ†æ / ã‚±ãƒªãƒ¼åŸºæº– / ä¸Šæ˜‡é¦¬ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—
# ==============================================================================

with tab_backtest:
    st.header("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ & å›åç‡åˆ†æã‚¨ãƒ³ã‚¸ãƒ³")
    df_bt = get_db_data()

    # çµæœãŒå…¥åŠ›ã•ã‚ŒãŸè¡Œã®ã¿å¯¾è±¡ï¼ˆresult_pos > 0 ã‹ã¤ result_pop > 0ï¼‰
    df_bt_valid = df_bt[(df_bt['result_pos'] > 0) & (df_bt['result_pop'] > 0)].copy()

    if df_bt_valid.empty:
        st.info("ã¾ã çµæœãŒå…¥åŠ›ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´ã€ã‚¿ãƒ–ã§ç€é †ãƒ»äººæ°—ã‚’å…¥åŠ›ã™ã‚‹ã¨ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")
    else:
        # äººæ°—é †ä½ã‹ã‚‰å˜å‹ã‚ªãƒƒã‚ºã®æ¨å®šå€¤ãƒãƒƒãƒ—ï¼ˆæ—¥æœ¬ç«¶é¦¬æ¨™æº–çš„ãªè¿‘ä¼¼å€¤ï¼‰
        BACKTEST_SINGLE_ODDS_MAP = {
            1: 2.5, 2: 4.2, 3: 6.5, 4: 10.0, 5: 15.0,
            6: 23.0, 7: 35.0, 8: 55.0, 9: 80.0, 10: 110.0
        }

        def bt_estimate_win_odds(pop_val):
            try:
                p_int = int(float(pop_val))
                if p_int in BACKTEST_SINGLE_ODDS_MAP:
                    return BACKTEST_SINGLE_ODDS_MAP[p_int]
                elif p_int > 10:
                    return 110.0 + (p_int - 10) * 25.0
                return 100.0
            except Exception:
                return 100.0

        df_bt_valid['est_win_odds'] = df_bt_valid['result_pop'].apply(bt_estimate_win_odds)
        df_bt_valid['hit_top1'] = (df_bt_valid['result_pos'] == 1).astype(int)
        df_bt_valid['hit_top2'] = (df_bt_valid['result_pos'] <= 2).astype(int)
        df_bt_valid['hit_top3'] = (df_bt_valid['result_pos'] <= 3).astype(int)

        # ============================================================
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³1: è²·ã„ãƒ•ãƒ©ã‚°åˆ¥ å›åç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        # ============================================================
        st.subheader("ğŸ¯ è²·ã„ãƒ•ãƒ©ã‚°åˆ¥ å›åç‡ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        st.caption("â€»å˜å‹ã‚ªãƒƒã‚ºã¯äººæ°—é †ä½ã‹ã‚‰ã®æ¨å®šå€¤ã§ã™ã€‚å®Ÿéš›ã®æ‰•ã„æˆ»ã—ã¨ã¯ç•°ãªã‚Šã¾ã™ã€‚")

        flag_condition_defs = [
            ("â˜…é€†è¡Œç‹™ã„ (æ¬¡èµ°ãƒ•ãƒ©ã‚°ã‚ã‚Š)", lambda r: "â˜…é€†è¡Œç‹™ã„" in str(r['next_buy_flag'])),
            ("ğŸ’ãƒã‚¤ã‚¢ã‚¹é€†è¡Œã‚’å«ã‚€", lambda r: "ğŸ’" in str(r['memo'])),
            ("ğŸ”¥å±•é–‹é€†è¡Œã‚’å«ã‚€", lambda r: "ğŸ”¥" in str(r['memo'])),
            ("ğŸ’¥ä¸¡æ–¹é€†è¡Œ (è¶…é«˜è©•ä¾¡)", lambda r: "ğŸ’" in str(r['memo']) and "ğŸ”¥" in str(r['memo'])),
            ("å…¨è¨˜éŒ²ï¼ˆãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒï¼‰", lambda r: True),
        ]

        analysis_result_rows = []
        for flag_display_name, flag_cond_fn in flag_condition_defs:
            df_flag_sub = df_bt_valid[df_bt_valid.apply(flag_cond_fn, axis=1)].copy()
            if len(df_flag_sub) == 0:
                continue

            n_total = len(df_flag_sub)
            win_rate_v = df_flag_sub['hit_top1'].mean()
            rentan_rate_v = df_flag_sub['hit_top2'].mean()
            fuku_rate_v = df_flag_sub['hit_top3'].mean()
            avg_pop_v = df_flag_sub['result_pop'].mean()

            # æ¨å®šå˜å‹å›åç‡ = çš„ä¸­æ™‚ã‚ªãƒƒã‚ºåˆè¨ˆ / ç·æŠ•ç¥¨æ•° * 100
            total_return_v = df_flag_sub[df_flag_sub['hit_top1'] == 1]['est_win_odds'].sum()
            roi_single_v = (total_return_v / n_total) * 100 if n_total > 0 else 0.0

            # ã‚±ãƒªãƒ¼åŸºæº–: f* = (b*p - (1-p)) / b
            avg_odds_v = df_flag_sub['est_win_odds'].mean()
            b_kelly = avg_odds_v - 1.0
            p_kelly = win_rate_v
            if b_kelly > 0 and p_kelly > 0:
                kelly_fraction = max(0.0, (b_kelly * p_kelly - (1.0 - p_kelly)) / b_kelly)
                kelly_display = f"{kelly_fraction * 100:.1f}%" if kelly_fraction > 0 else "è¦‹é€ã‚Šæ¨å¥¨"
            else:
                kelly_display = "è¦‹é€ã‚Šæ¨å¥¨"

            analysis_result_rows.append({
                "ãƒ•ãƒ©ã‚°ç¨®åˆ¥": flag_display_name,
                "å¯¾è±¡æ•°": n_total,
                "å˜å‹ç‡": f"{win_rate_v * 100:.1f}%",
                "é€£å¯¾ç‡": f"{rentan_rate_v * 100:.1f}%",
                "è¤‡å‹ç‡": f"{fuku_rate_v * 100:.1f}%",
                "å¹³å‡äººæ°—": f"{avg_pop_v:.1f}",
                "æ¨å®šå˜å‹å›åç‡": f"{roi_single_v:.0f}%",
                "ã‚±ãƒªãƒ¼æ¨å¥¨è³­ã‘æ¯”ç‡": kelly_display,
            })

        if analysis_result_rows:
            df_analysis_display = pd.DataFrame(analysis_result_rows)
            st.dataframe(df_analysis_display, use_container_width=True, hide_index=True)

        st.divider()

        # ============================================================
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³2: é¦¬åˆ¥ å›åç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        # ============================================================
        st.subheader("ğŸ é¦¬åˆ¥ æ¨å®šå›åç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆTop20ï¼‰")
        st.caption("èµ°æ•°2èµ°ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é¦¬ã®ã¿å¯¾è±¡ã€‚å˜å‹å›åç‡ãƒ™ãƒ¼ã‚¹ã§ã‚½ãƒ¼ãƒˆã€‚")

        horse_analysis_rows = []
        for h_name_bt in df_bt_valid['name'].dropna().unique():
            df_h_bt = df_bt_valid[df_bt_valid['name'] == h_name_bt].copy()
            n_h_bt = len(df_h_bt)
            if n_h_bt < 2:
                continue

            win_r_h = df_h_bt['hit_top1'].mean()
            fuku_r_h = df_h_bt['hit_top3'].mean()
            total_ret_h = df_h_bt[df_h_bt['hit_top1'] == 1]['est_win_odds'].sum()
            roi_h = (total_ret_h / n_h_bt) * 100 if n_h_bt > 0 else 0.0
            avg_pop_h = df_h_bt['result_pop'].mean()

            horse_analysis_rows.append({
                "é¦¬å": h_name_bt,
                "èµ°æ•°": n_h_bt,
                "è¤‡å‹ç‡": f"{fuku_r_h * 100:.0f}%",
                "å˜å‹ç‡": f"{win_r_h * 100:.0f}%",
                "å¹³å‡äººæ°—": f"{avg_pop_h:.1f}",
                "æ¨å®šå˜å‹å›åç‡": f"{roi_h:.0f}%",
                "_roi_sort": roi_h,
            })

        if horse_analysis_rows:
            df_horse_rank_bt = pd.DataFrame(horse_analysis_rows).sort_values('_roi_sort', ascending=False).drop('_roi_sort', axis=1)
            st.dataframe(df_horse_rank_bt.head(20), use_container_width=True, hide_index=True)

        st.divider()

        # ============================================================
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³3: ä¸Šæ˜‡é¦¬ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆRTCæ¨ç§»åˆ†æï¼‰
        # ============================================================
        st.subheader("ğŸ”¼ ä¸Šæ˜‡é¦¬ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆç›´è¿‘3èµ°ã§RTCå˜èª¿æ”¹å–„ï¼‰")
        st.caption("ç›´è¿‘3èµ°ã®æ­£è¦åŒ–RTCï¼ˆ1600mæ›ç®—ï¼‰ãŒç¶™ç¶šçš„ã«ä½ä¸‹ï¼ˆæ”¹å–„ï¼‰ã—ã¦ã„ã‚‹é¦¬ã‚’è‡ªå‹•æŠ½å‡ºã—ã¾ã™ã€‚")

        rising_horse_rows = []
        for h_name_rising in df_bt['name'].dropna().unique():
            df_h_rising = df_bt[df_bt['name'] == h_name_rising].sort_values("date")
            valid_rtc_rising = df_h_rising[(df_h_rising['base_rtc'] > 0) & (df_h_rising['base_rtc'] < 999)].tail(3)
            if len(valid_rtc_rising) < 3:
                continue
            norm_rtc_rising = []
            for _, r_rising in valid_rtc_rising.iterrows():
                if r_rising['dist'] > 0:
                    norm_rtc_rising.append(r_rising['base_rtc'] / r_rising['dist'] * 1600)
            if len(norm_rtc_rising) >= 3 and norm_rtc_rising[0] > norm_rtc_rising[1] > norm_rtc_rising[2]:
                last_entry_rising = df_h_rising.iloc[-1]
                improvement = norm_rtc_rising[0] - norm_rtc_rising[2]
                last_date_rising = last_entry_rising['date']
                last_date_str = last_date_rising.strftime('%Y-%m-%d') if not pd.isna(last_date_rising) else ""
                rising_horse_rows.append({
                    "é¦¬å": h_name_rising,
                    "ç›´è¿‘3èµ° æ­£è¦åŒ–RTC": f"{norm_rtc_rising[0]:.2f} â†’ {norm_rtc_rising[1]:.2f} â†’ {norm_rtc_rising[2]:.2f}",
                    "ç·æ”¹å–„å¹…": f"{improvement:.2f}ç§’",
                    "æœ€çµ‚ãƒ¬ãƒ¼ã‚¹": str(last_entry_rising.get('last_race', '')),
                    "æœ€çµ‚æ—¥ä»˜": last_date_str,
                })

        if rising_horse_rows:
            df_rising_display = pd.DataFrame(rising_horse_rows).sort_values("ç·æ”¹å–„å¹…", ascending=False)
            st.dataframe(df_rising_display, use_container_width=True, hide_index=True)
        else:
            st.info("ç›´è¿‘3èµ°ã§é€£ç¶šçš„ã«RTCãŒæ”¹å–„ã—ã¦ã„ã‚‹é¦¬ã¯ç¾åœ¨ã„ã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã™ã‚‹ã¨è‡ªå‹•çš„ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

        st.divider()

        # ============================================================
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³4: åŒä¸€ãƒ¬ãƒ¼ã‚¹éå»æ­´æ¤œç´¢
        # ============================================================
        st.subheader("ğŸ” åŒä¸€ãƒ¬ãƒ¼ã‚¹éå»æ­´æ¤œç´¢")
        st.caption("ãƒ¬ãƒ¼ã‚¹åï¼ˆéƒ¨åˆ†ä¸€è‡´ï¼‰ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãã®ãƒ¬ãƒ¼ã‚¹ã«å‡ºèµ°æ­´ãŒã‚ã‚‹å…¨é¦¬ã®æˆç¸¾ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")

        bt_race_search_query = st.text_input("æ¤œç´¢ã™ã‚‹ãƒ¬ãƒ¼ã‚¹å", value="", placeholder="ä¾‹: å¤©çš‡è³ã€æœ‰é¦¬ã€ãƒã‚¤ãƒ«CS", key="bt_race_search_q")

        if bt_race_search_query.strip():
            # éƒ¨åˆ†ä¸€è‡´ã§å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã‚’çµã‚Šè¾¼ã‚€
            df_bt_race_all = get_db_data()
            df_race_matched = df_bt_race_all[
                df_bt_race_all['last_race'].str.contains(bt_race_search_query.strip(), na=False, case=False)
            ].copy()

            if df_race_matched.empty:
                st.warning(f"ã€Œ{bt_race_search_query}ã€ã«ä¸€è‡´ã™ã‚‹ãƒ¬ãƒ¼ã‚¹å‡ºèµ°æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            else:
                # ãƒãƒƒãƒã—ãŸãƒ¬ãƒ¼ã‚¹åã®ä¸€è¦§ã‚’è¡¨ç¤º
                matched_race_names = sorted(df_race_matched['last_race'].dropna().unique().tolist())
                st.info(f"ãƒãƒƒãƒã—ãŸãƒ¬ãƒ¼ã‚¹: {', '.join(matched_race_names)} ï¼ˆè¨ˆ{len(df_race_matched)}ä»¶ï¼‰")

                # é¦¬ã”ã¨ã«é›†è¨ˆ
                same_race_summary_rows = []
                for h_name_sr in df_race_matched['name'].dropna().unique():
                    df_h_sr = df_race_matched[df_race_matched['name'] == h_name_sr].sort_values("date")
                    n_sr = len(df_h_sr)

                    df_h_sr_with_res = df_h_sr[df_h_sr['result_pos'] > 0]
                    best_pos_sr = int(df_h_sr_with_res['result_pos'].min()) if not df_h_sr_with_res.empty else None
                    avg_pos_sr = df_h_sr_with_res['result_pos'].mean() if not df_h_sr_with_res.empty else None
                    n_top3_sr = len(df_h_sr_with_res[df_h_sr_with_res['result_pos'] <= 3]) if not df_h_sr_with_res.empty else 0

                    # æœ€æ–°å‡ºèµ°æ™‚ã®RTCï¼ˆæ­£è¦åŒ–ï¼‰
                    last_sr = df_h_sr.iloc[-1]
                    last_date_sr = last_sr['date']
                    last_date_str_sr = last_date_sr.strftime('%Y-%m-%d') if not pd.isna(last_date_sr) else ""
                    last_rtc_sr = last_sr['base_rtc']
                    last_dist_sr = last_sr['dist']
                    norm_rtc_sr = (last_rtc_sr / last_dist_sr * 1600) if (last_dist_sr > 0 and 0 < last_rtc_sr < 999) else None

                    if best_pos_sr == 1:
                        result_icon_sr = "ğŸ¥‡"
                    elif best_pos_sr is not None and best_pos_sr <= 3:
                        result_icon_sr = "ğŸ¥ˆ"
                    elif best_pos_sr is not None and best_pos_sr <= 5:
                        result_icon_sr = "âœ…"
                    elif best_pos_sr is not None:
                        result_icon_sr = "ğŸ“‹"
                    else:
                        result_icon_sr = "â“"

                    same_race_summary_rows.append({
                        "": result_icon_sr,
                        "é¦¬å": h_name_sr,
                        "å‡ºèµ°å›æ•°": n_sr,
                        "æœ€é«˜ç€é †": f"{best_pos_sr}ç€" if best_pos_sr is not None else "ç€é †æœªå…¥åŠ›",
                        "å¹³å‡ç€é †": f"{avg_pos_sr:.1f}" if avg_pos_sr is not None else "-",
                        "è¤‡å‹å›æ•°": f"{n_top3_sr}/{len(df_h_sr_with_res)}" if not df_h_sr_with_res.empty else "-",
                        "æœ€çµ‚å‡ºèµ°æ—¥": last_date_str_sr,
                        "æœ€çµ‚ãƒ¬ãƒ¼ã‚¹æ­£è¦åŒ–RTC": f"{norm_rtc_sr:.2f}" if norm_rtc_sr is not None else "-",
                        "æœ€çµ‚ãƒ¬ãƒ¼ã‚¹å": str(last_sr.get('last_race', '')),
                    })

                if same_race_summary_rows:
                    # æœ€é«˜ç€é †ã§ã‚½ãƒ¼ãƒˆï¼ˆç€é †ãŒè‰¯ã„é † = æ•°å€¤ãŒå°ã•ã„é †ï¼‰
                    df_sr_display = pd.DataFrame(same_race_summary_rows)
                    # æœ€é«˜ç€é †ã‚’æ•°å€¤ã§ä¸€æ™‚ã‚½ãƒ¼ãƒˆ
                    df_sr_display['_sort_key'] = df_sr_display['æœ€é«˜ç€é †'].str.extract(r'(\d+)').astype(float).fillna(99)
                    df_sr_display = df_sr_display.sort_values('_sort_key').drop('_sort_key', axis=1)
                    st.dataframe(df_sr_display, use_container_width=True, hide_index=True)

with tab_management:
    st.header("ğŸ—‘ ç‰©ç†ç®¡ç† & å†è§£æå·¥ç¨‹è©³ç´°")
    if st.button("ğŸ”„ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå¼·åˆ¶ç‰©ç†åŒæœŸ (å…¨ç ´æ£„)"):
        st.cache_data.clear(); st.rerun()
    df_t6_f = get_db_data()
    
    def update_eval_tags_verbose_logic_final_step(row_v, df_ctx_v=None):
        m_r_v = str(row_v['memo']) if not pd.isna(row_v['memo']) else ""
        def to_f_v(v_in, default=0.0):
            try: return float(v_in) if not pd.isna(v_in) else default
            except: return default
        
        f3f_v = to_f_v(row_v['f3f'])
        l3f_v = to_f_v(row_v['l3f'])
        race_l3f_v = to_f_v(row_v['race_l3f'])
        pos_v = to_f_v(row_v['result_pos'])
        l_pos_v = to_f_v(row_v['load'])
        old_rtc_v = to_f_v(row_v['base_rtc'])
        
        raw_time_v = to_f_v(row_v.get('raw_time', 0.0))
        track_idx_v = to_f_v(row_v.get('track_idx', 0.0))
        bias_slider_v = to_f_v(row_v.get('bias_slider', 0.0))
        cushion_v = to_f_v(row_v.get('cushion', 9.5), 9.5)
        water_v = to_f_v(row_v.get('water', 10.0), 10.0)
        dist_v = to_f_v(row_v.get('dist', 1600.0), 1600.0)
        week_v = to_f_v(row_v.get('track_week', 1.0), 1.0)
        
        str_n_v = str(row_v['notes'])
        m_w_v = re.search(r'([4-6]\d\.\d)', str_n_v)
        indiv_w_v = float(m_w_v.group(1)) if m_w_v else 56.0
        
        pace_gap_v = f3f_v - race_l3f_v
        
        bt_label_v = "ãƒ•ãƒ©ãƒƒãƒˆ"; mx_field_v = 16
        if df_ctx_v is not None and not pd.isna(row_v['last_race']):
            rc_sub_v = df_ctx_v[df_ctx_v['last_race'] == row_v['last_race']]
            mx_field_v = rc_sub_v['result_pos'].max() if not rc_sub_v.empty else 16
            
            top3_v = rc_sub_v[rc_sub_v['result_pos'] <= 3].copy()
            top3_v['load'] = top3_v['load'].fillna(7.0)
            
            if not top3_v.empty:
                outlier_mask = (top3_v['load'] >= 10.0) | (top3_v['load'] <= 3.0)
                outliers = top3_v[outlier_mask]
                
                if len(outliers) == 1:
                    core_top3 = top3_v[~outlier_mask]
                    fourth_v = rc_sub_v[rc_sub_v['result_pos'] == 4].copy()
                    fourth_v['load'] = fourth_v['load'].fillna(7.0)
                    bias_calc_pool = pd.concat([core_top3, fourth_v])
                else:
                    bias_calc_pool = top3_v
                    
                if not bias_calc_pool.empty:
                    avg_l_v = bias_calc_pool['load'].mean()
                    if avg_l_v <= 4.0: bt_label_v = "å‰æœ‰åˆ©"
                    elif avg_l_v >= 10.0: bt_label_v = "å¾Œæœ‰åˆ©"
        
        ps_label_v = "ãƒã‚¤ãƒšãƒ¼ã‚¹" if "ãƒã‚¤" in m_r_v else "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" if "ã‚¹ãƒ­ãƒ¼" in m_r_v else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        
        val_rel_ratio_v = l_pos_v / mx_field_v if mx_field_v > 0 else l_pos_v / 16.0
        val_scale_v = mx_field_v / 16.0
        val_computed_load_v = 0.0
        
        if ps_label_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and bt_label_v != "å‰æœ‰åˆ©":
            val_computed_load_v = max(0.0, (0.6 - val_rel_ratio_v) * abs(pace_gap_v) * 3.0) * val_scale_v 
        elif ps_label_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and bt_label_v != "å¾Œæœ‰åˆ©":
            val_computed_load_v = max(0.0, (val_rel_ratio_v - 0.4) * abs(pace_gap_v) * 2.0) * val_scale_v 

        list_tags_v = []
        flag_is_counter_v = False
        
        if pos_v <= 5:
            if (bt_label_v == "å‰æœ‰åˆ©" and l_pos_v >= 10.0) or (bt_label_v == "å¾Œæœ‰åˆ©" and l_pos_v <= 3.0):
                list_tags_v.append("ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if mx_field_v >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ"); flag_is_counter_v = True
        
        if not ((ps_label_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and bt_label_v == "å‰æœ‰åˆ©") or (ps_label_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and bt_label_v == "å¾Œæœ‰åˆ©")):
            if ps_label_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and l_pos_v <= 3.0 and pos_v <= 5: 
                list_tags_v.append("ğŸ“‰ æ¿€æµè¢«å®³" if mx_field_v >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ"); flag_is_counter_v = True
            elif ps_label_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and l_pos_v >= 10.0 and (f3f_v - l3f_v) > 1.5 and pos_v <= 5: 
                list_tags_v.append("ğŸ”¥ å±•é–‹é€†è¡Œ"); flag_is_counter_v = True

        str_field_tag_v = "å¤š" if mx_field_v >= 16 else "å°‘" if mx_field_v <= 10 else "ä¸­"

        race_type_v = str(row_v.get('race_type', 'ä¸æ˜'))
        if pd.isna(race_type_v) or race_type_v == 'nan': race_type_v = "ä¸æ˜"

        mu_final_v = f"ã€{ps_label_v}({race_type_v})/{bt_label_v}/è² è·:{val_computed_load_v:.1f}({str_field_tag_v})/å¹³ã€‘{'/'.join(list_tags_v) if list_tags_v else 'é †å¢ƒ'}"
        
        new_rtc_v = old_rtc_v
        if raw_time_v > 0.0 and raw_time_v != 999.0:
            r_p1 = raw_time_v
            r_p2 = (indiv_w_v - 56.0) * 0.1
            r_p3 = track_idx_v / 10.0
            r_p4 = val_computed_load_v / 10.0
            r_p5 = (week_v - 1) * 0.05
            r_p8 = (water_v - 10.0) * 0.05
            r_p9 = (9.5 - cushion_v) * 0.1
            r_p10 = (dist_v - 1600) * 0.0005
            new_rtc_v = r_p1 - r_p2 - r_p3 - r_p4 - r_p5 + bias_slider_v - r_p8 - r_p9 + r_p10
        elif raw_time_v == 999.0:
            new_rtc_v = 999.0

        return mu_final_v, str(row_v['next_buy_flag']), new_rtc_v

    if st.button("ğŸ”„ ç‰©ç†ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å…¨è¨˜éŒ²ã®å†è¨ˆç®—ãƒ»ç‰©ç†åŒæœŸ"):
        st.cache_data.clear()
        latest_df_v = conn.read(ttl=0)
        for c_nm in ABSOLUTE_COLUMN_STRUCTURE_DEFINITION_GLOBAL:
            if c_nm not in latest_df_v.columns: latest_df_v[c_nm] = None
        for idx_sy, row_sy in latest_df_v.iterrows():
            m_res, f_res, rtc_res = update_eval_tags_verbose_logic_final_step(row_sy, latest_df_v)
            latest_df_v.at[idx_sy, 'memo'] = m_res
            latest_df_v.at[idx_sy, 'next_buy_flag'] = f_res
            latest_df_v.at[idx_sy, 'base_rtc'] = rtc_res
        if safe_update(latest_df_v): st.success("å…¨å±¥æ­´ã®çœŸãƒ»å†è§£ææˆåŠŸ"); st.rerun()

    if not df_t6_f.empty:
        st.subheader("ğŸ› ï¸ ç‰©ç†ã‚¨ãƒ‡ã‚£ã‚¿åŒæœŸä¿®æ­£å·¥ç¨‹")
        
        df_for_editor = df_t6_f.copy()
        df_for_editor['date'] = df_for_editor['date'].apply(lambda x: x.strftime('%Y-%m-%d') if pd.notnull(x) else "")
        df_for_editor['base_rtc'] = df_for_editor['base_rtc'].apply(format_time_to_hmsf_string)
        
        edf_f_v = st.data_editor(df_for_editor.sort_values("date", ascending=False), num_rows="dynamic", use_container_width=True)
        
        if st.button("ğŸ’¾ ã‚¨ãƒ‡ã‚£ã‚¿ä¿®æ­£å†…å®¹ã‚’åŒæœŸç¢ºå®šä¿å­˜"):
            sdf_f_v = edf_f_v.copy()
            sdf_f_v['base_rtc'] = sdf_f_v['base_rtc'].apply(parse_time_string_to_seconds)
            if safe_update(sdf_f_v): st.success("ç‰©ç†åŒæœŸå®Œäº†"); st.rerun()
        
        st.divider(); st.subheader("âŒ ç‰©ç†å…¨æŠ¹æ¶ˆè©³ç´°è¨­å®š")
        cd1_v, cd2_v = st.columns(2)
        with cd1_v:
            list_r_v = sorted([str(x) for x in df_t6_f['last_race'].dropna().unique()])
            tr_del_v = st.selectbox("æŠ¹æ¶ˆãƒ¬ãƒ¼ã‚¹ç‰©ç†é¸æŠ", ["æœªé¸æŠ"] + list_r_v)
            if tr_del_v != "æœªé¸æŠ" and st.button(f"ğŸš¨ ãƒ¬ãƒ¼ã‚¹å˜ä½æŠ¹æ¶ˆå®Ÿè¡Œ"):
                if safe_update(df_t6_f[df_t6_f['last_race'] != tr_del_v]): st.rerun()
        with cd2_v:
            list_h_v = sorted([str(x) for x in df_t6_f['name'].dropna().unique()])
            target_h_multi_v = st.multiselect("æŠ¹æ¶ˆå¯¾è±¡é¦¬ç‰©ç†é¸æŠ (è¤‡æ•°å¯)", list_h_v)
            if target_h_multi_v and st.button(f"ğŸš¨ é¸æŠã—ãŸ{len(target_h_multi_v)}é ­ã‚’ç‰©ç†æŠ¹æ¶ˆ"):
                if safe_update(df_t6_f[~df_t6_f['name'].isin(target_h_multi_v)]): st.rerun()
