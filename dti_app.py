import streamlit as st
import pandas as pd
import re
import time
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# ==============================================================================
# 1. ãƒšãƒ¼ã‚¸åŸºæœ¬è¨­å®š
# ==============================================================================
st.set_page_config(
    page_title="DTI Ultimate DB",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Google Sheets æ¥ç¶šè¨­å®š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# ==============================================================================
# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†)
# ==============================================================================
@st.cache_data(ttl=300)
def get_db_data_cached():
    """
    Google Sheetsã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã†ã€‚
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹ã«ã—ã¤ã¤ã€ttl=0ã®ç›´æ¥èª­ã¿è¾¼ã¿ã«ã‚‚å¯¾å¿œå¯èƒ½ã€‚
    """
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å…¨ã‚«ãƒ©ãƒ å®šç¾©ï¼ˆåˆæœŸã‹ã‚‰ä¸€è²«ã—ãŸå®šç¾©ã‚’ç¶­æŒï¼‰
    all_cols = [
        "name", 
        "base_rtc", 
        "last_race", 
        "course", 
        "dist", 
        "notes", 
        "timestamp", 
        "f3f", 
        "l3f", 
        "race_l3f", 
        "load", 
        "memo", 
        "date", 
        "cushion", 
        "water", 
        "result_pos", 
        "result_pop", 
        "next_buy_flag"
    ]
    
    try:
        # ğŸŒŸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã‚ãšæœ€æ–°ã‚’èª­ã¿å–ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã¯ ttl=0 ã§å‘¼ã³å‡ºã—ãŒè¡Œã‚ã‚Œã‚‹
        df = conn.read(ttl=0)
        
        if df is None:
            return pd.DataFrame(columns=all_cols)
            
        if df.empty:
            return pd.DataFrame(columns=all_cols)
        
        # ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°åˆæœŸå€¤Noneã§è£œå¡«
        for col in all_cols:
            if col not in df.columns:
                df[col] = None
        
        # ãƒ‡ãƒ¼ã‚¿ã®å‹å¤‰æ›ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è©³ç´°ã«è¨˜è¿°ï¼‰
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            
        if 'result_pos' in df.columns:
            df['result_pos'] = pd.to_numeric(df['result_pos'], errors='coerce')
        
        # ğŸŒŸ ä¸‰æ®µéšã‚½ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯
        # 1. æ—¥ä»˜(æ–°ã—ã„é †) 
        # 2. ãƒ¬ãƒ¼ã‚¹å(åå‰é †) 
        # 3. ç€é †(1ç€ã‹ã‚‰)
        df = df.sort_values(
            by=["date", "last_race", "result_pos"], 
            ascending=[False, True, True]
        )
        
        # æ•°å€¤ã‚«ãƒ©ãƒ ã®å¤‰æ›ã¨NaNè£œå®Œï¼ˆ1ãƒŸãƒªã‚‚å‰Šã‚‰ãšè©³ç´°ã«ï¼‰
        if 'result_pop' in df.columns:
            df['result_pop'] = pd.to_numeric(df['result_pop'], errors='coerce')
            
        if 'f3f' in df.columns:
            df['f3f'] = pd.to_numeric(df['f3f'], errors='coerce').fillna(0.0)
            
        if 'l3f' in df.columns:
            df['l3f'] = pd.to_numeric(df['l3f'], errors='coerce').fillna(0.0)
            
        if 'race_l3f' in df.columns:
            df['race_l3f'] = pd.to_numeric(df['race_l3f'], errors='coerce').fillna(0.0)
            
        if 'load' in df.columns:
            df['load'] = pd.to_numeric(df['load'], errors='coerce').fillna(0.0)
            
        if 'base_rtc' in df.columns:
            df['base_rtc'] = pd.to_numeric(df['base_rtc'], errors='coerce').fillna(0.0)
            
        # å…¨ã¦ã®è¡ŒãŒç©ºã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–
        df = df.dropna(how='all')
        
        return df
        
    except Exception as e:
        st.error(f"ã€é‡å¤§ãªè­¦å‘Šã€‘ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚è©³ç´°ãªåŸå› ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")
        return pd.DataFrame(columns=all_cols)

def get_db_data():
    """get_db_data_cachedã¸ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹"""
    return get_db_data_cached()

# ==============================================================================
# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°ãƒ­ã‚¸ãƒƒã‚¯ (å®‰å…¨ãªä¸Šæ›¸ã)
# ==============================================================================
def safe_update(df):
    """
    Google Sheetsã¸ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãæˆ»ã™ã€‚
    ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã€ã‚½ãƒ¼ãƒˆã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚»ãƒƒãƒˆã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã‚’å«ã‚€ã€‚
    """
    # ä¿å­˜ç›´å‰ã«æ•´åˆæ€§ã‚’ç¢ºä¿
    if 'date' in df.columns:
        if 'last_race' in df.columns:
            if 'result_pos' in df.columns:
                df['date'] = pd.to_datetime(df['date'], errors='coerce')
                df['result_pos'] = pd.to_numeric(df['result_pos'], errors='coerce')
                df = df.sort_values(
                    by=["date", "last_race", "result_pos"], 
                    ascending=[False, True, True]
                )
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä¸ä¸€è‡´ã«ã‚ˆã‚‹ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ
    df = df.reset_index(drop=True)
    
    max_retries = 3
    for i in range(max_retries):
        try:
            # ğŸŒŸ æœ€æ–°çŠ¶æ…‹ã§ã®ä¸Šæ›¸ãã‚’å®Ÿè¡Œ
            conn.update(data=df)
            
            # ğŸŒŸ é‡è¦ï¼šæˆåŠŸæ™‚ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å¼·åˆ¶ã‚¯ãƒªã‚¢ã—ã¦ã€åŒæœŸä¸å…¨ã‚’å®Œå…¨ã«è§£æ¶ˆ
            st.cache_data.clear()
            
            return True
            
        except Exception as e:
            wait_time = 5
            if i < max_retries - 1:
                st.warning(f"Google Sheetsæ¥ç¶šã‚¨ãƒ©ãƒ¼(è©¦è¡Œ {i+1}/3å›ç›®)... {wait_time}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™ã€‚")
                time.sleep(wait_time)
                continue
            else:
                st.error(f"Google Sheetsã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„: {e}")
                return False

# ==============================================================================
# 4. è£œåŠ©é–¢æ•° (ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆç­‰)
# ==============================================================================
def format_time(seconds):
    """ç§’æ•°ã‚’ mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›"""
    if seconds is None:
        return ""
    if seconds <= 0:
        return ""
    if pd.isna(seconds):
        return ""
    if isinstance(seconds, str):
        return seconds
        
    minutes_val = int(seconds // 60)
    seconds_val = seconds % 60
    return f"{minutes_val}:{seconds_val:04.1f}"

def parse_time_str(time_str):
    """mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã‚’ç§’æ•°(float)ã«å¤‰æ›"""
    if time_str is None:
        return 0.0
    try:
        if ":" in str(time_str):
            minutes_part, seconds_part = map(float, str(time_str).split(':'))
            return minutes_part * 60 + seconds_part
        return float(time_str)
    except:
        return 0.0

# ==============================================================================
# 5. ä¿‚æ•°ãƒã‚¹ã‚¿ (è©³ç´°æ•°å€¤å®Œå…¨å¾©å…ƒ)
# ==============================================================================
COURSE_DATA = {
    "æ±äº¬": 0.10, 
    "ä¸­å±±": 0.25, 
    "äº¬éƒ½": 0.15, 
    "é˜ªç¥": 0.18, 
    "ä¸­äº¬": 0.20,
    "æ–°æ½Ÿ": 0.05, 
    "å°å€‰": 0.30, 
    "ç¦å³¶": 0.28, 
    "æœ­å¹Œ": 0.22, 
    "å‡½é¤¨": 0.25
}

DIRT_COURSE_DATA = {
    "æ±äº¬": 0.40, 
    "ä¸­å±±": 0.55, 
    "äº¬éƒ½": 0.45, 
    "é˜ªç¥": 0.48, 
    "ä¸­äº¬": 0.50,
    "æ–°æ½Ÿ": 0.42, 
    "å°å€‰": 0.58, 
    "ç¦å³¶": 0.60, 
    "æœ­å¹Œ": 0.62, 
    "å‡½é¤¨": 0.65
}

SLOPE_FACTORS = {
    "ä¸­å±±": 0.005, 
    "ä¸­äº¬": 0.004, 
    "äº¬éƒ½": 0.002, 
    "é˜ªç¥": 0.004, 
    "æ±äº¬": 0.003,
    "æ–°æ½Ÿ": 0.001, 
    "å°å€‰": 0.002, 
    "ç¦å³¶": 0.003, 
    "æœ­å¹Œ": 0.001, 
    "å‡½é¤¨": 0.002
}

# ==============================================================================
# 6. ãƒ¡ã‚¤ãƒ³UIæ§‹æˆ - ã‚¿ãƒ–è¨­å®š
# ==============================================================================
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ è§£æãƒ»ä¿å­˜", 
    "ğŸ é¦¬åˆ¥å±¥æ­´", 
    "ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´", 
    "ğŸ¯ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", 
    "ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰", 
    "ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"
])

# ==============================================================================
# 7. Tab 1: è§£æãƒ»ä¿å­˜
# ==============================================================================
with tab1:
    # æ³¨ç›®é¦¬ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—
    df_pickup = get_db_data()
    if not df_pickup.empty:
        st.subheader("ğŸ¯ æ¬¡èµ°æ³¨ç›®é¦¬ï¼ˆé€†è¡Œè©•ä¾¡ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰")
        pickup_rows = []
        for i, row in df_pickup.iterrows():
            memo_text = str(row['memo'])
            bias_é€†è¡Œ = "ğŸ’" in memo_text
            pace_é€†è¡Œ = "ğŸ”¥" in memo_text
            
            if bias_é€†è¡Œ or pace_é€†è¡Œ:
                target_type = ""
                if bias_é€†è¡Œ and pace_é€†è¡Œ:
                    target_type = "ã€ğŸ’¥ä¸¡æ–¹é€†è¡Œã€‘"
                elif bias_é€†è¡Œ:
                    target_type = "ã€ğŸ’ãƒã‚¤ã‚¢ã‚¹é€†è¡Œã€‘"
                elif pace_é€†è¡Œ:
                    target_type = "ã€ğŸ”¥ãƒšãƒ¼ã‚¹é€†è¡Œã€‘"
                
                pickup_rows.append({
                    "é¦¬å": row['name'], 
                    "é€†è¡Œã‚¿ã‚¤ãƒ—": target_type, 
                    "å‰èµ°": row['last_race'],
                    "æ—¥ä»˜": row['date'].strftime('%Y-%m-%d') if not pd.isna(row['date']) else "", 
                    "è§£æãƒ¡ãƒ¢": memo_text
                })
        
        if pickup_rows:
            st.dataframe(
                pd.DataFrame(pickup_rows).sort_values("æ—¥ä»˜", ascending=False), 
                use_container_width=True, 
                hide_index=True
            )
            
    st.divider()

    st.header("ğŸš€ ãƒ¬ãƒ¼ã‚¹è§£æ & è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    with st.sidebar:
        st.title("è§£ææ¡ä»¶è¨­å®š")
        analysis_race_name = st.text_input("ãƒ¬ãƒ¼ã‚¹å (ä¾‹: æœ‰é¦¬è¨˜å¿µ)")
        analysis_race_date = st.date_input("ãƒ¬ãƒ¼ã‚¹å®Ÿæ–½æ—¥", datetime.now())
        analysis_course_name = st.selectbox("ç«¶é¦¬å ´é¸æŠ", list(COURSE_DATA.keys()))
        analysis_track_type = st.radio("ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
        dist_opts = list(range(1000, 3700, 100))
        analysis_dist = st.selectbox("è·é›¢ (m)", dist_opts, index=dist_opts.index(1600))
        st.divider()
        st.write("ğŸ’§ é¦¬å ´ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³è©³ç´°")
        analysis_cushion = st.number_input("ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤ (èŠã®ã¿)", 7.0, 12.0, 9.5, step=0.1) if analysis_track_type == "èŠ" else 9.5
        analysis_water_4c = st.number_input("å«æ°´ç‡ï¼š4è§’åœ°ç‚¹ (%)", 0.0, 50.0, 10.0, step=0.1)
        analysis_water_goal = st.number_input("å«æ°´ç‡ï¼šã‚´ãƒ¼ãƒ«å‰åœ°ç‚¹ (%)", 0.0, 50.0, 10.0, step=0.1)
        analysis_track_idx = st.number_input("é¦¬å ´æŒ‡æ•°", -50, 50, 0, step=1)
        analysis_bias_val = st.slider("é¦¬å ´ãƒã‚¤ã‚¢ã‚¹ (å†…æœ‰åˆ© -1.0 â†” å¤–æœ‰åˆ© +1.0)", -1.0, 1.0, 0.0, step=0.1)
        analysis_track_week = st.number_input("é–‹å‚¬é€± (ä¾‹: 1, 8)", 1, 12, 1)

    col_analysis1, col_analysis2 = st.columns(2)
    
    with col_analysis1: 
        st.markdown("##### ğŸ ãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—å…¥åŠ›")
        analysis_lap_input = st.text_area("JRAãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ— (ä¾‹: 12.5-11.0-12.0...)", height=150)
        
        calc_f3f_val = 0.0
        calc_l3f_val = 0.0
        calc_pace_status = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        calc_pace_diff = 0.0
        
        if analysis_lap_input:
            found_laps = [float(x) for x in re.findall(r'\d+\.\d', analysis_lap_input)]
            if len(found_laps) >= 3:
                calc_f3f_val = sum(found_laps[:3])
                calc_l3f_val = sum(found_laps[-3:])
                calc_pace_diff = calc_f3f_val - calc_l3f_val
                
                # è·é›¢åˆ¥ã®å‹•çš„ãƒšãƒ¼ã‚¹ã—ãã„å€¤
                pace_threshold = 1.0 * (analysis_dist / 1600.0)
                
                if calc_pace_diff < -pace_threshold:
                    calc_pace_status = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                elif calc_pace_diff > pace_threshold:
                    calc_pace_status = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                    
                st.success(f"ãƒ©ãƒƒãƒ—è§£æå®Œäº†: å‰3F {calc_f3f_val:.1f} / å¾Œ3F {calc_l3f_val:.1f} ({calc_pace_status})")
        
        analysis_final_l3f = st.number_input("ãƒ¬ãƒ¼ã‚¹ä¸ŠãŒã‚Š3F (è‡ªå‹•è¨ˆç®—ã‹ã‚‰ä¿®æ­£å¯)", 0.0, 60.0, calc_l3f_val, step=0.1)

    with col_analysis2: 
        st.markdown("##### ğŸ æˆç¸¾è¡¨è²¼ã‚Šä»˜ã‘")
        analysis_raw_input = st.text_area("JRAå…¬å¼ã‚µã‚¤ãƒˆã®æˆç¸¾è¡¨ã‚’ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=250)

    # ğŸŒŸ ã€å®Œå…¨å¾©å…ƒã€‘è§£ææ–¤é‡ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if analysis_raw_input and calc_f3f_val > 0:
        st.markdown("##### âš–ï¸ è§£æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæ–¤é‡ã®ç¢ºèªãƒ»ä¿®æ­£ï¼‰")
        input_lines = [l.strip() for l in analysis_raw_input.split('\n') if len(l.strip()) > 15]
        
        list_for_preview = []
        for line in input_lines:
            match_name = re.findall(r'([ã‚¡-ãƒ¶ãƒ¼]{2,})', line)
            if not match_name:
                continue
                
            # æ–¤é‡ã®æŠ½å‡º
            match_weight = re.search(r'\s([4-6]\d\.\d)\s', line)
            auto_extracted_w = float(match_weight.group(1)) if match_weight else 56.0
            
            list_for_preview.append({
                "é¦¬å": match_name[0], 
                "æ–¤é‡": auto_extracted_w, 
                "raw_line": line
            })
        
        # è©³ç´°ãªã‚¨ãƒ‡ã‚£ã‚¿è¡¨ç¤º
        df_editor_preview = st.data_editor(
            pd.DataFrame(list_for_preview), 
            use_container_width=True, 
            hide_index=True
        )

        if st.button("ğŸš€ ã“ã®å†…å®¹ã§è§£æã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ä¿å­˜"):
            if not analysis_race_name:
                st.error("ãƒ¬ãƒ¼ã‚¹åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            else:
                parsed_list = []
                for idx_pre, row_pre in df_editor_preview.iterrows():
                    current_line_text = row_pre["raw_line"]
                    
                    time_match_main = re.search(r'(\d{1,2}:\d{2}\.\d)', current_line_text)
                    if not time_match_main:
                        continue
                    
                    # ç€é †ã®å–å¾—
                    match_pos_rank = re.match(r'^(\d{1,2})', current_line_text)
                    res_pos_val = int(match_pos_rank.group(1)) if match_pos_rank else 99
                    
                    # 4è§’é€šéé †ä½ã®è©³ç´°å–å¾—
                    string_after_time = current_line_text[time_match_main.end():]
                    list_of_positions = re.findall(r'\b([1-2]?\d)\b', string_after_time)
                    final_four_c_pos = 7.0 
                    
                    if list_of_positions:
                        valid_pos_collected = []
                        for p_str in list_of_positions:
                            p_num = int(p_str)
                            if p_num > 30: # ç•°å¸¸å€¤ï¼ˆé¦¬ä½“é‡ç­‰ï¼‰ã®æ··å…¥é˜²æ­¢
                                if len(valid_pos_collected) > 0:
                                    break
                            valid_pos_collected.append(float(p_num))
                        
                        if valid_pos_collected:
                            final_four_c_pos = valid_pos_collected[-1]
                    
                    parsed_list.append({
                        "line": current_line_text, 
                        "res_pos": res_pos_val, 
                        "four_c_pos": final_four_c_pos, 
                        "name": row_pre["é¦¬å"], 
                        "weight": row_pre["æ–¤é‡"]
                    })
                
                # --- ãƒã‚¤ã‚¢ã‚¹åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ4ç€è£œå……ç‰¹ä¾‹ã‚’å®Œå…¨å±•é–‹ï¼‰ ---
                top_3_parsed = sorted(
                    [d for d in parsed_list if d["res_pos"] <= 3], 
                    key=lambda x: x["res_pos"]
                )
                
                # 10ç•ªæ‰‹ä»¥ä¸‹ã€ã‚ã‚‹ã„ã¯3ç•ªæ‰‹ä»¥å†…ã®æ¥µç«¯ãªé¦¬
                bias_outliers = [
                    d for d in top_3_parsed 
                    if d["four_c_pos"] >= 10.0 or d["four_c_pos"] <= 3.0
                ]
                
                if len(bias_outliers) == 1:
                    # 1é ­ã®ã¿æ¥µç«¯ãªã‚±ãƒ¼ã‚¹ï¼šãã®é¦¬ã‚’é™¤ãã€4ç€ã‚’è£œå……
                    bias_base_entries = [d for d in top_3_parsed if d != bias_outliers[0]]
                    fourth_horse = [d for d in parsed_list if d["res_pos"] == 4]
                    final_bias_set = bias_base_entries + fourth_horse
                else:
                    # ãã‚Œä»¥å¤–ï¼šé€šå¸¸ã®ä¸Šä½3é ­
                    final_bias_set = top_3_parsed
                
                if final_bias_set:
                    avg_c4_pos = sum(d["four_c_pos"] for d in final_bias_set) / len(final_bias_set)
                else:
                    avg_c4_pos = 7.0
                    
                if avg_c4_pos <= 4.0:
                    determined_bias_type = "å‰æœ‰åˆ©"
                elif avg_c4_pos >= 10.0:
                    determined_bias_type = "å¾Œæœ‰åˆ©"
                else:
                    determined_bias_type = "ãƒ•ãƒ©ãƒƒãƒˆ"
                
                # æœ€å¤§å‡ºèµ°é ­æ•°ã®ç‰¹å®š
                max_field_size = max([d["res_pos"] for d in parsed_list]) if parsed_list else 16

                final_new_rows = []
                for entry_p in parsed_list:
                    p_line = entry_p["line"]
                    p_last_pos = entry_p["four_c_pos"]
                    p_res_pos = entry_p["res_pos"]
                    p_weight = entry_p["weight"] 
                    
                    # ã‚¿ã‚¤ãƒ è¨ˆç®—
                    t_match = re.search(r'(\d{1,2}:\d{2}\.\d)', p_line)
                    t_str = t_match.group(1)
                    m_val, s_val = map(float, t_str.split(':'))
                    total_seconds = m_val * 60 + s_val
                    
                    # é¦¬ä½“é‡è©³ç´°
                    match_h_weight = re.search(r'(\d{3})kg', p_line)
                    string_h_weight = f"({match_h_weight.group(1)}kg)" if match_h_weight else ""

                    # å€‹åˆ¥ä¸ŠãŒã‚Š
                    p_l3f_indiv = 0.0
                    match_l3f_bracket = re.search(r'(\d{2}\.\d)\s*\d{3}\(', p_line)
                    if match_l3f_bracket:
                        p_l3f_indiv = float(match_l3f_bracket.group(1))
                    else:
                        found_decimals = re.findall(r'(\d{2}\.\d)', p_line)
                        for d_val in found_decimals:
                            dv = float(d_val)
                            if 30.0 <= dv <= 46.0:
                                if abs(dv - p_weight) > 0.5:
                                    p_l3f_indiv = dv
                                    break
                    if p_l3f_indiv == 0.0:
                        p_l3f_indiv = analysis_final_l3f 
                    
                    # --- ã€å®Œå…¨å¾©å…ƒã€‘é ­æ•°ãƒ»éç·šå½¢è² è·ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ---
                    relative_pos_ratio = p_last_pos / max_field_size
                    # 16é ­åŸºæº–ã®å¼·åº¦è£œæ­£
                    intensity_coeff = max_field_size / 16.0
                    
                    computed_load_score = 0.0
                    if calc_pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹":
                        if determined_bias_type != "å‰æœ‰åˆ©":
                            load_val = (0.6 - relative_pos_ratio) * abs(pace_diff) * 3.0
                            computed_load_score += max(0.0, load_val) * intensity_coeff
                            
                    elif calc_pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹":
                        if determined_bias_type != "å¾Œæœ‰åˆ©":
                            load_val = (relative_pos_ratio - 0.4) * abs(pace_diff) * 2.0
                            computed_load_score += max(0.0, load_val) * intensity_coeff
                    
                    # é€†è¡Œã‚¿ã‚°è©³ç´°
                    tag_list = []
                    is_counter_flag = False
                    
                    if p_res_pos <= 5:
                        # ãƒã‚¤ã‚¢ã‚¹é€†è¡Œ
                        if determined_bias_type == "å‰æœ‰åˆ©":
                            if p_last_pos >= 10.0:
                                t = "ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_field_size >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ"
                                tag_list.append(t)
                                is_counter_flag = True
                        elif determined_bias_type == "å¾Œæœ‰åˆ©":
                            if p_last_pos <= 3.0:
                                t = "ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_field_size >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ"
                                tag_list.append(t)
                                is_counter_flag = True
                                
                    # å±•é–‹é€†è¡Œ
                    favored_pace_bias = False
                    if calc_pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹":
                        if determined_bias_type == "å‰æœ‰åˆ©":
                            favored_pace_bias = True
                    elif calc_pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹":
                        if determined_bias_type == "å¾Œæœ‰åˆ©":
                            favored_pace_bias = True
                            
                    if favored_pace_bias == False:
                        if calc_pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹":
                            if p_last_pos <= 3.0:
                                tag_list.append("ğŸ“‰ æ¿€æµè¢«å®³" if max_field_size >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ")
                                is_counter_target_flag = True
                                is_counter_flag = True
                        elif calc_pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹":
                            if p_last_pos >= 10.0:
                                if (calc_f3f_val - p_l3f_indiv) > 1.5:
                                    tag_list.append("ğŸ”¥ å±•é–‹é€†è¡Œ")
                                    is_counter_flag = True
                    
                    # å±•é–‹æ©æµï¼ˆå°‘é ­æ•°ï¼‰
                    if max_field_size <= 10:
                        if calc_pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹":
                            if p_res_pos <= 2:
                                tag_list.append("ğŸŸ¢ å±•é–‹æ©æµ")

                    # ä¸ŠãŒã‚Šè©•ä¾¡
                    l3f_diff_val = analysis_final_l3f - p_l3f_indiv
                    if l3f_diff_val >= 0.5:
                        tag_list.append("ğŸš€ ã‚¢ã‚¬ãƒªå„ªç§€")
                    elif l3f_diff_val <= -1.0:
                        tag_list.append("ğŸ“‰ å¤±é€Ÿå¤§")
                    
                    # ä¸­ç›¤ãƒ©ãƒƒãƒ—è§£æè©³ç´°
                    mid_label = "å¹³"
                    if analysis_dist > 1200:
                        m_lap_calc = (total_seconds - calc_f3f_val - p_l3f_indiv) / ((analysis_dist - 1200) / 200)
                        if m_lap_calc >= 12.8:
                            mid_label = "ç·©"
                        elif m_lap_calc <= 11.8:
                            mid_label = "ç· "
                    else:
                        mid_label = "çŸ­"

                    field_size_tag = "å¤š" if max_field_size >= 16 else "å°‘" if max_field_size <= 10 else "ä¸­"
                    combined_memo = f"ã€{calc_pace_status}/{determined_bias_type}/è² è·:{computed_load_score:.1f}({field_size_tag})/{mid_label}ã€‘{'/'.join(tag_list) if tag_list else 'é †å¢ƒ'}"
                    
                    # æŒ‡æ•°è¨ˆç®—
                    week_offset = (analysis_track_week - 1) * 0.05
                    water_avg = (analysis_water_4c + analysis_water_goal) / 2.0
                    
                    # ğŸŒŸ RTCæŒ‡æ•°ã®å®Œå…¨è¨ˆç®—å¼
                    computed_rtc = (total_seconds - (p_weight - 56.0) * 0.1 - analysis_track_idx / 10.0 - computed_load_score / 10.0 - week_offset) + analysis_bias_val - (water_avg - 10.0) * 0.05 - (9.5 - analysis_cushion) * 0.1 + (analysis_dist - 1600) * 0.0005
                    
                    final_new_rows.append({
                        "name": entry_p["name"], 
                        "base_rtc": computed_rtc, 
                        "last_race": analysis_race_name, 
                        "course": analysis_course_name, 
                        "dist": analysis_dist, 
                        "notes": f"{p_weight}kg{string_h_weight}", 
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"), 
                        "f3f": calc_f3f_val, 
                        "l3f": p_l3f_indiv, 
                        "race_l3f": analysis_final_l3f, 
                        "load": p_last_pos, 
                        "memo": combined_memo,
                        "date": analysis_race_date.strftime("%Y-%m-%d"), 
                        "cushion": analysis_cushion, 
                        "water": water_avg, 
                        "next_buy_flag": "â˜…é€†è¡Œç‹™ã„" if is_counter_flag else "", 
                        "result_pos": p_res_pos
                    })
                
                if final_new_rows:
                    # ğŸŒŸ åŒæœŸä¸å…¨è§£æ¶ˆï¼šä¿å­˜ç›´å‰ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ç ´æ£„ã—ã¦æœ€æ–°ã‚·ãƒ¼ãƒˆã‚’èª­ã¿ç›´ã™
                    st.cache_data.clear()
                    current_sheet_df = conn.read(ttl=0)
                    
                    # èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦æ­£è¦åŒ–
                    for c_name in all_cols:
                        if c_name not in current_sheet_df.columns:
                            current_sheet_df[c_name] = None
                            
                    combined_final_df = pd.concat([current_sheet_df, pd.DataFrame(final_new_rows)], ignore_index=True)
                    
                    if safe_update(combined_final_df):
                        st.success(f"âœ… è§£æå®Œäº†ï¼{len(final_new_rows)}é ­ã®æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã—ã€åŒæœŸã—ã¾ã—ãŸã€‚")
                        st.rerun()

# ==============================================================================
# 8. Tab 2: é¦¬åˆ¥å±¥æ­´
# ==============================================================================
with tab2:
    st.header("ğŸ“Š é¦¬åˆ¥å±¥æ­´ & è²·ã„æ¡ä»¶è¨­å®š")
    df_tab2 = get_db_data()
    if not df_tab2.empty:
        col_t2_1, col_t2_2 = st.columns([1, 1])
        with col_t2_1:
            search_horse_name = st.text_input("é¦¬åã§çµã‚Šè¾¼ã¿æ¤œç´¢", key="search_horse_input_t2")
        
        unique_horse_list = sorted([str(x) for x in df_tab2['name'].dropna().unique()])
        with col_t2_2:
            target_horse_edit = st.selectbox("å€‹åˆ¥ãƒ¡ãƒ¢ãƒ»æ¡ä»¶ç·¨é›†å¯¾è±¡", ["æœªé¸æŠ"] + unique_horse_list)
        
        if target_horse_edit != "æœªé¸æŠ":
            idx_list = df_tab2[df_tab2['name'] == target_horse_edit].index
            target_idx = idx_list[-1]
            
            with st.form("edit_horse_form_tab2"):
                current_m = df_tab2.at[target_idx, 'memo'] if not pd.isna(df_tab2.at[target_idx, 'memo']) else ""
                new_m = st.text_area("ãƒ¡ãƒ¢ãƒ»è©•ä¾¡", value=current_m)
                
                current_f = df_tab2.at[target_idx, 'next_buy_flag'] if not pd.isna(df_tab2.at[target_idx, 'next_buy_flag']) else ""
                new_f = st.text_input("å€‹åˆ¥è²·ã„ãƒ•ãƒ©ã‚°", value=current_f)
                
                if st.form_submit_button("è¨­å®šä¿å­˜"):
                    df_tab2.at[target_idx, 'memo'] = new_m
                    df_tab2.at[target_idx, 'next_buy_flag'] = new_f
                    if safe_update(df_tab2):
                        st.success(f"{target_horse_edit} ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                        st.rerun()
        
        if search_horse_name:
            df_tab2_display = df_tab2[df_tab2['name'].str.contains(search_horse_name, na=False)]
        else:
            df_tab2_display = df_tab2
            
        df_tab2_formatted = df_tab2_display.copy()
        df_tab2_formatted['base_rtc'] = df_tab2_formatted['base_rtc'].apply(format_time)
        st.dataframe(
            df_tab2_formatted.sort_values("date", ascending=False)[["date", "name", "last_race", "base_rtc", "f3f", "l3f", "race_l3f", "load", "memo", "next_buy_flag"]], 
            use_container_width=True
        )

# ==============================================================================
# 9. Tab 3: ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´
# ==============================================================================
with tab3:
    st.header("ğŸ ç­”ãˆåˆã‚ã› & ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´")
    df_tab3 = get_db_data()
    if not df_tab3.empty:
        race_list_all = sorted([str(x) for x in df_tab3['last_race'].dropna().unique()])
        selected_race_tab3 = st.selectbox("ãƒ¬ãƒ¼ã‚¹é¸æŠ", race_list_all)
        
        if selected_race_tab3:
            df_race_tab3 = df_tab3[df_tab3['last_race'] == selected_race_tab3].copy()
            with st.form("race_result_form_tab3"):
                st.write(f"ã€{selected_race_tab3}ã€‘ã®çµæœã‚’å…¥åŠ›")
                for idx_r, row_r in df_race_tab3.iterrows():
                    v_pos = int(row_r['result_pos']) if not pd.isna(row_r['result_pos']) else 0
                    v_pop = int(row_r['result_pop']) if not pd.isna(row_r['result_pop']) else 0
                    
                    c_r1, c_r2 = st.columns(2)
                    with c_r1:
                        df_race_tab3.at[idx_r, 'result_pos'] = st.number_input(f"{row_r['name']} ç€é †", 0, 100, value=v_pos, key=f"pos_{idx_r}")
                    with c_r2:
                        df_race_tab3.at[idx_r, 'result_pop'] = st.number_input(f"{row_r['name']} äººæ°—", 0, 100, value=v_pop, key=f"pop_{idx_r}")
                
                if st.form_submit_button("çµæœã‚’ä¸€æ‹¬ä¿å­˜"):
                    for idx_r, row_r in df_race_tab3.iterrows():
                        df_tab3.at[idx_r, 'result_pos'] = row_r['result_pos']
                        df_tab3.at[idx_r, 'result_pop'] = row_r['result_pop']
                    if safe_update(df_tab3):
                        st.success("çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
                        st.rerun()
            
            df_race_formatted = df_race_tab3.copy()
            df_race_formatted['base_rtc'] = df_race_formatted['base_rtc'].apply(format_time)
            st.dataframe(df_race_formatted[["name", "notes", "base_rtc", "f3f", "l3f", "race_l3f", "result_pos", "result_pop"]], use_container_width=True)

# ==============================================================================
# 10. Tab 4: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ (å€‹åˆ¥æ–¤é‡ãƒ»éå»3èµ°ãƒ«ãƒ¼ãƒ—ãƒ»é ­æ•°é€£å‹•)
# ==============================================================================
with tab4:
    st.header("ğŸ¯ æ¬¡èµ°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ & çµ±åˆè©•ä¾¡")
    df_tab4 = get_db_data()
    if not df_tab4.empty:
        horse_names_tab4 = sorted([str(x) for x in df_tab4['name'].dropna().unique()])
        selected_sim_horses = st.multiselect("å‡ºèµ°äºˆå®šé¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„", options=horse_names_tab4)
        
        sim_input_pops = {}
        sim_input_gates = {}
        sim_input_weights = {}
        
        if selected_sim_horses:
            st.markdown("##### ğŸ“ æ ç•ªãƒ»äºˆæƒ³äººæ°—ãƒ»æƒ³å®šæ–¤é‡ã®å€‹åˆ¥å…¥åŠ›")
            sim_cols = st.columns(min(len(selected_sim_horses), 4))
            for i, h_name in enumerate(selected_sim_horses):
                with sim_cols[i % 4]:
                    h_latest = df_tab4[df_tab4['name'] == h_name].iloc[-1]
                    sim_input_gates[h_name] = st.number_input(f"{h_name} æ ", 1, 18, value=1, key=f"sg_{h_name}")
                    sim_input_pops[h_name] = st.number_input(f"{h_name} äººæ°—", 1, 18, value=int(h_latest['result_pop']) if not pd.isna(h_latest['result_pop']) else 10, key=f"sp_{h_name}")
                    # å€‹åˆ¥æ–¤é‡å…¥åŠ›
                    sim_input_weights[h_name] = st.number_input(f"{h_name} æ–¤é‡", 48.0, 62.0, 56.0, step=0.5, key=f"sw_{h_name}")

            col_sim1, col_sim2 = st.columns(2)
            with col_sim1: 
                sim_course = st.selectbox("æ¬¡èµ°ç«¶é¦¬å ´", list(COURSE_DATA.keys()), key="sc_select")
                sim_dist = st.selectbox("è·é›¢ (m)", list(range(1000, 3700, 100)), index=6)
                sim_track = st.radio("æ¬¡èµ°ãƒˆãƒ©ãƒƒã‚¯", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
            with col_sim2: 
                sim_cushion = st.slider("æƒ³å®šã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤", 7.0, 12.0, 9.5)
                sim_water = st.slider("æƒ³å®šå«æ°´ç‡ (%)", 0.0, 30.0, 10.0)
            
            if st.button("ğŸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
                results_sim = []
                num_total_sim = len(selected_sim_horses)
                styles_sim = {"é€ƒã’": 0, "å…ˆè¡Œ": 0, "å·®ã—": 0, "è¿½è¾¼": 0}
                avg_l3f_db = df_tab4['l3f'].mean()

                for h_name in selected_sim_horses:
                    h_history = df_tab4[df_tab4['name'] == h_name].sort_values("date")
                    last_3_runs = h_history.tail(3)
                    conv_rtc_list = []
                    
                    # è„šè³ªåˆ¤å®šè©³ç´°
                    avg_load_3r = last_3_runs['load'].mean()
                    if avg_load_3r <= 3.5: 
                        h_style = "é€ƒã’"
                    elif avg_load_3r <= 7.0: 
                        h_style = "å…ˆè¡Œ"
                    elif avg_load_3r <= 11.0: 
                        h_style = "å·®ã—"
                    else: 
                        h_style = "è¿½è¾¼"
                    styles_sim[h_style] += 1

                    # æ¸‹æ»ãƒªã‚¹ã‚¯
                    jam_label = "âš ï¸è©°ã¾ã‚Šæ³¨æ„" if num_total_sim >= 15 and h_style in ["å·®ã—", "è¿½è¾¼"] and sim_input_gates[h_name] <= 4 else "-"
                    # ã‚¹ãƒ­ãƒ¼é©æ€§
                    slow_label = "-"
                    if num_total_sim <= 10:
                        h_min_l3f = h_history['l3f'].min()
                        if h_min_l3f < avg_l3f_db - 0.5:
                            slow_label = "âš¡ã‚¹ãƒ­ãƒ¼ç‰¹åŒ–"
                        elif h_min_l3f > avg_l3f_db + 0.5:
                            slow_label = "ğŸ“‰ç¬ç™ºåŠ›ä¸è¶³"

                    h_std = h_history['base_rtc'].std() if len(h_history) >= 3 else 0.0
                    h_stab = "âš–ï¸å®‰å®š" if 0 < h_std < 0.2 else "ğŸ¢ãƒ ãƒ©" if h_std > 0.4 else "-"
                    
                    h_best_past = h_history.loc[h_history['base_rtc'].idxmin()]
                    h_apt = "ğŸ¯é¦¬å ´â—" if abs(h_best_past['cushion'] - sim_cushion) <= 0.5 and abs(h_best_past['water'] - sim_water) <= 2.0 else "-"

                    # ğŸŒŸ ã€å®Œå…¨å¾©æ—§ã€‘éå»3èµ°ã™ã¹ã¦ã®æ–¤é‡å€‹åˆ¥è¨ˆç®—ãƒ«ãƒ¼ãƒ—
                    for i_r, row_r in last_3_runs.iterrows():
                        p_dist_r = row_r['dist']
                        p_rtc_r = row_r['base_rtc']
                        p_course_r = row_r['course']
                        p_load_r = row_r['load']
                        p_notes_r = str(row_r['notes'])
                        
                        p_w_r = 56.0
                        h_bw_r = 480.0
                        
                        w_match_r = re.search(r'([4-6]\d\.\d)', p_notes_r)
                        if w_match_r:
                            p_w_r = float(w_match_r.group(1))
                            
                        hb_match_r = re.search(r'\((\d{3})kg\)', p_notes_r)
                        if hb_match_r:
                            h_bw_r = float(hb_match_r.group(1))
                        
                        if p_dist_r > 0:
                            l_adj = (p_load_r - 7.0) * 0.02
                            # æ–¤é‡æ„Ÿå¿œåº¦
                            sens_f = 0.15 if h_bw_r <= 440 else 0.08 if h_bw_r >= 500 else 0.1
                            w_diff = (sim_input_weights[h_name] - p_w_r) * sens_f
                            
                            # æŒ‡æ•°å¤‰æ›
                            b_conv = (p_rtc_r + l_adj + w_diff) / p_dist_r * sim_dist
                            # å‚è£œæ­£
                            s_adj = (SLOPE_FACTORS.get(sim_course, 0.002) - SLOPE_FACTORS.get(p_course_r, 0.002)) * sim_dist
                            conv_rtc_list.append(b_conv + s_adj)
                    
                    avg_rtc_res = sum(conv_rtc_list) / len(conv_rtc_list) if conv_rtc_list else 0
                    
                    # è·é›¢å®Ÿç¸¾è£œæ­£
                    h_best_d = h_history.loc[h_history['base_rtc'].idxmin(), 'dist']
                    avg_rtc_res += (abs(sim_dist - h_best_d) / 100) * 0.05
                    
                    # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
                    h_mom = "-"
                    if len(h_history) >= 2:
                        if h_history.iloc[-1]['base_rtc'] < h_history.iloc[-2]['base_rtc'] - 0.2:
                            h_mom = "ğŸ“ˆä¸Šæ˜‡"
                            avg_rtc_res -= 0.15

                    # æ Ã—ãƒã‚¤ã‚¢ã‚¹
                    syn_bias = -0.2 if (sim_input_gates[h_name] <= 4 and analysis_bias_val <= -0.5) or (sim_input_gates[h_name] >= 13 and analysis_bias_val >= 0.5) else 0
                    avg_rtc_res += syn_bias

                    # ã‚³ãƒ¼ã‚¹å®Ÿç¸¾
                    h_c_bonus = -0.2 if any((h_history['course'] == sim_course) & (h_history['result_pos'] <= 3)) else 0.0
                    
                    # æœ€çµ‚ã‚¢ã‚¸ãƒ£ã‚¹ãƒˆ
                    w_adj_f = (sim_water - 10.0) * 0.05
                    c_dict_f = DIRT_COURSE_DATA if sim_track == "ãƒ€ãƒ¼ãƒˆ" else COURSE_DATA
                    if sim_track == "ãƒ€ãƒ¼ãƒˆ":
                        w_adj_f = -w_adj_f
                    
                    final_rtc_sim = (avg_rtc_res + (c_dict_f[sim_course] * (sim_dist/1600.0)) + h_c_bonus + w_adj_f - (9.5 - sim_cushion) * 0.1)
                    
                    h_lat = last_3_runs.iloc[-1]
                    results_sim.append({
                        "é¦¬å": h_name, 
                        "è„šè³ª": h_style, 
                        "æƒ³å®šã‚¿ã‚¤ãƒ ": final_rtc_sim, 
                        "æ¸‹æ»": jam_label, 
                        "ã‚¹ãƒ­ãƒ¼": slow_label, 
                        "é©æ€§": h_apt, 
                        "å®‰å®š": h_stab, 
                        "åå·®": "â¤´ï¸è¦šé†’æœŸå¾…" if final_rtc_sim < h_history['base_rtc'].min() - 0.3 else "-", 
                        "ä¸Šæ˜‡": h_mom, 
                        "ãƒ¬ãƒ™ãƒ«": "ğŸ”¥å¼·ï¾’ï¾ï¾‚" if df_tab4[df_tab4['last_race'] == h_lat['last_race']]['base_rtc'].mean() < df_tab4['base_rtc'].mean() - 0.2 else "-", 
                        "load": h_lat['load'], 
                        "çŠ¶æ…‹": "ğŸ’¤ä¼‘ã¿æ˜ã‘" if (datetime.now() - h_lat['date']).days // 7 >= 12 else "-", 
                        "raw_rtc": final_rtc_sim, 
                        "è§£æãƒ¡ãƒ¢": h_lat['memo']
                    })
                
                # å±•é–‹äºˆæƒ³
                pred_pace = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                if styles_sim["é€ƒã’"] >= 2 or (styles_sim["é€ƒã’"] + styles_sim["å…ˆè¡Œ"]) >= num_total_sim * 0.6:
                    pred_pace = "ãƒã‚¤ãƒšãƒ¼ã‚¹å‚¾å‘"
                elif styles_sim["é€ƒã’"] == 0 and styles_sim["å…ˆè¡Œ"] <= 1:
                    pred_pace = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹å‚¾å‘"
                
                df_sim_final = pd.DataFrame(results_sim)
                # å±•é–‹ã‚·ãƒŠã‚¸ãƒ¼å¼·åŒ–
                sim_p_multiplier = 1.5 if num_total_sim >= 15 else 1.0
                
                def apply_synergy_sim(row):
                    adj = 0.0
                    if "ãƒã‚¤" in pred_pace:
                        if row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]: adj = -0.2 * sim_p_multiplier
                        elif row['è„šè³ª'] == "é€ƒã’": adj = 0.2 * sim_p_multiplier
                    elif "ã‚¹ãƒ­ãƒ¼" in pred_pace:
                        if row['è„šè³ª'] in ["é€ƒã’", "å…ˆè¡Œ"]: adj = -0.2 * sim_p_multiplier
                        elif row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]: adj = 0.2 * sim_p_multiplier
                    return row['raw_rtc'] + adj

                df_sim_final['synergy_rtc'] = df_sim_final.apply(apply_synergy_sim, axis=1)
                df_sim_final = df_sim_final.sort_values("synergy_rtc")
                df_sim_final['RTCé †ä½'] = range(1, len(df_sim_final) + 1)
                
                top_t_sim = df_sim_final.iloc[0]['raw_rtc']
                df_sim_final['å·®'] = df_sim_final['raw_rtc'] - top_t_sim
                df_sim_final['äºˆæƒ³äººæ°—'] = df_sim_final['é¦¬å'].map(sim_input_pops)
                df_sim_final['å¦™å‘³ã‚¹ã‚³ã‚¢'] = df_sim_final['äºˆæƒ³äººæ°—'] - df_sim_final['RTCé †ä½']
                
                df_sim_final['å½¹å‰²'] = "-"
                df_sim_final.loc[df_sim_final['RTCé †ä½'] == 1, 'å½¹å‰²'] = "â—"
                df_sim_final.loc[df_sim_final['RTCé †ä½'] == 2, 'å½¹å‰²'] = "ã€‡"
                df_sim_final.loc[df_sim_final['RTCé †ä½'] == 3, 'å½¹å‰²'] = "â–²"
                pb_sim = df_sim_final[df_sim_final['RTCé †ä½'] > 1].sort_values("å¦™å‘³ã‚¹ã‚³ã‚¢", ascending=False)
                if not pb_sim.empty:
                    df_sim_final.loc[df_sim_final['é¦¬å'] == pb_sim.iloc[0]['é¦¬å'], 'å½¹å‰²'] = "â˜…"
                
                df_sim_final['æƒ³å®šã‚¿ã‚¤ãƒ '] = df_sim_final['raw_rtc'].apply(format_time)
                df_sim_final['å·®'] = df_sim_final['å·®'].apply(lambda x: f"+{x:.1f}" if x > 0 else "Â±0.0")

                st.markdown("---")
                st.subheader(f"ğŸ å±•é–‹äºˆæƒ³ï¼š{pred_pace} ({num_total_sim}é ­ç«‹ã¦)")
                col_rec1, col_rec2 = st.columns(2)
                
                fav_h = df_sim_final[df_sim_final['å½¹å‰²'] == "â—"].iloc[0]['é¦¬å'] if not df_sim_final[df_sim_final['å½¹å‰²'] == "â—"].empty else ""
                opp_h = df_sim_final[df_sim_final['å½¹å‰²'] == "ã€‡"].iloc[0]['é¦¬å'] if not df_sim_final[df_sim_final['å½¹å‰²'] == "ã€‡"].empty else ""
                bomb_h = df_sim_final[df_sim_final['å½¹å‰²'] == "â˜…"].iloc[0]['é¦¬å'] if not df_sim_final[df_sim_final['å½¹å‰²'] == "â˜…"].empty else ""
                
                with col_rec1:
                    st.info(f"**ğŸ¯ 1ç‚¹å‹è² **\n\nâ— {fav_h} ï¼ ã€‡ {opp_h}")
                with col_rec2: 
                    if bomb_h:
                        st.warning(f"**ğŸ’£ å¦™å‘³ç‹™ã„**\n\nâ— {fav_h} ï¼ â˜… {bomb_h}")
                
                def highlight_sim(row):
                    if row['å½¹å‰²'] == "â˜…":
                        return ['background-color: #ffe4e1; font-weight: bold'] * len(row)
                    if row['å½¹å‰²'] == "â—":
                        return ['background-color: #fff700; font-weight: bold; color: black'] * len(row)
                    return [''] * len(row)
                
                st.table(df_sim_final[["å½¹å‰²", "é¦¬å", "è„šè³ª", "æ¸‹æ»", "ã‚¹ãƒ­ãƒ¼", "æƒ³å®šã‚¿ã‚¤ãƒ ", "å·®", "å¦™å‘³ã‚¹ã‚³ã‚¢", "é©æ€§", "å®‰å®š", "ä¸Šæ˜‡", "ãƒ¬ãƒ™ãƒ«", "åå·®", "load", "çŠ¶æ…‹", "è§£æãƒ¡ãƒ¢"]].style.apply(highlight_sim, axis=1))

# ==============================================================================
# 11. Tab 5: ãƒˆãƒ¬ãƒ³ãƒ‰
# ==============================================================================
with tab5:
    st.header("ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰ & çµ±è¨ˆè§£æ")
    df_tab5 = get_db_data()
    if not df_tab5.empty:
        tc_sel = st.selectbox("ãƒˆãƒ¬ãƒ³ãƒ‰ç«¶é¦¬å ´", list(COURSE_DATA.keys()), key="tc_sel_tab5")
        tdf_tab5 = df_tab5[df_tab5['course'] == tc_sel].sort_values("date")
        if not tdf_tab5.empty:
            st.subheader("ğŸ’§ ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³æ¨ç§»"); st.line_chart(tdf_tab5.set_index("date")[["cushion", "water"]])
            st.subheader("ğŸ ãƒ¬ãƒ¼ã‚¹å‚¾å‘"); st.bar_chart(tdf_tab5.groupby('last_race').agg({'load':'mean', 'date':'max'}).sort_values('date', ascending=False).head(15)['load'])

# ==============================================================================
# 12. Tab 6: ãƒ‡ãƒ¼ã‚¿ç®¡ç† (æ‰‹å‹•ä¿®æ­£åŒæœŸãƒ»å†è§£æãƒ»ä¸€æ‹¬å‰Šé™¤)
# ==============================================================================
with tab6:
    st.header("ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å®ˆ & ç®¡ç†")
    
    # ğŸŒŸ ã€æŒ‡ç¤ºåæ˜ ã€‘åŒæœŸä¸å…¨è§£æ¶ˆãƒ»æ‰‹å‹•ä¿®æ­£åæ˜ ç”¨ãƒœã‚¿ãƒ³
    if st.button("ğŸ”„ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ‰‹å‹•ä¿®æ­£ã‚’åŒæœŸï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç ´æ£„ï¼‰"):
        st.cache_data.clear()
        st.success("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å®Œå…¨ã«ç ´æ£„ã—ã¾ã—ãŸã€‚æœ€æ–°ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå†…å®¹ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
        st.rerun()

    db_df_tab6 = get_db_data()

    def update_eval_tags_full_logic_verbose(row, df_context=None):
        """ã€å®Œå…¨å¾©å…ƒã€‘å†—é•·ãªæ¡ä»¶åˆ†å²ã«ã‚ˆã‚‹å†è§£æç”¨è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯"""
        m_raw = str(row['memo']) if not pd.isna(row['memo']) else ""
        
        def to_f_safe(v):
            try: return float(v) if not pd.isna(v) else 0.0
            except: return 0.0
            
        f3_v, l3_v, rl3_v, pos_v, l_pos_v, d_v, rtc_v = map(to_f_safe, [
            row['f3f'], row['l3f'], row['race_l3f'], row['result_pos'], row['load'], row['dist'], row['base_rtc']
        ])
        
        # ğŸŒŸ æ–¤é‡ã‚’notesã‹ã‚‰å†æŠ½å‡ºï¼ˆæ‰‹å‹•ä¿®æ­£åæ˜ ã®è¦ï¼‰
        n_str = str(row['notes'])
        w_match_v = re.search(r'([4-6]\d\.\d)', n_str)
        indiv_w_v = float(w_match_v.group(1)) if w_match_v else 56.0
        
        # ä¸­ç›¤ãƒ©ãƒƒãƒ—
        mid_note_v = "å¹³"
        if d_v > 1200 and f3_v > 0:
            m_lap_v = (rtc_v - f3_v - l3_v) / ((d_v - 1200) / 200)
            if m_lap_v >= 12.8: mid_note_v = "ç·©"
            elif m_lap_v <= 11.8: mid_note_v = "ç· "
        elif d_v <= 1200:
            mid_note_v = "çŸ­"

        # ãƒã‚¤ã‚¢ã‚¹åˆ¤å®šå®Œå…¨å†ç¾
        b_type_v = "ãƒ•ãƒ©ãƒƒãƒˆ"; max_r_v = 16
        if df_context is not None and not pd.isna(row['last_race']):
            r_ctx = df_context[df_context['last_race'] == row['last_race']]
            max_r_v = r_ctx['result_pos'].max() if not r_ctx.empty else 16
            top3_v = r_ctx[pd.to_numeric(r_ctx['result_pos'], errors='coerce') <= 3].copy()
            top3_v['load'] = pd.to_numeric(top3_v['load'], errors='coerce').fillna(7.0)
            
            out_v = top3_v[(top3_v['load'] >= 10.0) | (top3_v['load'] <= 3.0)]
            if len(out_v) == 1:
                b_set_v = pd.concat([
                    top3_v[top3_v['name'] != out_v.iloc[0]['name']], 
                    r_ctx[pd.to_numeric(r_ctx['result_pos'], errors='coerce') == 4]
                ])
            else:
                b_set_v = top3_v
            
            if not b_set_v.empty:
                avg_v = b_set_v['load'].mean()
                if avg_v <= 4.0: b_type_v = "å‰æœ‰åˆ©"
                elif avg_v >= 10.0: b_type_v = "å¾Œæœ‰åˆ©"

        # ãƒšãƒ¼ã‚¹ãƒ»å¼·åº¦è£œæ­£
        p_status_v = "ãƒã‚¤ãƒšãƒ¼ã‚¹" if "ãƒã‚¤" in m_raw else "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" if "ã‚¹ãƒ­ãƒ¼" in m_raw else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        p_diff_v = 1.5 if p_status_v != "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹" else 0.0
        rel_p_v = l_pos_v / max_r_v
        f_int_v = max_r_v / 16.0
        
        new_l_score_v = 0.0
        if p_status_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and b_type_v != "å‰æœ‰åˆ©":
            new_l_score_v = max(0, (0.6 - rel_p_v) * p_diff_v * 3.0) * f_int_v
        elif p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and b_type_v != "å¾Œæœ‰åˆ©":
            new_l_score_v = max(0, (rel_p_v - 0.4) * p_diff_v * 2.0) * f_int_v
        
        t_list_v = []
        is_c_v = False
        if rl3_v > 0:
            if (rl3_v - l3_v) >= 0.5: t_list_v.append("ğŸš€ ã‚¢ã‚¬ãƒªå„ªç§€")
            elif (rl3_v - l3_v) <= -1.0: t_list_v.append("ğŸ“‰ å¤±é€Ÿå¤§")
            
        if pos_v <= 5:
            if b_type_v == "å‰æœ‰åˆ©" and l_pos_v >= 10.0:
                t_list_v.append("ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_r_v >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ")
                is_c_v = True
            elif b_type_v == "å¾Œæœ‰åˆ©" and l_pos_v <= 3.0:
                t_list_v.append("ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_r_v >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ")
                is_c_v = True
            
            # å±•é–‹é€†è¡Œ
            if p_status_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and b_type_v != "å‰æœ‰åˆ©" and l_pos_v <= 3.0:
                t_list_v.append("ğŸ“‰ æ¿€æµè¢«å®³" if max_r_v >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ")
                is_c_v = True
            elif p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and b_type_v != "å¾Œæœ‰åˆ©" and l_pos_v >= 10.0:
                if (f3_v - l3_v) > 1.5:
                    t_list_v.append("ğŸ”¥ å±•é–‹é€†è¡Œ")
                    is_c_v = True
        
        if max_r_v <= 10 and p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and pos_v <= 2:
            t_list_v.append("ğŸŸ¢ å±•é–‹æ©æµ")

        field_tag_v = "å¤š" if max_r_v >= 16 else "å°‘" if max_r_v <= 10 else "ä¸­"
        memo_upd = (f"ã€{p_status_v}/{b_type_v}/è² è·:{new_l_score_v:.1f}({field_tag_v})/{mid_note_v}ã€‘" + "/".join(t_list_v)).strip("/")
        flag_upd = ("â˜…é€†è¡Œç‹™ã„ " + str(row['next_buy_flag']).replace("â˜…é€†è¡Œç‹™ã„", "")).strip() if is_c_v else str(row['next_buy_flag']).replace("â˜…é€†è¡Œç‹™ã„", "").strip()
        
        return memo_upd, flag_upd

    # é–‹å‚¬é€±è£œæ­£ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    st.subheader("ğŸ—“ éå»ãƒ¬ãƒ¼ã‚¹ã®é–‹å‚¬é€±ã‚’ä¸€æ‹¬è¨­å®š")
    if not db_df_tab6.empty:
        rm_weeks = db_df_tab6[['last_race', 'date']].drop_duplicates(subset=['last_race']).copy()
        rm_weeks['track_week'] = 1
        ew_df = st.data_editor(rm_weeks, hide_index=True)
        if st.button("ğŸ”„ è£œæ­£&å†è§£æã‚’ä¸€æ‹¬é©ç”¨"):
            w_dict = dict(zip(ew_df['last_race'], ew_df['track_week']))
            for idx_w, row_w in db_df_tab6.iterrows():
                if row_w['last_race'] in w_dict:
                    db_df_tab6.at[idx_w, 'base_rtc'] = row_w['base_rtc'] - (w_dict[row_w['last_race']] - 1) * 0.05
                    m_re, f_re = update_eval_tags_full_logic_verbose(db_df_tab6.iloc[idx_w], db_df_tab6)
                    db_df_tab6.at[idx_w, 'memo'] = m_re
                    db_df_tab6.at[idx_w, 'next_buy_flag'] = f_re
            if safe_update(db_df_tab6):
                st.success("é–‹å‚¬é€±è£œæ­£ã¨å†è¨ˆç®—ã‚’å®Œäº†ã—ã¾ã—ãŸã€‚"); st.rerun()

    st.subheader("ğŸ› ï¸ ä¸€æ‹¬å‡¦ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    col_adm1, col_adm2 = st.columns(2)
    with col_adm1:
        if st.button("ğŸ”„ DBå†è§£æï¼ˆæœ€æ–°æ•°å€¤ã‚’åŸºã«ä¸Šæ›¸ãï¼‰"):
            # ğŸŒŸ ã€æŒ‡ç¤ºåæ˜ ã€‘åŒæœŸä¸å…¨è§£æ¶ˆãƒ»æ‰‹å‹•ä¿®æ­£åæ˜ ã®æ ¸å¿ƒ
            st.cache_data.clear()
            latest_db = conn.read(ttl=0)
            # ã‚«ãƒ©ãƒ æ­£è¦åŒ–
            for c in all_cols:
                if c not in latest_db.columns: latest_db[c] = None
            
            for idx, row in latest_db.iterrows():
                m_upd, f_upd = update_eval_tags_full_logic_verbose(row, latest_db)
                latest_db.at[idx, 'memo'] = m_upd
                latest_db.at[idx, 'next_buy_flag'] = f_upd
            
            if safe_update(latest_db):
                st.success("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ‰‹å‹•ä¿®æ­£ã‚’åŸºã«ã€å…¨è§£æãƒ¡ãƒ¢ã‚’æ›´æ–°ãƒ»åŒæœŸã—ã¾ã—ãŸã€‚")
                st.rerun()
    with col_adm2:
        if st.button("ğŸ§¼ é‡è¤‡å‰Šé™¤"):
            b_cnt = len(db_df_tab6)
            db_df_tab6 = db_df_tab6.drop_duplicates(subset=['name', 'date', 'last_race'], keep='first')
            if safe_update(db_df_tab6):
                st.success(f"{b_cnt - len(db_df_tab6)}ä»¶ã®é‡è¤‡ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"); st.rerun()

    if not db_df_tab6.empty:
        st.subheader("ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿ç·¨é›†ã‚¨ãƒ‡ã‚£ã‚¿")
        edf_tab6 = db_df_tab6.copy()
        edf_tab6['base_rtc'] = edf_tab6['base_rtc'].apply(format_time)
        edited_db_final = st.data_editor(edf_tab6.sort_values("date", ascending=False), num_rows="dynamic", use_container_width=True)
        if st.button("ğŸ’¾ ã‚¨ãƒ‡ã‚£ã‚¿ã®å¤‰æ›´å†…å®¹ã‚’åæ˜ "):
            save_df_final = edited_db_final.copy()
            save_df_final['base_rtc'] = save_df_final['base_rtc'].apply(parse_time_str)
            if safe_update(save_df_final):
                st.success("ã‚¨ãƒ‡ã‚£ã‚¿ã®å†…å®¹ã‚’DBã«åæ˜ ã—ã¾ã—ãŸã€‚"); st.rerun()
        
        st.divider()
        st.subheader("âŒ ãƒ‡ãƒ¼ã‚¿å‰Šé™¤è¨­å®š")
        col_del1, col_del2 = st.columns(2)
        with col_del1:
            all_r_del = sorted([str(x) for x in db_df_tab6['last_race'].dropna().unique()])
            target_r_del = st.selectbox("å‰Šé™¤å¯¾è±¡ãƒ¬ãƒ¼ã‚¹", ["æœªé¸æŠ"] + all_r_del)
            if target_r_del != "æœªé¸æŠ":
                if st.button(f"ğŸš¨ ãƒ¬ãƒ¼ã‚¹ã€{target_r_del}ã€‘ã‚’å…¨å‰Šé™¤"):
                    if safe_update(db_df_tab6[db_df_tab6['last_race'] != target_r_del]): st.rerun()
        with col_del2:
            all_h_del = sorted([str(x) for x in db_df_tab6['name'].dropna().unique()])
            # ğŸŒŸ ã€å®Œå…¨å¾©å…ƒã€‘ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆä¸€æ‹¬å‰Šé™¤
            target_h_del_list = st.multiselect("å‰Šé™¤é¦¬é¸æŠï¼ˆè¤‡æ•°å¯ï¼‰", all_h_del, key="mult_del_final")
            if target_h_del_list:
                if st.button(f"ğŸš¨ é¸æŠã—ãŸ{len(target_h_del_list)}é ­ã‚’DBã‹ã‚‰å‰Šé™¤"):
                    if safe_update(db_df_tab6[~db_df_tab6['name'].isin(target_h_del_list)]): st.rerun()

        st.divider()
        with st.expander("â˜¢ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"):
            if st.button("ğŸ§¨ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ"):
                if safe_update(pd.DataFrame(columns=db_df_tab6.columns)):
                    st.success("DBã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚"); st.rerun()
