import streamlit as st
import pandas as pd
import re
import time
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# ==========================================
# ãƒšãƒ¼ã‚¸åŸºæœ¬è¨­å®š
# ==========================================
st.set_page_config(
    page_title="DTI Ultimate DB",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Google Sheets æ¥ç¶šè¨­å®š ---
conn = st.connection("gsheets", type=GSheetsConnection)

# ğŸŒŸ APIåˆ¶é™(429 Error)å›é¿ã®ãŸã‚ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®š
# 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’è¡Œã„ã€é »ç¹ãªèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã‚’é˜²æ­¢ã—ã¾ã™
@st.cache_data(ttl=300)
def get_db_data_cached():
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å…¨ã‚«ãƒ©ãƒ å®šç¾©ï¼ˆåˆæœŸã‹ã‚‰ä¸€è²«ã—ãŸå®šç¾©ã‚’ç¶­æŒï¼‰
    all_cols = [
        "name", "base_rtc", "last_race", "course", "dist", "notes", 
        "timestamp", "f3f", "l3f", "race_l3f", "load", "memo", 
        "date", "cushion", "water", "result_pos", "result_pop", "next_buy_flag"
    ]
    try:
        df = conn.read(ttl=0)
        if df is None or df.empty:
            return pd.DataFrame(columns=all_cols)
        
        # ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ©ãƒ ãŒã‚ã‚Œã°åˆæœŸå€¤Noneã§è£œå¡«
        for col in all_cols:
            if col not in df.columns:
                df[col] = None
        
        # ãƒ‡ãƒ¼ã‚¿ã®å‹å¤‰æ›ã¨å‰å‡¦ç†
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['result_pos'] = pd.to_numeric(df['result_pos'], errors='coerce')
        
        # ğŸŒŸ ä¸‰æ®µéšã‚½ãƒ¼ãƒˆãƒ­ã‚¸ãƒƒã‚¯: æ—¥ä»˜(æ–°ã—ã„é †) â†’ ãƒ¬ãƒ¼ã‚¹å(åå‰é †) â†’ ç€é †(1ç€ã‹ã‚‰)
        df = df.sort_values(["date", "last_race", "result_pos"], ascending=[False, True, True])
        
        # äººæ°—é †ã®æ•°å€¤å¤‰æ›
        df['result_pop'] = pd.to_numeric(df['result_pop'], errors='coerce')
        
        # æ•°å€¤è¨ˆç®—ã«ä½¿ã†ã‚«ãƒ©ãƒ ã®å®‰å…¨ãªå¤‰æ› (NaNã¯0.0ã§åŸ‹ã‚ã‚‹)
        df['f3f'] = pd.to_numeric(df['f3f'], errors='coerce').fillna(0.0)
        df['l3f'] = pd.to_numeric(df['l3f'], errors='coerce').fillna(0.0)
        df['race_l3f'] = pd.to_numeric(df['race_l3f'], errors='coerce').fillna(0.0)
        df['load'] = pd.to_numeric(df['load'], errors='coerce').fillna(0.0)
            
        # å…¨ã¦ã®è¡ŒãŒç©ºã®ãƒ‡ãƒ¼ã‚¿ã¯é™¤å¤–
        df = df.dropna(how='all')
        return df
    except Exception as e:
        st.error(f"ã€è­¦å‘Šã€‘ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚APIåˆ¶é™ã‚„é€šä¿¡ç’°å¢ƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°: {e}")
        return pd.DataFrame(columns=all_cols)

def get_db_data():
    return get_db_data_cached()

# ğŸŒŸ APIæ›´æ–°ã‚¨ãƒ©ãƒ¼å¯¾ç­–ã®ãƒªãƒˆãƒ©ã‚¤é–¢æ•° (å®‰å…¨ãªæ›¸ãè¾¼ã¿å‡¦ç†)
def safe_update(df):
    # ä¿å­˜ã®ç›´å‰ã«ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ä¿ã¤ãŸã‚ã‚½ãƒ¼ãƒˆã‚’è¡Œã†
    if all(col in df.columns for col in ['date', 'last_race', 'result_pos']):
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df['result_pos'] = pd.to_numeric(df['result_pos'], errors='coerce')
        df = df.sort_values(["date", "last_race", "result_pos"], ascending=[False, True, True])
    
    # å¤±æ•—æ™‚ã«ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ (APIã®429ã‚¨ãƒ©ãƒ¼å¯¾ç­–)
    max_retries = 3
    for i in range(max_retries):
        try:
            conn.update(data=df)
            st.cache_data.clear() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦æœ€æ–°ã‚’åæ˜ 
            return True
        except Exception as e:
            if i < max_retries - 1:
                st.warning(f"Google Sheetsæ¥ç¶šã‚¨ãƒ©ãƒ¼(ãƒªãƒˆãƒ©ã‚¤ {i+1}/3å›ç›®): 5ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™ã€‚æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                time.sleep(5)
                continue
            else:
                st.error(f"Google Sheetsã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                return False

# --- è¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
def format_time(seconds):
    """ç§’æ•°ã‚’ mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã«å¤‰æ›"""
    if seconds is None or seconds <= 0 or pd.isna(seconds):
        return ""
    if isinstance(seconds, str):
        return seconds
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

def parse_time_str(time_str):
    """mm:ss.f å½¢å¼ã®æ–‡å­—åˆ—ã‚’ç§’æ•°(float)ã«å¤‰æ›"""
    try:
        if ":" in str(time_str):
            m, s = map(float, str(time_str).split(':'))
            return m * 60 + s
        return float(time_str)
    except:
        try:
            return float(time_str)
        except:
            return 0.0

# ğŸŒŸ ã€å®Œå…¨å¾©å…ƒã€‘ã‚³ãƒ¼ã‚¹ãƒ»é¦¬å ´è² è·ä¿‚æ•°ãƒ‡ãƒ¼ã‚¿
# å„ç«¶é¦¬å ´ã®åŸºç¤è£œæ­£å€¤ã‚’è©³ç´°ã«å®šç¾©
COURSE_DATA = {
    "æ±äº¬": 0.10, 
    "ä¸­å±±": 0.25, 
    "äº¬éƒ½": 0.15, 
    "é˜ªç¥": 0.18, 
    "ä¸­äº¬": 0.20,
    "æ–°æ½Ÿ": 0.05, 
    "å°å€‰": 0.30, 
    "ç¦å³¶": 0.28, 
    "æœ­å¹Œ": 0.22, 
    "å‡½é¤¨": 0.25
}
DIRT_COURSE_DATA = {
    "æ±äº¬": 0.40, 
    "ä¸­å±±": 0.55, 
    "äº¬éƒ½": 0.45, 
    "é˜ªç¥": 0.48, 
    "ä¸­äº¬": 0.50,
    "æ–°æ½Ÿ": 0.42, 
    "å°å€‰": 0.58, 
    "ç¦å³¶": 0.60, 
    "æœ­å¹Œ": 0.62, 
    "å‡½é¤¨": 0.65
}
SLOPE_FACTORS = {
    "ä¸­å±±": 0.005, 
    "ä¸­äº¬": 0.004, 
    "äº¬éƒ½": 0.002, 
    "é˜ªç¥": 0.004, 
    "æ±äº¬": 0.003,
    "æ–°æ½Ÿ": 0.001, 
    "å°å€‰": 0.002, 
    "ç¦å³¶": 0.003, 
    "æœ­å¹Œ": 0.001, 
    "å‡½é¤¨": 0.002
}

# ==========================================
# ãƒ¡ã‚¤ãƒ³ UI æ§‹æˆ
# ==========================================
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "ğŸ“ è§£æãƒ»ä¿å­˜", "ğŸ é¦¬åˆ¥å±¥æ­´", "ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´", 
    "ğŸ¯ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", "ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰", "ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"
])

# --- Tab 1: è§£æãƒ»ä¿å­˜ ---
with tab1:
    df_pickup = get_db_data()
    if not df_pickup.empty:
        st.subheader("ğŸ¯ æ¬¡èµ°æ³¨ç›®é¦¬ï¼ˆé€†è¡Œè©•ä¾¡ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰")
        pickup_rows = []
        for i, row in df_pickup.iterrows():
            memo_str = str(row['memo'])
            b_flag = "ğŸ’" in memo_str
            p_flag = "ğŸ”¥" in memo_str
            if b_flag or p_flag:
                detail = ""
                if b_flag and p_flag:
                    detail = "ã€ğŸ’¥ä¸¡æ–¹é€†è¡Œã€‘"
                elif b_flag:
                    detail = "ã€ğŸ’ãƒã‚¤ã‚¢ã‚¹é€†è¡Œã€‘"
                elif p_flag:
                    detail = "ã€ğŸ”¥ãƒšãƒ¼ã‚¹é€†è¡Œã€‘"
                
                pickup_rows.append({
                    "é¦¬å": row['name'], 
                    "é€†è¡Œã‚¿ã‚¤ãƒ—": detail, 
                    "å‰èµ°": row['last_race'],
                    "æ—¥ä»˜": row['date'].strftime('%Y-%m-%d') if not pd.isna(row['date']) else "", 
                    "è§£æãƒ¡ãƒ¢": memo_str
                })
        if pickup_rows:
            st.dataframe(pd.DataFrame(pickup_rows).sort_values("æ—¥ä»˜", ascending=False), use_container_width=True, hide_index=True)
        else:
            st.info("ç¾åœ¨ã€ãƒã‚¤ã‚¢ã‚¹ã‚„å±•é–‹ã«é€†è¡Œã—ã¦å¥½èµ°ãƒ»å–„æˆ¦ã—ãŸæ³¨ç›®é¦¬ã¯ã„ã¾ã›ã‚“ã€‚")
    st.divider()

    st.header("ğŸš€ ãƒ¬ãƒ¼ã‚¹è§£æ & è‡ªå‹•ä¿å­˜ã‚·ã‚¹ãƒ†ãƒ ")
    with st.sidebar:
        st.title("è§£ææ¡ä»¶è¨­å®š")
        r_name = st.text_input("ãƒ¬ãƒ¼ã‚¹å (ä¾‹: æœ‰é¦¬è¨˜å¿µ)")
        r_date = st.date_input("ãƒ¬ãƒ¼ã‚¹å®Ÿæ–½æ—¥", datetime.now())
        c_name = st.selectbox("ç«¶é¦¬å ´é¸æŠ", list(COURSE_DATA.keys()))
        t_type = st.radio("ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
        dist_options = list(range(1000, 3700, 100))
        dist = st.selectbox("è·é›¢ (m)", dist_options, index=dist_options.index(1600))
        st.divider()
        st.write("ğŸ’§ é¦¬å ´ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³ãƒ»ãƒã‚¤ã‚¢ã‚¹")
        cush = st.number_input("ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤ (èŠã®ã¿)", 7.0, 12.0, 9.5, step=0.1) if t_type == "èŠ" else 9.5
        w_4c = st.number_input("å«æ°´ç‡ï¼š4è§’åœ°ç‚¹ (%)", 0.0, 50.0, 10.0, step=0.1)
        w_goal = st.number_input("å«æ°´ç‡ï¼šã‚´ãƒ¼ãƒ«å‰åœ°ç‚¹ (%)", 0.0, 50.0, 10.0, step=0.1)
        track_index = st.number_input("é¦¬å ´æŒ‡æ•° (JRAå…¬å¼ã¾ãŸã¯ç‹¬è‡ª)", -50, 50, 0, step=1)
        bias_val = st.slider("é¦¬å ´ãƒã‚¤ã‚¢ã‚¹ (å†…æœ‰åˆ© -1.0 â†” å¤–æœ‰åˆ© +1.0)", -1.0, 1.0, 0.0, step=0.1)
        # é–‹å‚¬é€±å…¥åŠ›
        track_week = st.number_input("é–‹å‚¬é€± (ä¾‹: 1, 8)", 1, 12, 1)

    col1, col2 = st.columns(2)
    with col1: 
        st.markdown("##### ğŸ ãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ—å…¥åŠ›")
        lap_input = st.text_area("JRAãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ— (ä¾‹: 12.5-11.0-12.0...)", height=150)
        f3f_val = 0.0
        l3f_val = 0.0
        pace_status = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        pace_diff = 0.0
        if lap_input:
            laps = [float(x) for x in re.findall(r'\d+\.\d', lap_input)]
            if len(laps) >= 3:
                f3f_val = sum(laps[:3])
                l3f_val = sum(laps[-3:])
                pace_diff = f3f_val - l3f_val
                # è·é›¢åˆ¥ãƒšãƒ¼ã‚¹ã—ãã„å€¤ã®å‹•çš„è¨ˆç®—
                dynamic_threshold = 1.0 * (dist / 1600.0)
                if pace_diff < -dynamic_threshold:
                    pace_status = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                elif pace_diff > dynamic_threshold:
                    pace_status = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                st.success(f"è§£æå®Œäº†: å‰3F {f3f_val:.1f} / å¾Œ3F {l3f_val:.1f} ({pace_status})")
        l3f_val = st.number_input("ãƒ¬ãƒ¼ã‚¹ä¸ŠãŒã‚Š3F (è‡ªå‹•è¨ˆç®—ã‹ã‚‰ä¿®æ­£å¯)", 0.0, 60.0, l3f_val, step=0.1)

    with col2: 
        st.markdown("##### ğŸ æˆç¸¾è¡¨è²¼ã‚Šä»˜ã‘")
        raw_input = st.text_area("JRAå…¬å¼ã‚µã‚¤ãƒˆã®æˆç¸¾è¡¨ã‚’ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘ã¦ãã ã•ã„", height=250)

    # ğŸŒŸ ã€å®Œå…¨å¾©æ—§ã€‘è§£æå‰ã«æ–¤é‡ã‚’æ‰‹å‹•ç¢ºèªãƒ»ä¿®æ­£ã™ã‚‹ãŸã‚ã®è©³ç´°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    if raw_input and f3f_val > 0:
        st.markdown("##### âš–ï¸ è§£æãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæ–¤é‡ã®ç¢ºèªãƒ»ä¿®æ­£ï¼‰")
        preview_lines = [l.strip() for l in raw_input.split('\n') if len(l.strip()) > 15]
        preview_list = []
        for line in preview_lines:
            name_parts = re.findall(r'([ã‚¡-ãƒ¶ãƒ¼]{2,})', line)
            if not name_parts:
                continue
            # æ–¤é‡ã®è‡ªå‹•æŠ½å‡ºãƒ­ã‚¸ãƒƒã‚¯
            weight_match = re.search(r'\s([4-6]\d\.\d)\s', line)
            extracted_w = float(weight_match.group(1)) if weight_match else 56.0
            preview_list.append({
                "é¦¬å": name_parts[0], 
                "æ–¤é‡": extracted_w, 
                "raw_line": line
            })
        
        # ç·¨é›†å¯èƒ½ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è©³ç´°ã«è¡¨ç¤º
        edited_preview_df = st.data_editor(pd.DataFrame(preview_list), use_container_width=True, hide_index=True)

        if st.button("ğŸš€ ã“ã®å†…å®¹ã§è§£æã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¸ä¿å­˜"):
            parsed_data = []
            for i, row in edited_preview_df.iterrows():
                current_line = row["raw_line"]
                time_match = re.search(r'(\d{1,2}:\d{2}\.\d)', current_line)
                if not time_match:
                    continue
                
                # ç€é †ã®å–å¾—
                res_pos_match = re.match(r'^(\d{1,2})', current_line)
                res_pos = int(res_pos_match.group(1)) if res_pos_match else 99
                
                # 4è§’é€šéé †ä½ã®å–å¾—
                after_time_str = current_line[time_match.end():]
                pos_list = re.findall(r'\b([1-2]?\d)\b', after_time_str)
                four_c_pos = 7.0 
                if pos_list:
                    valid_positions = []
                    for p in pos_list:
                        if int(p) > 30 and len(valid_positions) > 0:
                            break
                        valid_positions.append(float(p))
                    if valid_positions:
                        four_c_pos = valid_positions[-1]
                
                parsed_data.append({
                    "line": current_line, 
                    "res_pos": res_pos, 
                    "four_c_pos": four_c_pos, 
                    "name": row["é¦¬å"], 
                    "weight": row["æ–¤é‡"]
                })
            
            # --- ã€æŒ‡ç¤ºåæ˜ ã€‘ãƒã‚¤ã‚¢ã‚¹åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆ4ç€è£œå……ç‰¹ä¾‹ã‚’è©³ç´°è¨˜è¿°ï¼‰ ---
            top_3_entries = sorted([d for d in parsed_data if d["res_pos"] <= 3], key=lambda x: x["res_pos"])
            # æ¥µç«¯ãªä½ç½®å–ã‚Šï¼ˆ10ç•ªæ‰‹ä»¥ä¸‹ or 3ç•ªæ‰‹ä»¥å†…ï¼‰ã®é¦¬ã‚’ç‰¹å®š
            outliers = [d for d in top_3_entries if d["four_c_pos"] >= 10.0 or d["four_c_pos"] <= 3.0]
            
            if len(outliers) == 1:
                # 1é ­ã ã‘æ¥µç«¯ãªå ´åˆã¯ã€ãã®é¦¬ã‚’é™¤å¤–ã—ã¦4ç€é¦¬ã‚’è£œå……ã—ã¦åˆ¤å®š
                base_entries = [d for d in top_3_entries if d != outliers[0]]
                fourth_place = [d for d in parsed_data if d["res_pos"] == 4]
                bias_calculation_entries = base_entries + fourth_place
            else:
                # 0é ­ã¾ãŸã¯2é ­ä»¥ä¸Šã®å ´åˆã¯é€šå¸¸é€šã‚Šä¸Šä½3é ­ã§åˆ¤å®š
                bias_calculation_entries = top_3_entries
            
            avg_top_pos = sum(d["four_c_pos"] for d in bias_calculation_entries) / len(bias_calculation_entries) if bias_calculation_entries else 7.0
            bias_type = "å‰æœ‰åˆ©" if avg_top_pos <= 4.0 else "å¾Œæœ‰åˆ©" if avg_top_pos >= 10.0 else "ãƒ•ãƒ©ãƒƒãƒˆ"
            
            # å‡ºèµ°é ­æ•°ã®æŠŠæ¡ï¼ˆç›¸å¯¾åŒ–ç”¨ï¼‰
            max_runners = max([d["res_pos"] for d in parsed_data]) if parsed_data else 16

            new_rows_to_save = []
            for entry in parsed_data:
                line_text = entry["line"]
                last_pos = entry["four_c_pos"]
                result_pos = entry["res_pos"]
                indiv_weight = entry["weight"] 
                
                # ã‚¿ã‚¤ãƒ ã®ç§’æ•°æ›ç®—
                time_match_obj = re.search(r'(\d{1,2}:\d{2}\.\d)', line_text)
                time_str = time_match_obj.group(1)
                m_p, s_p = map(float, time_str.split(':'))
                indiv_time_seconds = m_p * 60 + s_p
                
                # é¦¬ä½“é‡ã®æŠ½å‡º
                h_weight_match = re.search(r'(\d{3})kg', line_text)
                h_weight_str = f"({h_weight_match.group(1)}kg)" if h_weight_match else ""

                # å€‹åˆ¥ä¸ŠãŒã‚Š3Fã®æŠ½å‡º
                l3f_indiv = 0.0
                l3f_match = re.search(r'(\d{2}\.\d)\s*\d{3}\(', line_text)
                if l3f_match:
                    l3f_indiv = float(l3f_match.group(1))
                else:
                    decimal_finds = re.findall(r'(\d{2}\.\d)', line_text)
                    for d_val in decimal_finds:
                        f_val = float(d_val)
                        if 30.0 <= f_val <= 46.0 and abs(f_val - indiv_weight) > 0.5:
                            l3f_indiv = f_val
                            break
                if l3f_indiv == 0.0:
                    l3f_indiv = l3f_val 
                
                # --- ã€æŒ‡ç¤ºåæ˜ ã€‘è§£æç”¨è² è·ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆé ­æ•°ãƒ»éç·šå½¢è£œæ­£ã‚’è©³ç´°è¨˜è¿°ï¼‰ ---
                rel_pos_factor = last_pos / max_runners
                # 16é ­ã‚’åŸºæº–ã¨ã—ãŸå¼·åº¦è£œæ­£ä¿‚æ•°
                field_intensity = max_runners / 16.0
                load_score_val = 0.0
                if pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and bias_type != "å‰æœ‰åˆ©":
                    load_score_val += max(0, (0.6 - rel_pos_factor) * abs(pace_diff) * 3.0) * field_intensity
                elif pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and bias_type != "å¾Œæœ‰åˆ©":
                    load_score_val += max(0, (rel_pos_factor - 0.4) * abs(pace_diff) * 2.0) * field_intensity
                
                # é€†è¡Œãƒ•ãƒ©ã‚°è©³ç´°åˆ¤å®š
                eval_tags = []
                is_counter_target_flag = False
                if result_pos <= 5:
                    if (bias_type == "å‰æœ‰åˆ©" and last_pos >= 10.0) or (bias_type == "å¾Œæœ‰åˆ©" and last_pos <= 3.0):
                        # å¤šé ­æ•°æ™‚ã®é€†è¡Œã‚¿ã‚°æ ¼ä¸Šã’
                        upgrade_tag = "ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_runners >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ"
                        eval_tags.append(upgrade_tag)
                        is_counter_target_flag = True
                
                is_favored_pattern = (pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and bias_type == "å‰æœ‰åˆ©") or (pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and bias_type == "å¾Œæœ‰åˆ©")
                if not is_favored_pattern:
                    if (pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and last_pos <= 3.0):
                        # æ¿€æµè¢«å®³ã®åˆ¤å®š
                        eval_tags.append("ğŸ“‰ æ¿€æµè¢«å®³" if max_runners >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ")
                        is_counter_target_flag = True
                    elif (pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and last_pos >= 10.0 and (f3f_val - l3f_indiv) > 1.5):
                        eval_tags.append("ğŸ”¥ å±•é–‹é€†è¡Œ")
                        is_counter_target_flag = True
                
                # å°‘é ­æ•°å±•é–‹æ©æµã®åˆ¤å®š
                if max_runners <= 10 and pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and result_pos <= 2:
                    eval_tags.append("ğŸŸ¢ å±•é–‹æ©æµ")

                # ä¸ŠãŒã‚Šæ€§èƒ½è©•ä¾¡
                if (l3f_val - l3f_indiv) >= 0.5:
                    eval_tags.append("ğŸš€ ã‚¢ã‚¬ãƒªå„ªç§€")
                elif (l3f_val - l3f_indiv) <= -1.0:
                    eval_tags.append("ğŸ“‰ å¤±é€Ÿå¤§")
                
                # --- ä¸­ç›¤ãƒ©ãƒƒãƒ—è§£æ ---
                mid_pace_note = "å¹³"
                if dist > 1200:
                    mid_lap_val = (indiv_time_seconds - f3f_val - l3f_indiv) / ((dist - 1200) / 200)
                    if mid_lap_val >= 12.8:
                        mid_pace_note = "ç·©"
                    elif mid_lap_val <= 11.8:
                        mid_pace_note = "ç· "
                else:
                    mid_pace_note = "çŸ­"

                field_attribute = "å¤š" if max_runners >= 16 else "å°‘" if max_runners <= 10 else "ä¸­"
                final_memo = f"ã€{pace_status}/{bias_type}/è² è·:{load_score_val:.1f}({field_attribute})/{mid_pace_note}ã€‘{'/'.join(eval_tags) if eval_tags else 'é †å¢ƒ'}"
                
                # é–‹å‚¬é€±è£œæ­£ã®è¨ˆç®—
                week_adjustment_val = (track_week - 1) * 0.05
                
                # ğŸŒŸ RTCæŒ‡æ•°ã®æ±ºå®šï¼ˆæ–¤é‡ãƒ»é¦¬å ´ãƒ»è² è·ã‚’ã™ã¹ã¦åæ˜ ï¼‰
                final_rtc_val = (indiv_time_seconds - (indiv_weight - 56.0) * 0.1 - track_index / 10.0 - load_score_val / 10.0 - week_adjustment_val) + bias_val - ((w_4c+w_goal)/2 - 10.0)*0.05 - (9.5-cush)*0.1 + (dist - 1600) * 0.0005
                
                new_rows_to_save.append({
                    "name": entry["name"], 
                    "base_rtc": final_rtc_val, 
                    "last_race": r_name, 
                    "course": c_name, 
                    "dist": dist, 
                    "notes": f"{indiv_weight}kg{h_weight_str}", 
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"), 
                    "f3f": f3f_val, 
                    "l3f": l3f_indiv, 
                    "race_l3f": l3f_val, 
                    "load": last_pos, 
                    "memo": final_memo,
                    "date": r_date.strftime("%Y-%m-%d"), 
                    "cushion": cush, 
                    "water": (w_4c+w_goal)/2, 
                    "next_buy_flag": "â˜…é€†è¡Œç‹™ã„" if is_counter_target_flag else "", 
                    "result_pos": result_pos
                })
            
            if new_rows_to_save:
                current_db_df = get_db_data()
                updated_full_df = pd.concat([current_db_df, pd.DataFrame(new_rows_to_save)], ignore_index=True)
                if safe_update(updated_full_df):
                    st.success(f"âœ… è§£æå®Œäº†ï¼{len(new_rows_to_save)}é ­ã®ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                    st.rerun()

# --- Tab 2: é¦¬åˆ¥å±¥æ­´ ---
with tab2:
    st.header("ğŸ“Š é¦¬åˆ¥å±¥æ­´ & è²·ã„æ¡ä»¶è¨­å®š")
    db_df_tab2 = get_db_data()
    if not db_df_tab2.empty:
        col_search1, col_search2 = st.columns([1, 1])
        with col_search1:
            search_name_query = st.text_input("é¦¬åã§çµã‚Šè¾¼ã¿æ¤œç´¢", key="search_horse_tab2")
        
        horse_list_sorted = sorted([str(x) for x in db_df_tab2['name'].dropna().unique()])
        with col_search2:
            selected_target_horse = st.selectbox("å€‹åˆ¥ãƒ¡ãƒ¢ãƒ»è²·ã„æ¡ä»¶ã‚’ç·¨é›†ã™ã‚‹é¦¬ã‚’é¸æŠ", ["æœªé¸æŠ"] + horse_list_sorted)
        
        if selected_target_horse != "æœªé¸æŠ":
            horse_latest_index = db_df_tab2[db_df_tab2['name'] == selected_target_horse].index[-1]
            with st.form("edit_horse_detail_form"):
                current_horse_memo = db_df_tab2.at[horse_latest_index, 'memo'] if not pd.isna(db_df_tab2.at[horse_latest_index, 'memo']) else ""
                new_horse_memo = st.text_area("ãƒ¡ãƒ¢ãƒ»ç‰¹è¨˜è©•ä¾¡", value=current_horse_memo)
                
                current_buy_flag = db_df_tab2.at[horse_latest_index, 'next_buy_flag'] if not pd.isna(db_df_tab2.at[horse_latest_index, 'next_buy_flag']) else ""
                new_buy_flag = st.text_input("æ¬¡èµ°ã¸ã®å€‹åˆ¥è²·ã„ãƒ•ãƒ©ã‚°", value=current_buy_flag)
                
                if st.form_submit_button("è¨­å®šå†…å®¹ã‚’ä¿å­˜"):
                    db_df_tab2.at[horse_latest_index, 'memo'] = new_horse_memo
                    db_df_tab2.at[horse_latest_index, 'next_buy_flag'] = new_buy_flag
                    if safe_update(db_df_tab2):
                        st.success(f"{selected_target_horse} ã®è¨­å®šã‚’æ›´æ–°ã—ã¾ã—ãŸ")
                        st.rerun()
        
        if search_name_query:
            display_horse_df = db_df_tab2[db_df_tab2['name'].str.contains(search_name_query, na=False)]
        else:
            display_horse_df = db_df_tab2
        
        display_horse_df_formatted = display_horse_df.copy()
        display_horse_df_formatted['base_rtc'] = display_horse_df_formatted['base_rtc'].apply(format_time)
        st.dataframe(display_horse_df_formatted.sort_values("date", ascending=False)[["date", "name", "last_race", "base_rtc", "f3f", "l3f", "race_l3f", "load", "memo", "next_buy_flag"]], use_container_width=True)

# --- Tab 3: ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´ ---
with tab3:
    st.header("ğŸ ç­”ãˆåˆã‚ã› & ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´")
    db_df_tab3 = get_db_data()
    if not db_df_tab3.empty:
        full_race_list = sorted([str(x) for x in db_df_tab3['last_race'].dropna().unique()])
        selected_race_name = st.selectbox("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„", full_race_list)
        if selected_race_name:
            race_history_df = db_df_tab3[db_df_tab3['last_race'] == selected_race_name].copy()
            with st.form("race_result_entry_form"):
                st.write(f"ã€{selected_race_name}ã€‘ã®çµæœãƒ»äººæ°—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
                for idx, row in race_history_df.iterrows():
                    current_res_pos = int(row['result_pos']) if not pd.isna(row['result_pos']) else 0
                    current_res_pop = int(row['result_pop']) if not pd.isna(row['result_pop']) else 0
                    
                    col_res1, col_res2 = st.columns(2)
                    with col_res1:
                        race_history_df.at[idx, 'result_pos'] = st.number_input(f"{row['name']} ç€é †", 0, 100, value=min(max(0, current_res_pos), 100), key=f"pos_input_{idx}")
                    with col_res2:
                        race_history_df.at[idx, 'result_pop'] = st.number_input(f"{row['name']} äººæ°—", 0, 100, value=min(max(0, current_res_pop), 100), key=f"pop_input_{idx}")
                
                if st.form_submit_button("ãƒ¬ãƒ¼ã‚¹çµæœã‚’ä¿å­˜"):
                    for idx, row in race_history_df.iterrows():
                        db_df_tab3.at[idx, 'result_pos'] = row['result_pos']
                        db_df_tab3.at[idx, 'result_pop'] = row['result_pop']
                    if safe_update(db_df_tab3):
                        st.success("ãƒ¬ãƒ¼ã‚¹ã®çµæœã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
                        st.rerun()
            
            display_race_history_formatted = race_history_df.copy()
            display_race_history_formatted['base_rtc'] = display_race_history_formatted['base_rtc'].apply(format_time)
            st.dataframe(display_race_history_formatted[["name", "notes", "base_rtc", "f3f", "l3f", "race_l3f", "result_pos", "result_pop"]], use_container_width=True)

# --- Tab 4: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ ---
with tab4:
    st.header("ğŸ¯ æ¬¡èµ°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ & çµ±åˆè©•ä¾¡")
    db_df_tab4 = get_db_data()
    if not db_df_tab4.empty:
        all_horse_names_list = sorted([str(x) for x in db_df_tab4['name'].dropna().unique()])
        selected_horses_sim = st.multiselect("å‡ºèµ°äºˆå®šé¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„", options=all_horse_names_list)
        
        sim_input_pops = {}
        sim_input_gates = {}
        sim_input_weights = {}
        
        if selected_horses_sim:
            st.markdown("##### ğŸ“ æ ç•ªãƒ»äºˆæƒ³äººæ°—ãƒ»æƒ³å®šæ–¤é‡ã®å€‹åˆ¥å…¥åŠ›")
            sim_pop_cols = st.columns(min(len(selected_horses_sim), 4))
            for i, h_name in enumerate(selected_horses_sim):
                with sim_pop_cols[i % 4]:
                    h_latest_data = db_df_tab4[db_df_tab4['name'] == h_name].iloc[-1]
                    sim_input_gates[h_name] = st.number_input(f"{h_name} æ ç•ª", 1, 18, value=1, key=f"sim_gate_{h_name}")
                    sim_input_pops[h_name] = st.number_input(f"{h_name} äººæ°—", 1, 18, value=int(h_latest_data['result_pop']) if not pd.isna(h_latest_data['result_pop']) else 10, key=f"sim_pop_{h_name}")
                    # ğŸŒŸ ã€å®Œå…¨å¾©æ—§ã€‘å€‹åˆ¥æ–¤é‡å…¥åŠ›
                    sim_input_weights[h_name] = st.number_input(f"{h_name} æ–¤é‡", 48.0, 62.0, 56.0, step=0.5, key=f"sim_weight_{h_name}")

            col_sim_cfg1, col_sim_cfg2 = st.columns(2)
            with col_sim_cfg1: 
                sim_target_course = st.selectbox("æ¬¡èµ°ã®ç«¶é¦¬å ´", list(COURSE_DATA.keys()), key="sim_target_course_select")
                sim_target_dist = st.selectbox("è·é›¢ (m)", list(range(1000, 3700, 100)), index=6)
                sim_target_track = st.radio("æ¬¡èµ°ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"], horizontal=True)
            with col_sim_cfg2: 
                sim_current_cushion = st.slider("æƒ³å®šã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤", 7.0, 12.0, 9.5)
                sim_current_water = st.slider("æƒ³å®šå«æ°´ç‡ (%)", 0.0, 30.0, 10.0)
            
            if st.button("ğŸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
                sim_results_list = []
                num_sim_horses = len(selected_horses_sim)
                sim_styles_count = {"é€ƒã’": 0, "å…ˆè¡Œ": 0, "å·®ã—": 0, "è¿½è¾¼": 0}
                sim_overall_l3f_avg = db_df_tab4['l3f'].mean()

                for h_name in selected_horses_sim:
                    h_full_history = db_df_tab4[db_df_tab4['name'] == h_name].sort_values("date")
                    sim_last_3_runs = h_full_history.tail(3)
                    sim_converted_rtc_list = []
                    
                    # è„šè³ªåˆ¤å®š
                    avg_load_val_3r = sim_last_3_runs['load'].mean()
                    if avg_load_val_3r <= 3.5: 
                        h_style_type = "é€ƒã’"
                    elif avg_load_val_3r <= 7.0: 
                        h_style_type = "å…ˆè¡Œ"
                    elif avg_load_val_3r <= 11.0: 
                        h_style_type = "å·®ã—"
                    else: 
                        h_style_type = "è¿½è¾¼"
                    sim_styles_count[h_style_type] += 1

                    # ğŸŒŸ é ­æ•°é€£å‹•ï¼šæ¸‹æ»ãƒªã‚¹ã‚¯åˆ¤å®š
                    traffic_jam_tag = "âš ï¸è©°ã¾ã‚Šæ³¨æ„" if num_sim_horses >= 15 and h_style_type in ["å·®ã—", "è¿½è¾¼"] and sim_input_gates[h_name] <= 4 else "-"

                    # ğŸŒŸ é ­æ•°é€£å‹•ï¼šã‚¹ãƒ­ãƒ¼é©æ€§åˆ¤å®š
                    sim_slow_aptitude_tag = "-"
                    if num_sim_horses <= 10:
                        h_best_past_l3f = h_full_history['l3f'].min()
                        if h_best_past_l3f < sim_overall_l3f_avg - 0.5:
                            sim_slow_aptitude_tag = "âš¡ã‚¹ãƒ­ãƒ¼ç‰¹åŒ–"
                        elif h_best_past_l3f > sim_overall_l3f_avg + 0.5:
                            sim_slow_aptitude_tag = "ğŸ“‰ç¬ç™ºåŠ›ä¸è¶³"

                    # å„ç¨®ã‚¿ã‚°åˆ¤å®š
                    h_rtc_std_val = h_full_history['base_rtc'].std() if len(h_full_history) >= 3 else 0.0
                    h_stability_label = "âš–ï¸å®‰å®š" if 0 < h_rtc_std_val < 0.2 else "ğŸ¢ãƒ ãƒ©" if h_rtc_std_val > 0.4 else "-"
                    
                    h_best_run_data = h_full_history.loc[h_full_history['base_rtc'].idxmin()]
                    h_aptitude_label = "ğŸ¯é¦¬å ´â—" if abs(h_best_run_data['cushion'] - sim_current_cushion) <= 0.5 and abs(h_best_run_data['water'] - sim_current_water) <= 2.0 else "-"

                    # ğŸŒŸ ã€å®Œå…¨å¾©æ—§ã€‘éå»3èµ°ã™ã¹ã¦ã«ãŠã‘ã‚‹å€‹åˆ¥æ–¤é‡è£œæ­£ãƒ«ãƒ¼ãƒ—
                    for idx, row in sim_last_3_runs.iterrows():
                        p_race_dist = row['dist']
                        p_race_rtc = row['base_rtc']
                        p_race_course = row['course']
                        p_race_load = row['load']
                        p_race_notes = str(row['notes'])
                        
                        # å‰èµ°æ™‚ç‚¹ã®æ–¤é‡ã¨é¦¬ä½“é‡ã®æŠ½å‡º
                        p_race_weight = 56.0
                        h_body_weight_sim = 480.0
                        w_match_sim = re.search(r'([4-6]\d\.\d)', p_race_notes)
                        if w_match_sim:
                            p_race_weight = float(w_match_sim.group(1))
                        
                        hb_match_sim = re.search(r'\((\d{3})kg\)', p_race_notes)
                        if hb_match_sim:
                            h_body_weight_sim = float(hb_match_sim.group(1))
                        
                        if p_race_dist > 0:
                            p_load_adj = (p_race_load - 7.0) * 0.02
                            # ğŸŒŸ æ–¤é‡æ„Ÿå¿œåº¦ï¼ˆé¦¬ä½“é‡ã«åŸºã¥ãè©³ç´°ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                            weight_sensitivity_factor = 0.15 if h_body_weight_sim <= 440 else 0.08 if h_body_weight_sim >= 500 else 0.1
                            
                            # ä»Šå›å…¥åŠ›ã•ã‚ŒãŸå€‹åˆ¥æ–¤é‡ã¨ã®å·®åˆ†ã‚’è£œæ­£
                            weight_difference_adjustment = (sim_input_weights[h_name] - p_race_weight) * weight_sensitivity_factor
                            
                            # æŒ‡æ•°å¤‰æ›è¨ˆç®—
                            base_converted_rtc = (p_race_rtc + p_load_adj + weight_difference_adjustment) / p_race_dist * sim_target_dist
                            
                            # å‚ãƒ»é«˜ä½å·®è£œæ­£
                            slope_adjustment_val = (SLOPE_FACTORS.get(sim_target_course, 0.002) - SLOPE_FACTORS.get(p_race_course, 0.002)) * sim_target_dist
                            sim_converted_rtc_list.append(base_converted_rtc + slope_adjustment_val)
                    
                    avg_sim_rtc_result = sum(sim_converted_rtc_list) / len(sim_converted_rtc_list) if sim_converted_rtc_list else 0
                    
                    # è·é›¢å®Ÿç¸¾ã®å¼¾åŠ›æ€§è£œæ­£
                    h_best_dist_past = h_full_history.loc[h_full_history['base_rtc'].idxmin(), 'dist']
                    avg_sim_rtc_result += (abs(sim_target_dist - h_best_dist_past) / 100) * 0.05
                    
                    # è¿‘å½±ä¸Šæ˜‡ï¼ˆãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ï¼‰åˆ¤å®š
                    h_momentum_label = "-"
                    if len(h_full_history) >= 2:
                        if h_full_history.iloc[-1]['base_rtc'] < h_full_history.iloc[-2]['base_rtc'] - 0.2:
                            h_momentum_label = "ğŸ“ˆä¸Šæ˜‡"
                            avg_sim_rtc_result -= 0.15

                    # æ é †Ã—ãƒã‚¤ã‚¢ã‚¹ã®ã‚·ãƒŠã‚¸ãƒ¼è£œæ­£
                    synergy_bias_adj = -0.2 if (sim_input_gates[h_name] <= 4 and bias_val <= -0.5) or (sim_input_gates[h_name] >= 13 and bias_val >= 0.5) else 0
                    avg_sim_rtc_result += synergy_bias_adj

                    # ã‚³ãƒ¼ã‚¹ç›¸æ€§ãƒœãƒ¼ãƒŠã‚¹
                    h_course_bonus_val = -0.2 if any((h_full_history['course'] == sim_target_course) & (h_full_history['result_pos'] <= 3)) else 0.0
                    
                    # å«æ°´ç‡ãƒ»ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤ã®æœ€çµ‚ã‚¢ã‚¸ãƒ£ã‚¹ãƒˆ
                    water_adjustment_final = (sim_current_water - 10.0) * 0.05
                    course_master_dict = DIRT_COURSE_DATA if sim_target_track == "ãƒ€ãƒ¼ãƒˆ" else COURSE_DATA
                    if sim_target_track == "ãƒ€ãƒ¼ãƒˆ":
                        water_adjustment_final = -water_adjustment_final # ãƒ€ãƒ¼ãƒˆã¯æ°´ã‚’å«ã‚“ã æ–¹ãŒé€Ÿã„
                    
                    final_sim_rtc_computed = (avg_sim_rtc_result + (course_master_dict[sim_target_course] * (sim_target_dist/1600.0)) + h_course_bonus_val + water_adjustment_final - (9.5 - sim_current_cushion) * 0.1)
                    
                    h_latest_entry = sim_last_3_runs.iloc[-1]
                    sim_results_list.append({
                        "é¦¬å": h_name, 
                        "è„šè³ª": h_style_type, 
                        "æƒ³å®šã‚¿ã‚¤ãƒ ": final_sim_rtc_computed, 
                        "æ¸‹æ»": traffic_jam_tag, 
                        "ã‚¹ãƒ­ãƒ¼": sim_slow_aptitude_tag, 
                        "é©æ€§": h_aptitude_label, 
                        "å®‰å®š": h_stability_label, 
                        "åå·®": "â¤´ï¸è¦šé†’æœŸå¾…" if final_sim_rtc_computed < h_full_history['base_rtc'].min() - 0.3 else "-", 
                        "ä¸Šæ˜‡": h_momentum_label, 
                        "ãƒ¬ãƒ™ãƒ«": "ğŸ”¥å¼·ï¾’ï¾ï¾‚" if db_df_tab4[db_df_tab4['last_race'] == h_latest_entry['last_race']]['base_rtc'].mean() < db_df_tab4['base_rtc'].mean() - 0.2 else "-", 
                        "load": h_latest_entry['load'], 
                        "çŠ¶æ…‹": "ğŸ’¤ä¼‘ã¿æ˜ã‘" if (datetime.now() - h_latest_entry['date']).days // 7 >= 12 else "-", 
                        "raw_rtc": final_sim_rtc_computed,
                        "è§£æãƒ¡ãƒ¢": h_latest_entry['memo']
                    })
                
                # å±•é–‹äºˆæƒ³ãƒ­ã‚¸ãƒƒã‚¯
                sim_pace_prediction = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                if sim_styles_count["é€ƒã’"] >= 2 or (sim_styles_count["é€ƒã’"] + sim_styles_count["å…ˆè¡Œ"]) >= num_sim_horses * 0.6:
                    sim_pace_prediction = "ãƒã‚¤ãƒšãƒ¼ã‚¹å‚¾å‘"
                elif sim_styles_count["é€ƒã’"] == 0 and sim_styles_count["å…ˆè¡Œ"] <= 1:
                    sim_pace_prediction = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹å‚¾å‘"
                
                sim_final_df = pd.DataFrame(sim_results_list)
                
                # ğŸŒŸ è„šè³ªãƒ»å±•é–‹ã‚·ãƒŠã‚¸ãƒ¼åæ˜ ï¼ˆå¤šé ­æ•°æ™‚ã¯å½±éŸ¿åº¦1.5å€ï¼‰
                sim_pace_multiplier = 1.5 if num_sim_horses >= 15 else 1.0
                def apply_pace_synergy_func(row):
                    synergy_adj_val = 0.0
                    if "ãƒã‚¤" in sim_pace_prediction:
                        if row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]:
                            synergy_adj_val = -0.2 * sim_pace_multiplier
                        elif row['è„šè³ª'] == "é€ƒã’":
                            synergy_adj_val = 0.2 * sim_pace_multiplier
                    elif "ã‚¹ãƒ­ãƒ¼" in sim_pace_prediction:
                        if row['è„šè³ª'] in ["é€ƒã’", "å…ˆè¡Œ"]:
                            synergy_adj_val = -0.2 * sim_pace_multiplier
                        elif row['è„šè³ª'] in ["å·®ã—", "è¿½è¾¼"]:
                            synergy_adj_val = 0.2 * sim_pace_multiplier
                    return row['raw_rtc'] + synergy_adj_val

                sim_final_df['synergy_rtc'] = sim_final_df.apply(apply_pace_synergy_func, axis=1)
                sim_final_df = sim_final_df.sort_values("synergy_rtc")
                sim_final_df['RTCé †ä½'] = range(1, len(sim_final_df) + 1)
                sim_top_time = sim_final_df.iloc[0]['raw_rtc']
                sim_final_df['å·®'] = sim_final_df['raw_rtc'] - sim_top_time
                sim_final_df['äºˆæƒ³äººæ°—'] = sim_final_df['é¦¬å'].map(sim_input_pops)
                sim_final_df['å¦™å‘³ã‚¹ã‚³ã‚¢'] = sim_final_df['äºˆæƒ³äººæ°—'] - sim_final_df['RTCé †ä½']
                
                # å°ã®å‰²ã‚Šå½“ã¦
                sim_final_df['å½¹å‰²'] = "-"
                sim_final_df.loc[sim_final_df['RTCé †ä½'] == 1, 'å½¹å‰²'] = "â—"
                sim_final_df.loc[sim_final_df['RTCé †ä½'] == 2, 'å½¹å‰²'] = "ã€‡"
                sim_final_df.loc[sim_final_df['RTCé †ä½'] == 3, 'å½¹å‰²'] = "â–²"
                potential_bomb_horses = sim_final_df[sim_final_df['RTCé †ä½'] > 1].sort_values("å¦™å‘³ã‚¹ã‚³ã‚¢", ascending=False)
                if not potential_bomb_horses.empty:
                    sim_final_df.loc[sim_final_df['é¦¬å'] == potential_bomb_horses.iloc[0]['é¦¬å'], 'å½¹å‰²'] = "â˜…"
                
                # è¡¨ç¤ºç”¨ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                sim_final_df['æƒ³å®šã‚¿ã‚¤ãƒ '] = sim_final_df['raw_rtc'].apply(format_time)
                sim_final_df['å·®'] = sim_final_df['å·®'].apply(lambda x: f"+{x:.1f}" if x > 0 else "Â±0.0")

                st.markdown("---")
                st.subheader(f"ğŸ å±•é–‹äºˆæƒ³ï¼š{sim_pace_prediction} ({num_sim_horses}é ­ç«‹ã¦)")
                st.write(f"ã€è„šè³ªæ§‹æˆã€‘ é€ƒã’:{sim_styles_count['é€ƒã’']} / å…ˆè¡Œ:{sim_styles_count['å…ˆè¡Œ']} / å·®ã—:{sim_styles_count['å·®ã—']} / è¿½è¾¼:{sim_styles_count['è¿½è¾¼']}")
                
                fav_h_sim = sim_final_df[sim_final_df['å½¹å‰²'] == "â—"].iloc[0]['é¦¬å'] if not sim_final_df[sim_final_df['å½¹å‰²'] == "â—"].empty else ""
                opp_h_sim = sim_final_df[sim_final_df['å½¹å‰²'] == "ã€‡"].iloc[0]['é¦¬å'] if not sim_final_df[sim_final_df['å½¹å‰²'] == "ã€‡"].empty else ""
                bomb_h_sim = sim_final_df[sim_final_df['å½¹å‰²'] == "â˜…"].iloc[0]['é¦¬å'] if not sim_final_df[sim_final_df['å½¹å‰²'] == "â˜…"].empty else ""
                
                col_rec_sim1, col_rec_sim2 = st.columns(2)
                with col_rec_sim1:
                    st.info(f"**ğŸ¯ é¦¬é€£ãƒ»ãƒ¯ã‚¤ãƒ‰1ç‚¹å‹è² **\n\nâ— {fav_h_sim} ï¼ ã€‡ {opp_h_sim}")
                with col_rec_sim2: 
                    if bomb_h_sim:
                        st.warning(f"**ğŸ’£ å¦™å‘³ç‹™ã„ãƒ¯ã‚¤ãƒ‰1ç‚¹**\n\nâ— {fav_h_sim} ï¼ â˜… {bomb_h_sim} (å±•é–‹Ã—å¦™å‘³)")
                
                def highlight_sim_results(row):
                    if row['å½¹å‰²'] == "â˜…":
                        return ['background-color: #ffe4e1; font-weight: bold'] * len(row)
                    if row['å½¹å‰²'] == "â—":
                        return ['background-color: #fff700; font-weight: bold; color: black'] * len(row)
                    return [''] * len(row)
                
                st.table(sim_final_df[["å½¹å‰²", "é¦¬å", "è„šè³ª", "æ¸‹æ»", "ã‚¹ãƒ­ãƒ¼", "æƒ³å®šã‚¿ã‚¤ãƒ ", "å·®", "å¦™å‘³ã‚¹ã‚³ã‚¢", "é©æ€§", "å®‰å®š", "ä¸Šæ˜‡", "ãƒ¬ãƒ™ãƒ«", "åå·®", "load", "çŠ¶æ…‹", "è§£æãƒ¡ãƒ¢"]].style.apply(highlight_sim_results, axis=1))

# --- Tab 5: ãƒˆãƒ¬ãƒ³ãƒ‰è§£æ ---
with tab5:
    st.header("ğŸ“ˆ é¦¬å ´ãƒˆãƒ¬ãƒ³ãƒ‰ & çµ±è¨ˆè§£æ")
    db_df_tab5 = get_db_data()
    if not db_df_tab5.empty:
        target_course_trend = st.selectbox("ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ç¢ºèªã™ã‚‹ç«¶é¦¬å ´ã‚’é¸æŠ", list(COURSE_DATA.keys()), key="trend_course_select")
        trend_analysis_df = db_df_tab5[db_df_tab5['course'] == target_course_trend].sort_values("date")
        if not trend_analysis_df.empty:
            st.subheader("ğŸ’§ ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤ & å«æ°´ç‡ã®æ™‚ç³»åˆ—æ¨ç§»")
            st.line_chart(trend_analysis_df.set_index("date")[["cushion", "water"]])
            st.subheader("ğŸ ç›´è¿‘ã®ãƒ¬ãƒ¼ã‚¹å‚¾å‘ (4è§’å¹³å‡é€šéé †ä½)")
            recent_races_trend = trend_analysis_df.groupby('last_race').agg({'load':'mean', 'date':'max'}).sort_values('date', ascending=False).head(15)
            st.bar_chart(recent_races_trend['load'])
            st.subheader("ğŸ“Š ç›´è¿‘ä¸ŠãŒã‚Š3Fæ¨ç§»")
            st.line_chart(trend_analysis_df.set_index("date")["race_l3f"])

# --- Tab 6: ãƒ‡ãƒ¼ã‚¿ç®¡ç† ---
with tab6:
    st.header("ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å®ˆ & é«˜åº¦ãªç®¡ç†æ©Ÿèƒ½")
    db_df_tab6 = get_db_data()

    def update_eval_tags_full_logic(row, df_context=None):
        """ã€å®Œå…¨å¾©å…ƒã€‘å†è§£æãƒ»ãƒ‡ãƒ¼ã‚¿ã®å†æ¤œè¨¼ç”¨è©³ç´°ãƒ­ã‚¸ãƒƒã‚¯"""
        current_memo = str(row['memo']) if not pd.isna(row['memo']) else ""
        current_buy_flag = str(row['next_buy_flag']).replace("â˜…é€†è¡Œç‹™ã„", "").strip()
        
        # æ—¢å­˜ã®ãƒ¡ãƒ¢ã‹ã‚‰ã‚¿ã‚°éƒ¨åˆ†ã‚’é™¤å»ã—ã¦ãƒ™ãƒ¼ã‚¹ã‚’æŠ½å‡º
        base_memo_clean = re.sub(r'ã€.*?ã€‘', '', current_memo).strip("/")
        
        def safe_to_float(val):
            try:
                return float(val) if not pd.isna(val) else 0.0
            except:
                return 0.0
        
        f3f_v, l3f_v, r_l3f_v, res_pos_v, load_pos_v, dist_v, rtc_v = map(safe_to_float, [
            row['f3f'], row['l3f'], row['race_l3f'], row['result_pos'], row['load'], row['dist'], row['base_rtc']
        ])
        
        # ä¸­ç›¤ãƒ©ãƒƒãƒ—åˆ¤å®š
        m_note_v = "å¹³"
        if dist_v > 1200 and f3f_v > 0:
            m_lap_v = (rtc_v - f3f_v - l3f_v) / ((dist_v - 1200) / 200)
            if m_lap_v >= 12.8:
                m_note_v = "ç·©"
            elif m_lap_v <= 11.8:
                m_note_v = "ç· "
        elif dist_v <= 1200:
            m_note_v = "çŸ­"

        # ãƒã‚¤ã‚¢ã‚¹åˆ¤å®šï¼ˆ4ç€è£œå……ç‰¹ä¾‹ã‚’å®Œå…¨å†ç¾ï¼‰
        b_type_v = "ãƒ•ãƒ©ãƒƒãƒˆ"
        max_r_v = 16
        if df_context is not None and not pd.isna(row['last_race']):
            race_context_horses = df_context[df_context['last_race'] == row['last_race']]
            max_r_v = race_context_horses['result_pos'].max() if not race_context_horses.empty else 16
            top_3_race_v = race_context_horses[pd.to_numeric(race_context_horses['result_pos'], errors='coerce') <= 3].copy()
            top_3_race_v['load'] = pd.to_numeric(top_3_race_v['load'], errors='coerce').fillna(7.0)
            
            outliers_v = top_3_race_v[(top_3_race_v['load'] >= 10.0) | (top_3_race_v['load'] <= 3.0)]
            if len(outliers_v) == 1:
                bias_set_v = pd.concat([top_3_race_v[top_3_race_v['name'] != outliers_v.iloc[0]['name']], race_context_horses[pd.to_numeric(race_context_horses['result_pos'], errors='coerce') == 4]])
            else:
                bias_set_v = top_3_race_v
            
            if not bias_set_v.empty:
                avg_top_pos_v = bias_set_v['load'].mean()
                b_type_v = "å‰æœ‰åˆ©" if avg_top_pos_v <= 4.0 else "å¾Œæœ‰åˆ©" if avg_top_pos_v >= 10.0 else "ãƒ•ãƒ©ãƒƒãƒˆ"

        # ãƒšãƒ¼ã‚¹åˆ¤å®šï¼ˆãƒ¡ãƒ¢ã‹ã‚‰æŠ½å‡ºï¼‰
        p_status_v = "ãƒã‚¤ãƒšãƒ¼ã‚¹" if "ãƒã‚¤" in current_memo else "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" if "ã‚¹ãƒ­ãƒ¼" in current_memo else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        p_diff_v = 1.5 if p_status_v != "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹" else 0.0
        rel_p_v = load_pos_v / max_r_v
        
        # ğŸŒŸ å†è§£ææ™‚ã‚‚é ­æ•°å¼·åº¦ã‚’åæ˜ ï¼ˆéç·šå½¢è² è·ï¼‰
        field_intensity_v = max_r_v / 16.0
        new_load_score_v = 0.0
        if p_status_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and b_type_v != "å‰æœ‰åˆ©":
            new_load_score_v = max(0, (0.6 - rel_p_v) * p_diff_v * 3.0) * field_intensity_v
        elif p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and b_type_v != "å¾Œæœ‰åˆ©":
            new_load_score_v = max(0, (rel_p_v - 0.4) * p_diff_v * 2.0) * field_intensity_v
        
        # æ–°ã—ã„ã‚¿ã‚°ã®æ§‹æˆ
        new_tags_v = []
        is_counter_v = False
        if r_l3f_v > 0:
            diff_l3f_v = r_l3f_v - l3f_v
            if diff_l3f_v >= 0.5:
                new_tags_v.append("ğŸš€ ã‚¢ã‚¬ãƒªå„ªç§€")
            elif diff_l3f_v <= -1.0:
                new_tags_v.append("ğŸ“‰ å¤±é€Ÿå¤§")
        
        if res_pos_v <= 5:
            if (b_type_v == "å‰æœ‰åˆ©" and load_pos_v >= 10.0) or (b_type_v == "å¾Œæœ‰åˆ©" and load_pos_v <= 3.0):
                new_tags_v.append("ğŸ’ğŸ’ ï¾Šï¾ï½²ï½±ï½½æ¥µé™é€†è¡Œ" if max_r_v >= 16 else "ğŸ’ ï¾Šï¾ï½²ï½±ï½½é€†è¡Œ")
                is_counter_v = True
            
            is_favored_v = (p_status_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and b_type_v == "å‰æœ‰åˆ©") or (p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and b_type_v == "å¾Œæœ‰åˆ©")
            if not is_favored_v:
                if (p_status_v == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and load_pos_v <= 3.0):
                    new_tags_v.append("ğŸ“‰ æ¿€æµè¢«å®³" if max_r_v >= 14 else "ğŸ”¥ å±•é–‹é€†è¡Œ")
                    is_counter_v = True
                elif (p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and load_pos_v >= 10.0 and (f3f_v - l3f_v) > 1.5):
                    new_tags_v.append("ğŸ”¥ å±•é–‹é€†è¡Œ")
                    is_counter_v = True
        
        if max_r_v <= 10 and p_status_v == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and res_pos_v <= 2:
            new_tags_v.append("ğŸŸ¢ å±•é–‹æ©æµ")

        field_attr_v = "å¤š" if max_r_v >= 16 else "å°‘" if max_r_v <= 10 else "ä¸­"
        updated_memo_text = (f"ã€{p_status_v}/{b_type_v}/è² è·:{new_load_score_v:.1f}({field_attr_v})/{m_note_v}ã€‘" + "/".join(new_tags_v)).strip("/")
        updated_buy_flag_text = ("â˜…é€†è¡Œç‹™ã„ " + current_buy_flag).strip() if is_counter_v else current_buy_flag
        
        return updated_memo_text, updated_buy_flag_text

    # --- ğŸ—“ éå»ãƒ¬ãƒ¼ã‚¹ã®é–‹å‚¬é€±ã‚’ä¸€æ‹¬è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    st.subheader("ğŸ—“ éå»ãƒ¬ãƒ¼ã‚¹ã®é–‹å‚¬é€±ã‚’ä¸€æ‹¬è¨­å®š")
    if not db_df_tab6.empty:
        race_master_weeks = db_df_tab6[['last_race', 'date']].drop_duplicates(subset=['last_race']).copy()
        race_master_weeks['track_week'] = 1
        # ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ‡ã‚£ã‚¿ã§é€±æ•°ã‚’ä¸€æ‹¬å…¥åŠ›å¯èƒ½ã«
        edited_weeks_df = st.data_editor(race_master_weeks, hide_index=True)
        
        if st.button("ğŸ”„ è£œæ­£&å†è§£æã‚’ä¸€æ‹¬é©ç”¨"):
            week_lookup_dict = dict(zip(edited_weeks_df['last_race'], edited_weeks_df['track_week']))
            for idx_w, row_w in db_df_tab6.iterrows():
                if row_w['last_race'] in week_lookup_dict:
                    # RTCæŒ‡æ•°ã®é¡ã‚Šè£œæ­£
                    db_df_tab6.at[idx_w, 'base_rtc'] = row_w['base_rtc'] - (week_lookup_dict[row_w['last_race']] - 1) * 0.05
                    # ãƒ¡ãƒ¢ã¨ãƒ•ãƒ©ã‚°ã‚‚æœ€æ–°ãƒ­ã‚¸ãƒƒã‚¯ã§å†ç”Ÿæˆ
                    memo_re, flag_re = update_eval_tags_full_logic(db_df_tab6.iloc[idx_w], db_df_tab6)
                    db_df_tab6.at[idx_w, 'memo'] = memo_re
                    db_df_tab6.at[idx_w, 'next_buy_flag'] = flag_re
            
            if safe_update(db_df_tab6):
                st.success("å…¨ã¦ã®éå»ãƒ‡ãƒ¼ã‚¿ã®é–‹å‚¬é€±è£œæ­£ã¨å†è§£æãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                st.rerun()

    st.subheader("ğŸ› ï¸ ä¸€æ‹¬å‡¦ç†ãƒ¡ãƒ‹ãƒ¥ãƒ¼")
    col_adm_btn1, col_adm_btn2 = st.columns(2)
    with col_adm_btn1:
        if st.button("ğŸ”„ DBå†è§£æï¼ˆãƒ­ã‚¸ãƒƒã‚¯ã®ã¿ä¸€æ‹¬æ›´æ–°ï¼‰"):
            for idx_re, row_re in db_df_tab6.iterrows():
                m_re, f_re = update_eval_tags_full_logic(row_re, db_df_tab6)
                db_df_tab6.at[idx_re, 'memo'] = m_re
                db_df_tab6.at[idx_re, 'next_buy_flag'] = f_re
            if safe_update(db_df_tab6):
                st.success("DBã®å…¨å±¥æ­´ã«å¯¾ã—ã¦æœ€æ–°ãƒ­ã‚¸ãƒƒã‚¯ã‚’å†é©ç”¨ã—ã¾ã—ãŸã€‚")
                st.rerun()
    with col_adm_btn2:
        if st.button("ğŸ§¼ é‡è¤‡å‰Šé™¤ï¼ˆå®Œå…¨ä¸€è‡´è¡Œã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰"):
            count_before = len(db_df_tab6)
            db_df_tab6 = db_df_tab6.drop_duplicates(subset=['name', 'date', 'last_race'], keep='first')
            count_after = len(db_df_tab6)
            if safe_update(db_df_tab6):
                st.success(f"é‡è¤‡ãƒ‡ãƒ¼ã‚¿ {count_before - count_after} ä»¶ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
                st.rerun()

    if not db_df_tab6.empty:
        st.subheader("ğŸ› ï¸ ãƒ‡ãƒ¼ã‚¿ç·¨é›†ã‚¨ãƒ‡ã‚£ã‚¿")
        edit_display_full_df = db_df_tab6.copy()
        edit_display_full_df['base_rtc'] = edit_display_full_df['base_rtc'].apply(format_time)
        final_edited_db_df = st.data_editor(
            edit_display_full_df.sort_values("date", ascending=False), 
            num_rows="dynamic", 
            use_container_width=True
        )
        
        if st.button("ğŸ’¾ ã‚¨ãƒ‡ã‚£ã‚¿ã®å¤‰æ›´å†…å®¹ã‚’DBã«åæ˜ "):
            converted_save_df = final_edited_db_df.copy()
            converted_save_df['base_rtc'] = converted_save_df['base_rtc'].apply(parse_time_str)
            if safe_update(converted_save_df):
                st.success("ã‚¨ãƒ‡ã‚£ã‚¿ã§ã®ä¿®æ­£å†…å®¹ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«åæ˜ ã—ã¾ã—ãŸã€‚")
                st.rerun()
        
        st.divider()
        st.subheader("âŒ ãƒ‡ãƒ¼ã‚¿å‰Šé™¤è¨­å®š")
        col_del_final1, col_del_final2 = st.columns(2)
        with col_del_final1:
            all_races_for_del = sorted([str(x) for x in db_df_tab6['last_race'].dropna().unique()])
            target_race_to_del = st.selectbox("å‰Šé™¤å¯¾è±¡ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", ["æœªé¸æŠ"] + all_races_for_del)
            if target_race_to_del != "æœªé¸æŠ":
                if st.button(f"ğŸš¨ ãƒ¬ãƒ¼ã‚¹ã€{target_race_to_del}ã€‘ã‚’å…¨å‰Šé™¤"):
                    filtered_del_race_df = db_df_tab6[db_df_tab6['last_race'] != target_race_to_del]
                    if safe_update(filtered_del_race_df):
                        st.rerun()
        
        with col_del_final2:
            all_horses_for_del = sorted([str(x) for x in db_df_tab6['name'].dropna().unique()])
            # ğŸŒŸ ã€å®Œå…¨å¾©æ—§ã€‘ãƒãƒ«ãƒã‚»ãƒ¬ã‚¯ãƒˆå½¢å¼ã®é¦¬åä¸€æ‹¬å‰Šé™¤
            target_horses_to_del = st.multiselect("å‰Šé™¤ã™ã‚‹é¦¬ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰", all_horses_for_del, key="multi_del_horses_admin")
            if target_horses_to_del:
                if st.button(f"ğŸš¨ é¸æŠã—ãŸ {len(target_horses_to_del)} é ­ã‚’DBã‹ã‚‰å®Œå…¨å‰Šé™¤"):
                    filtered_del_horse_df = db_df_tab6[~db_df_tab6['name'].isin(target_horses_to_del)]
                    if safe_update(filtered_del_horse_df):
                        st.rerun()

        st.divider()
        with st.expander("â˜¢ï¸ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"):
            st.warning("ã“ã®æ“ä½œã¯å–ã‚Šæ¶ˆã›ã¾ã›ã‚“ã€‚å…¨ã¦ã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãŒæ¶ˆå»ã•ã‚Œã¾ã™ã€‚")
            if st.button("ğŸ§¨ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å®Œå…¨ã«ãƒªã‚»ãƒƒãƒˆ"):
                reset_empty_df = pd.DataFrame(columns=db_df_tab6.columns)
                if safe_update(reset_empty_df):
                    st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸã€‚")
                    st.rerun()
