import streamlit as st
import pandas as pd
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="DTI Ultimate DB", layout="wide")

# --- Google Sheets æ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

def get_db_data():
    all_cols = ["name", "base_rtc", "last_race", "course", "dist", "notes", "timestamp", "f3f", "l3f", "load"]
    try:
        df = conn.read(ttl="0")
        if df is None or df.empty:
            return pd.DataFrame(columns=all_cols)
        for col in all_cols:
            if col not in df.columns:
                df[col] = None
        return df
    except:
        return pd.DataFrame(columns=all_cols)

def format_time(seconds):
    if seconds is None or seconds <= 0: return ""
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

COURSE_DATA = {
    "æ±äº¬": 0.10, "ä¸­å±±": 0.25, "äº¬éƒ½": 0.15, "é˜ªç¥": 0.18, "ä¸­äº¬": 0.20,
    "æ–°æ½Ÿ": 0.05, "å°å€‰": 0.30, "ç¦å³¶": 0.28, "æœ­å¹Œ": 0.22, "å‡½é¤¨": 0.25
}

# --- ãƒ¡ã‚¤ãƒ³ UI ---
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ è§£æãƒ»ä¿å­˜", "ğŸ é¦¬åˆ¥å±¥æ­´", "ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´", "ğŸ¯ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", "ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"])

with tab1:
    st.header("ğŸš€ ãƒ¬ãƒ¼ã‚¹è§£æ & è‡ªå‹•ä¿å­˜")
    with st.sidebar:
        r_name = st.text_input("ãƒ¬ãƒ¼ã‚¹å")
        c_name = st.selectbox("ç«¶é¦¬å ´", list(COURSE_DATA.keys()))
        t_type = st.radio("ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"])
        dist_options = list(range(1000, 3700, 100))
        dist = st.selectbox("è·é›¢ (m)", dist_options, index=dist_options.index(1600))
        st.divider()
        st.write("ğŸ’§ é¦¬å ´ãƒ»ãƒã‚¤ã‚¢ã‚¹")
        cush = st.number_input("ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤", 7.0, 12.0, 9.5, step=0.1) if t_type == "èŠ" else 9.5
        w_4c = st.slider("å«æ°´ç‡ï¼š4è§’ (%)", 0.0, 30.0, 10.0)
        w_goal = st.slider("å«æ°´ç‡ï¼šã‚´ãƒ¼ãƒ«å‰ (%)", 0.0, 30.0, 10.0)
        bias_val = st.slider("é¦¬å ´ãƒã‚¤ã‚¢ã‚¹ (å†…æœ‰åˆ© -1.0 â†” å¤–æœ‰åˆ© +1.0)", -1.0, 1.0, 0.0)

    col1, col2 = st.columns(2)
    with col1: 
        lap_input = st.text_area("JRAãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ— (ä¾‹: 12.5-11.0-12.0...)")
        f3f_val = 0.0; l3f_val = 0.0; pace_status = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
        if lap_input:
            laps = [float(x) for x in re.findall(r'\d+\.\d', lap_input)]
            if len(laps) >= 3:
                f3f_val = sum(laps[:3])
                l3f_val = sum(laps[-3:])
                pace_diff = f3f_val - l3f_val
                if pace_diff < -1.0: pace_status = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                elif pace_diff > 1.0: pace_status = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                st.info(f"ğŸ å‰å¾ŒåŠ3Fæ¯”è¼ƒ: {f3f_val:.1f} - {l3f_val:.1f} ({pace_status})")

    with col2: raw_input = st.text_area("JRAæˆç¸¾è¡¨è²¼ã‚Šä»˜ã‘")

    if st.button("ğŸš€ è§£æã—ã¦DBã¸ä¿å­˜"):
        if raw_input and f3f_val > 0:
            clean_text = re.sub(r'\s+', ' ', raw_input)
            matches = list(re.finditer(r'(\d{1,2}:\d{2}\.\d)', clean_text))
            agari_list = re.findall(r'\s(\d{2}\.\d)\s', clean_text)
            pos_list = re.findall(r'\d{1,2}-\d{1,2}-\d{1,2}-\d{1,2}', clean_text)
            
            top3_pos = []
            for i in range(min(3, len(pos_list))):
                top3_pos.append(float(pos_list[i].split('-')[-1]))
            avg_top_pos = sum(top3_pos)/len(top3_pos) if top3_pos else 5.0
            race_bias = "å‰æ®‹ã‚Š" if avg_top_pos <= 4.0 else "å·®ã—æ±ºç€" if avg_top_pos >= 8.0 else "ãƒ•ãƒ©ãƒƒãƒˆ"

            new_rows = []
            for idx, m in enumerate(matches):
                time_str = m.group(1)
                before = clean_text[max(0, m.start()-100):m.start()]
                weight_m = re.search(r'(\d{2}\.\d)', before)
                name = "ä¸æ˜"; weight = 56.0
                if weight_m:
                    weight = float(weight_m.group(1))
                    parts = re.findall(r'([ã‚¡-ãƒ¶ãƒ¼]{2,})', before[:weight_m.start()])
                    if parts: name = parts[-1]
                
                m_p, s_p = map(float, time_str.split(':'))
                indiv_time = m_p * 60 + s_p
                
                try: indiv_l3f = float(agari_list[idx])
                except: indiv_l3f = l3f_val
                try: last_pos = float(pos_list[idx].split('-')[-1])
                except: last_pos = 5.0

                stamina_penalty = (dist - 1600) * 0.0005
                load_tags = []
                bonus_sec = 0.0
                
                if pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and last_pos <= 4:
                    load_tags.append("ãƒšãƒ¼ã‚¹é€†è¡Œ(ç²˜)"); bonus_sec -= 0.3
                elif pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and last_pos >= 10:
                    load_tags.append("ãƒšãƒ¼ã‚¹é€†è¡Œ(è¿½)"); bonus_sec -= 0.3

                if race_bias == "å‰æ®‹ã‚Š" and last_pos >= 8:
                    load_tags.append("ãƒã‚¤ã‚¢ã‚¹é€†è¡Œ(å·®)"); bonus_sec -= 0.2
                elif race_bias == "å·®ã—æ±ºç€" and last_pos <= 4:
                    load_tags.append("ãƒã‚¤ã‚¢ã‚¹é€†è¡Œ(ç²˜)"); bonus_sec -= 0.2
                else:
                    load_tags.append("ãƒã‚¤ã‚¢ã‚¹ç›¸å¿œ")

                avg_water = (w_4c + w_goal) / 2
                water_impact = (avg_water - 10.0) * 0.05 if t_type == "èŠ" else (12.0 - avg_water) * -0.10
                cush_impact = (9.5 - cush) * 0.1 if t_type == "èŠ" else 0
                
                rtc = indiv_time + bonus_sec + bias_val - (weight-56)*0.1 - water_impact - cush_impact + stamina_penalty
                
                new_rows.append({
                    "name": name, "base_rtc": rtc, "last_race": r_name,
                    "course": c_name, "dist": dist, "notes": "/".join(load_tags),
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
                    "f3f": f3f_val, "l3f": indiv_l3f, "load": last_pos
                })
            
            if new_rows:
                existing_df = get_db_data()
                updated_df = pd.concat([existing_df, pd.DataFrame(new_rows)], ignore_index=True)
                conn.update(data=updated_df)
                st.success(f"âœ… è§£æå®Œäº†ã€‚ãƒã‚¤ã‚¢ã‚¹: {race_bias}")

with tab3:
    st.header("ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    df = get_db_data()
    if not df.empty:
        race_list = sorted(df['last_race'].unique())
        selected_race = st.selectbox("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", race_list)
        if selected_race:
            race_df = df[df['last_race'] == selected_race].copy()
            f3f_raw = race_df['f3f'].iloc[0] if 'f3f' in race_df.columns else 0
            l3f_raw = race_df['l3f'].iloc[0] if 'l3f' in race_df.columns else 0
            if f3f_raw and l3f_raw:
                p_stat = "ãƒã‚¤" if (f3f_raw - l3f_raw) < -1.0 else "ã‚¹ãƒ­ãƒ¼" if (f3f_raw - l3f_raw) > 1.0 else "ãƒŸãƒ‰ãƒ«"
                avg_pos = race_df['load'].head(3).mean() if 'load' in race_df.columns else 0
                bias_info = "å‰æ®‹ã‚Š" if avg_pos <= 4 else "å·®ã—æ±ºç€" if avg_pos >= 8 else "ãƒ•ãƒ©ãƒƒãƒˆ"
                st.info(f"ğŸ“‹ ã€{p_stat}ãƒšãƒ¼ã‚¹ã€‘ã‹ã¤ã€ä¸Šä½å¹³å‡{avg_pos:.1f}ç•ªæ‰‹ï¼ˆ{bias_info}ï¼‰ã€‘ã®ãƒ¬ãƒ¼ã‚¹æ€§è³ª")
            race_df['base_rtc'] = race_df['base_rtc'].apply(format_time)
            st.dataframe(race_df.sort_values("base_rtc"), use_container_width=True)

with tab4:
    st.header("ğŸ¯ æ¬¡èµ°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼ & æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    df = get_db_data()
    if not df.empty:
        selected = st.multiselect("å‡ºèµ°äºˆå®šé¦¬ã‚’é¸æŠ", df['name'].unique())
        if selected:
            target_c = st.selectbox("æ¬¡èµ°ã®ç«¶é¦¬å ´", list(COURSE_DATA.keys()))
            if st.button("ğŸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
                results = []
                for h in selected:
                    h_history = df[df['name'] == h].sort_values("timestamp")
                    h_latest = h_history.iloc[-1]
                    has_hard_grit = h_history['notes'].str.contains("é€†è¡Œ", na=False).any()
                    sim_rtc = h_latest['base_rtc'] + (COURSE_DATA[target_c] * (h_latest['dist']/1600.0))
                    results.append({"é¦¬å": h, "æƒ³å®šRTC": sim_rtc, "last_f3f": h_latest['f3f'], "last_pos": h_latest['load'], "grit": has_hard_grit})

                front_runners = [r for r in results if r['last_pos'] <= 3]
                predicted_pace = "ãƒã‚¤ãƒšãƒ¼ã‚¹" if len(front_runners) >= 3 else "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" if len(front_runners) <= 1 else "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                st.subheader(f"ğŸ”® å±•é–‹äºˆæ¸¬: ã€{predicted_pace}ã€‘")

                final_list = []
                for r in results:
                    suitability = "æ™®é€š"
                    if predicted_pace == "ãƒã‚¤ãƒšãƒ¼ã‚¹": suitability = "âœ¨ å±•é–‹åˆ©ï¼ˆå·®ï¼‰" if r['last_pos'] >= 8 else "âš ï¸ å±•é–‹ä¸åˆ©ï¼ˆå‰ï¼‰"
                    elif predicted_pace == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹": suitability = "âœ¨ å±•é–‹åˆ©ï¼ˆå‰ï¼‰" if r['last_pos'] <= 3 else "âš ï¸ å±•é–‹ä¸åˆ©ï¼ˆå¾Œï¼‰"

                    status_note = suitability
                    expectancy_score = 2 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(ä¸­)
                    expectancy_label = "ä¸­"
                    
                    if r['grit']:
                        status_note = f"{suitability} â†’ ğŸ›  å®Ÿç¸¾ã«ã‚ˆã‚Šå‰²å¼•ä¸è¦" if "ä¸åˆ©" in suitability else f"{suitability} (é‰„æ¿)"
                        expectancy_score = 3
                        expectancy_label = "é«˜"
                    elif "åˆ©" in suitability:
                        expectancy_score = 3
                        expectancy_label = "é«˜"
                    elif "ä¸åˆ©" in suitability:
                        expectancy_score = 1
                        expectancy_label = "ä½"

                    final_list.append({
                        "é¦¬å": r['é¦¬å'], 
                        "æƒ³å®šã‚¿ã‚¤ãƒ ": format_time(r['æƒ³å®šRTC']), 
                        "å±•é–‹é©æ€§": status_note, 
                        "æœŸå¾…å€¤": expectancy_label, 
                        "score": expectancy_score,
                        "raw_rtc": r['æƒ³å®šRTC']
                    })

                # ã‚¹ã‚³ã‚¢(é™é †) > ã‚¿ã‚¤ãƒ (æ˜‡é †) ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°åŒ–
                res_df = pd.DataFrame(final_list).sort_values(by=["score", "raw_rtc"], ascending=[False, True])
                res_df.insert(0, "é †ä½", range(1, len(res_df) + 1))
                
                st.subheader("ğŸ† æœŸå¾…å€¤ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ»ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
                st.table(res_df[["é †ä½", "é¦¬å", "æƒ³å®šã‚¿ã‚¤ãƒ ", "æœŸå¾…å€¤", "å±•é–‹é©æ€§"]])

# --- Tab 2, 5 ã¯ãã®ã¾ã¾ ---
with tab2:
    st.header("ğŸ“Š é¦¬åˆ¥å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    df = get_db_data()
    if not df.empty:
        search_h = st.text_input("é¦¬åã§æ¤œç´¢", key="search_h")
        display_df = df.copy()
        if search_h: display_df = display_df[display_df['name'].str.contains(search_h)]
        display_df['base_rtc'] = display_df['base_rtc'].apply(format_time)
        st.dataframe(display_df.sort_values(["name", "timestamp"], ascending=[True, False]), use_container_width=True)

with tab5:
    st.header("ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤")
    df = get_db_data()
    if not df.empty:
        target_r = st.selectbox("å‰Šé™¤å¯¾è±¡ãƒ¬ãƒ¼ã‚¹", sorted(df['last_race'].unique()))
        if st.button("ğŸš¨ ãƒ¬ãƒ¼ã‚¹å‰Šé™¤ï¼ˆå®Ÿè¡Œï¼‰"):
            conn.update(data=df[df['last_race'] != target_r])
            st.success("å‰Šé™¤å®Œäº†"); st.rerun()
