import streamlit as st
import pandas as pd
import re
from streamlit_gsheets import GSheetsConnection
from datetime import datetime

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="DTI Ultimate DB", layout="wide")

# --- Google Sheets æ¥ç¶š ---
conn = st.connection("gsheets", type=GSheetsConnection)

def get_db_data():
    try:
        return conn.read(ttl="0") 
    except:
        return pd.DataFrame(columns=["name", "base_rtc", "last_race", "course", "dist", "notes", "timestamp", "f3f", "l3f", "load"])

def format_time(seconds):
    if seconds is None or seconds <= 0: return ""
    m = int(seconds // 60)
    s = seconds % 60
    return f"{m}:{s:04.1f}"

COURSE_DATA = {
    "æ±äº¬": 0.10, "ä¸­å±±": 0.25, "äº¬éƒ½": 0.15, "é˜ªç¥": 0.18, "ä¸­äº¬": 0.20,
    "æ–°æ½Ÿ": 0.05, "å°å€‰": 0.30, "ç¦å³¶": 0.28, "æœ­å¹Œ": 0.22, "å‡½é¤¨": 0.25
}

# --- ãƒ¡ã‚¤ãƒ³ UI ---
tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“ è§£æãƒ»ä¿å­˜", "ğŸ é¦¬åˆ¥å±¥æ­´", "ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´", "ğŸ¯ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼", "ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"])

with tab1:
    st.header("ğŸš€ ãƒ¬ãƒ¼ã‚¹è§£æ & è‡ªå‹•ä¿å­˜")
    with st.sidebar:
        r_name = st.text_input("ãƒ¬ãƒ¼ã‚¹å")
        c_name = st.selectbox("ç«¶é¦¬å ´", list(COURSE_DATA.keys()))
        t_type = st.radio("ç¨®åˆ¥", ["èŠ", "ãƒ€ãƒ¼ãƒˆ"])
        dist_options = list(range(1000, 3700, 100))
        dist = st.selectbox("è·é›¢ (m)", dist_options, index=dist_options.index(1600))
        st.divider()
        st.write("ğŸ’§ é¦¬å ´ãƒ»ãƒã‚¤ã‚¢ã‚¹")
        cush = st.number_input("ã‚¯ãƒƒã‚·ãƒ§ãƒ³å€¤", 7.0, 12.0, 9.5, step=0.1) if t_type == "èŠ" else 9.5
        w_4c = st.slider("å«æ°´ç‡ï¼š4è§’ (%)", 0.0, 30.0, 10.0)
        w_goal = st.slider("å«æ°´ç‡ï¼šã‚´ãƒ¼ãƒ«å‰ (%)", 0.0, 30.0, 10.0)
        bias_val = st.slider("é¦¬å ´ãƒã‚¤ã‚¢ã‚¹ (å†…æœ‰åˆ© -1.0 â†” å¤–æœ‰åˆ© +1.0)", -1.0, 1.0, 0.0)

    col1, col2 = st.columns(2)
    with col1: 
        lap_input = st.text_area("JRAãƒ¬ãƒ¼ã‚¹ãƒ©ãƒƒãƒ— (ä¾‹: 12.5-11.0-12.0...)")
        f3f_val = 0.0; l3f_val = 0.0; pace_status = ""
        if lap_input:
            laps = [float(x) for x in re.findall(r'\d+\.\d', lap_input)]
            if len(laps) >= 3:
                f3f_val = sum(laps[:3]) # ç´”ç²‹ãªå‰åŠ600m
                l3f_val = sum(laps[-3:]) # ç´”ç²‹ãªä¸ŠãŒã‚Š600m
                pace_diff = f3f_val - l3f_val
                if pace_diff < -1.0: pace_status = "ãƒã‚¤ãƒšãƒ¼ã‚¹"
                elif pace_diff > 1.0: pace_status = "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹"
                else: pace_status = "ãƒŸãƒ‰ãƒ«ãƒšãƒ¼ã‚¹"
                st.info(f"ğŸ å‰å¾ŒåŠ3Fæ¯”è¼ƒ: {f3f_val:.1f} - {l3f_val:.1f} ({pace_status})")

    with col2: 
        raw_input = st.text_area("JRAæˆç¸¾è¡¨è²¼ã‚Šä»˜ã‘ (ç€é †ãƒ»é¦¬åãƒ»æ–¤é‡ãƒ»é€šéé †ãƒ»ä¸ŠãŒã‚Š3Fã‚’å«ã‚€)")

    if st.button("ğŸš€ è§£æã—ã¦DBã¸ä¿å­˜"):
        if raw_input and f3f_val > 0:
            clean_text = re.sub(r'\s+', ' ', raw_input)
            matches = list(re.finditer(r'(\d{1,2}:\d{2}\.\d)', clean_text))
            agari_list = re.findall(r'\s(\d{2}\.\d)\s', clean_text)
            pos_list = re.findall(r'\d{1,2}-\d{1,2}-\d{1,2}-\d{1,2}', clean_text) # é€šéé †ã®æŠ½å‡º
            
            new_rows = []
            for idx, m in enumerate(matches):
                time_str = m.group(1)
                before = clean_text[max(0, m.start()-100):m.start()]
                weight_m = re.search(r'(\d{2}\.\d)', before)
                name = "ä¸æ˜"; weight = 56.0
                if weight_m:
                    weight = float(weight_m.group(1))
                    parts = re.findall(r'([ã‚¡-ãƒ¶ãƒ¼]{2,})', before[:weight_m.start()])
                    if parts: name = parts[-1]
                
                m_p, s_p = map(float, time_str.split(':'))
                indiv_time = m_p * 60 + s_p
                
                # ä¸ŠãŒã‚Šã¨ä½ç½®å–ã‚Š
                try: indiv_l3f = float(agari_list[idx])
                except: indiv_l3f = l3f_val
                
                try: 
                    last_pos = float(pos_list[idx].split('-')[-1]) # 4è§’ä½ç½®
                except: 
                    last_pos = 5.0

                # --- 1. ã‚¹ã‚¿ãƒŸãƒŠè£œæ­£ ---
                stamina_penalty = (dist - 1600) * 0.0005 # è·é›¢ãŒä¼¸ã³ã‚‹ã»ã©ãƒ­ã‚¹è€æ€§ãŒæ¸›ã‚‹è£œæ­£
                
                # --- 2. é€†è¡Œåˆ¤å®šãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯ ---
                load_tags = []
                bonus_sec = 0.0
                
                # ãƒšãƒ¼ã‚¹é€†è¡Œãƒã‚§ãƒƒã‚¯ (ä¾‹: ãƒã‚¤ãƒšãƒ¼ã‚¹ã§é€ƒã’/å…ˆè¡Œ)
                if pace_status == "ãƒã‚¤ãƒšãƒ¼ã‚¹" and last_pos <= 4:
                    load_tags.append("ãƒšãƒ¼ã‚¹é€†è¡Œ(ç²˜)")
                    bonus_sec -= 0.3 # æ ¹æ€§è©•ä¾¡ã¨ã—ã¦ã‚¿ã‚¤ãƒ ã‚’çŸ­ç¸®
                elif pace_status == "ã‚¹ãƒ­ãƒ¼ãƒšãƒ¼ã‚¹" and last_pos >= 10:
                    load_tags.append("ãƒšãƒ¼ã‚¹é€†è¡Œ(è¿½)")
                    bonus_sec -= 0.3

                # ãƒã‚¤ã‚¢ã‚¹é€†è¡Œãƒã‚§ãƒƒã‚¯ (ä¾‹: å†…æœ‰åˆ©ã§å¤–ã‚’å›ã—ãŸ/å¤–æœ‰åˆ©ã§å†…ã§è©°ã¾ã£ãŸ)
                if bias_val < -0.5: # å†…æœ‰åˆ©ãƒã‚¤ã‚¢ã‚¹æ™‚
                    load_tags.append("ãƒã‚¤ã‚¢ã‚¹é€†è¡Œ(å¤–)")
                    bonus_sec -= 0.2
                elif bias_val > 0.5: # å¤–æœ‰åˆ©ãƒã‚¤ã‚¢ã‚¹æ™‚
                    load_tags.append("ãƒã‚¤ã‚¢ã‚¹é€†è¡Œ(å†…)")
                    bonus_sec -= 0.2

                # --- 3. æ­£ç¢ºãªRTCç®—å‡º (ç‰©ç†è£œæ­£ + å±•é–‹ãƒœãƒ¼ãƒŠã‚¹) ---
                avg_water = (w_4c + w_goal) / 2
                water_impact = (avg_water - 10.0) * 0.05 if t_type == "èŠ" else (12.0 - avg_water) * -0.10
                cush_impact = (9.5 - cush) * 0.1 if t_type == "èŠ" else 0
                
                rtc = indiv_time + bonus_sec + bias_val - (weight-56)*0.1 - water_impact - cush_impact + stamina_penalty
                
                new_rows.append({
                    "name": name, "base_rtc": rtc, "last_race": r_name,
                    "course": c_name, "dist": dist, "notes": "/".join(load_tags) if load_tags else pace_status,
                    "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M"),
                    "f3f": f3f_val, "l3f": indiv_l3f, "load": last_pos
                })
            
            if new_rows:
                existing_df = get_db_data()
                updated_df = pd.concat([existing_df, pd.DataFrame(new_rows)], ignore_index=True)
                conn.update(data=updated_df)
                st.success(f"âœ… è§£æå®Œäº†ã€‚é€†è¡Œè² è·ã‚’ã‚¿ã‚¤ãƒ ã«é‚„å…ƒã—ã¾ã—ãŸã€‚")

with tab3:
    st.header("ğŸ ãƒ¬ãƒ¼ã‚¹åˆ¥å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    df = get_db_data()
    if not df.empty:
        race_list = sorted(df['last_race'].unique())
        selected_race = st.selectbox("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒ¼ã‚¹ã‚’é¸æŠ", race_list)
        if selected_race:
            race_df = df[df['last_race'] == selected_race].copy()
            
            # --- ä¸€ç›®ã§ã‚ã‹ã‚‹ã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ ---
            avg_f3f = race_df['f3f'].iloc[0]
            avg_l3f = race_df['l3f'].iloc[0]
            p_stat = "ãƒã‚¤" if (avg_f3f - avg_l3f) < -1.0 else "ã‚¹ãƒ­ãƒ¼" if (avg_f3f - avg_l3f) > 1.0 else "ãƒŸãƒ‰ãƒ«"
            avg_pos = race_df.iloc[:3]['load'].mean() # ä¸Šä½3é ­ã®å¹³å‡4è§’ä½ç½®
            bias_info = "å‰æ®‹ã‚Š" if avg_pos <= 4 else "å·®ã—æ±ºç€" if avg_pos >= 8 else "ãƒ•ãƒ©ãƒƒãƒˆ"
            
            st.info(f"ğŸ“‹ ã€{p_stat}ãƒšãƒ¼ã‚¹ã€‘ã‹ã¤ã€ä¸Šä½å¹³å‡{avg_pos:.1f}ç•ªæ‰‹ï¼ˆ{bias_info}ï¼‰ã€‘ã®ãƒ¬ãƒ¼ã‚¹æ€§è³ª")
            
            st.subheader("ğŸ¯ æ¬¡èµ°ç‹™ã„é¦¬ (é€†è¡Œå…‹æœé¦¬)")
            targets = race_df[race_df['notes'].str.contains("é€†è¡Œ", na=False)]
            if not targets.empty:
                for _, t in targets.iterrows():
                    st.write(f"ğŸŒŸ **{t['name']}** - {t['notes']} (è£œæ­£æ¸ˆã¿åˆ¤å®š)")
            else: st.write("è©²å½“ãªã—")

            st.divider()
            race_df['base_rtc'] = race_df['base_rtc'].apply(format_time)
            st.dataframe(race_df.sort_values("base_rtc"), use_container_width=True)

with tab2:
    st.header("ğŸ“Š é¦¬åˆ¥å±¥æ­´ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
    df = get_db_data()
    if not df.empty:
        search_horse = st.text_input("é¦¬åã§æ¤œç´¢", key="search_h")
        display_df = df.copy()
        if search_horse: display_df = display_df[display_df['name'].str.contains(search_horse)]
        display_df['base_rtc'] = display_df['base_rtc'].apply(format_time)
        st.dataframe(display_df.sort_values(["name", "timestamp"], ascending=[True, False]), use_container_width=True)

with tab4:
    st.header("ğŸ¯ æ¬¡èµ°ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãƒ¼")
    df = get_db_data()
    if not df.empty:
        selected = st.multiselect("å‡ºèµ°é¦¬ã‚’é¸æŠ", df['name'].unique())
        if selected:
            target_c = st.selectbox("æ¬¡èµ°ã®ç«¶é¦¬å ´", list(COURSE_DATA.keys()))
            if st.button("ğŸ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"):
                results = []
                for h in selected:
                    h_data = df[df['name'] == h].iloc[-1]
                    sim_rtc = h_data['base_rtc'] + (COURSE_DATA[target_c] * (h_data['dist']/1600.0))
                    results.append({"é¦¬å": h, "æƒ³å®šRTC": format_time(sim_rtc), "raw": sim_rtc})
                res_df = pd.DataFrame(results).sort_values("raw")
                st.table(res_df[["é¦¬å", "æƒ³å®šRTC"]])

with tab5:
    st.header("ğŸ—‘ ãƒ‡ãƒ¼ã‚¿ã®å‰Šé™¤")
    df = get_db_data()
    if not df.empty:
        delete_mode = st.radio("å‰Šé™¤å˜ä½", ["ãƒ¬ãƒ¼ã‚¹å˜ä½", "é¦¬å˜ä½"])
        if delete_mode == "ãƒ¬ãƒ¼ã‚¹å˜ä½":
            target_race = st.selectbox("å‰Šé™¤å¯¾è±¡", sorted(df['last_race'].unique()))
            if st.button("ğŸš¨ å‰Šé™¤ï¼ˆãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼‰"):
                new_df = df[df['last_race'] != target_race]
                conn.update(data=new_df)
                st.success("å‰Šé™¤æˆåŠŸ"); st.rerun()
        else:
            target_horse = st.selectbox("å‰Šé™¤å¯¾è±¡", sorted(df['name'].unique()))
            if st.button("ğŸš¨ å‰Šé™¤ï¼ˆãƒ€ãƒ–ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œï¼‰"):
                new_df = df[df['name'] != target_horse]
                conn.update(data=new_df)
                st.success("å‰Šé™¤æˆåŠŸ"); st.rerun()
